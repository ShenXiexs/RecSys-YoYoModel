code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
--> time_str: 202511240000, end_date: 202511240000
---------------------------------main-train-------------------------------------
---------------------------------export.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
---------------------------------main-export-------------------------------------
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-25 10:06:17.275909: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-25 10:06:17.275940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-25 10:06:17.275944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-25 10:06:17.276063: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-25 10:06:17.276081: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-25 10:06:17.276084: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:Using CPU for training
INFO:tensorflow:time_str=20251124, end_time_str=20251124
INFO:tensorflow:train_date={'20251124': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-22-1246916-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-26-1473628-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-16-906848-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-23-1303594-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-17-963526-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-15-850170-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-24-1360272-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-19-1076882-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-28-1586984-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-05-283390-56678.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511240000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 0
}
intra_op_parallelism_threads: 16
inter_op_parallelism_threads: 16
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: CPU
INFO:tensorflow:Batch sizes - Train: 5120, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 5120, 'train_epoch': 1, 'batch_size': 1024}
seq_idxs=[]
defalut feature:Tensor("StringJoin:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_1:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_2:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_3:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_4:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_5:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_6:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_7:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_8:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_9:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_10:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_11:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_12:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_13:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_14:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_15:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_16:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_17:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_18:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_19:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_20:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_21:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_22:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_23:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_24:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_25:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_26:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_27:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_28:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_29:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_30:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_31:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_32:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_33:0", shape=(None,), dtype=string)
feature:user__imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_34:0", shape=(None,), dtype=string)
feature:user__clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_35:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_36:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_37:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_38:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_39:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_40:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_41:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_42:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_43:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_44:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_45:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_46:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_47:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_48:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_49:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_50:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_51:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_52:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_53:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_54:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_55:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_56:0", shape=(None,), dtype=string)
feature:user__imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_57:0", shape=(None,), dtype=string)
feature:user__clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_58:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_59:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_60:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_61:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_62:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_63:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_64:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_65:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_66:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_67:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_68:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_69:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_70:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_71:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_72:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_73:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_74:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_75:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_76:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_77:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_78:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_79:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_80:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_81:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_82:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_83:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_84:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_85:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_86:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_87:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_88:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_89:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_90:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_91:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_92:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_93:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_94:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_95:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_96:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_97:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_98:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_99:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_100:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_101:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_102:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_103:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_104:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_105:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_106:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_107:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_108:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_109:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_110:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_111:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_112:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_113:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_114:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_115:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_116:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_117:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_118:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_119:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_120:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_121:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_122:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_123:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_124:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_125:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_126:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_127:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_128:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_129:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_130:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_131:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_132:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_133:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_134:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_135:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_136:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_137:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_138:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_139:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_140:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_141:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_142:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_143:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_144:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_145:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_146:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_147:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_148:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_149:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_150:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_151:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_152:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_153:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_154:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_155:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_156:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_157:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_158:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_159:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_160:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_161:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_162:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_163:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_164:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_165:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_166:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_167:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_168:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_169:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_170:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_171:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_172:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_173:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_174:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_175:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_176:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_177:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_178:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_179:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_180:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_181:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_182:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_183:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_184:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_185:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_186:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_187:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_188:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_189:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_190:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_191:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_192:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_193:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_194:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_195:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_196:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_197:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_198:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_199:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_200:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_201:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_202:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_203:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_204:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_205:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_206:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_207:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_208:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_209:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_210:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_211:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_212:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_213:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_214:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_215:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_216:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_217:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_218:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_219:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_220:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_221:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_222:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_223:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_224:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_225:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_226:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_227:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_228:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_229:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_230:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_231:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_232:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_233:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_234:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_235:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_236:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_237:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_238:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_239:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_240:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_241:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_242:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_243:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_244:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_245:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_246:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_247:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_248:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_249:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_250:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_251:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_252:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_253:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_254:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_255:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_256:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_257:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_258:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_259:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_260:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_261:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_262:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_263:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_264:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_265:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_266:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_267:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_268:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_269:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_270:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_271:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_272:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_273:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_274:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_275:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_276:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_277:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_278:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_279:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_280:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_281:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_282:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_283:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_284:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_285:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_286:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_287:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_288:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_289:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_290:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_291:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_292:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_293:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_294:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_295:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_296:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_297:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_298:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_299:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_300:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_301:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_302:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_303:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_304:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_305:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_306:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_307:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_308:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_309:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_310:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_311:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_312:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_313:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_314:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_315:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_316:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_317:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_318:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_319:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_320:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_321:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_322:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_323:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_324:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_325:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_326:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_327:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_328:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_329:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_330:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_331:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_332:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_333:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_334:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_335:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_336:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_337:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_338:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_339:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_340:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_341:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_342:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_343:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_344:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_345:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_346:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_347:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_348:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_349:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_350:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_351:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_352:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_353:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_354:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_355:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_356:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_357:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_358:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_359:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_360:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_361:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_362:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_363:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_364:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_365:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_366:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_367:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_368:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_369:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_370:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_371:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_372:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_373:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_374:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_375:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_376:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_377:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_378:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_379:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_380:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_381:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_382:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_383:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_384:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_385:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_386:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_387:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_388:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_389:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_390:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_391:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_392:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_393:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_394:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_395:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_396:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_397:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_398:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_399:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_400:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_401:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_402:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_403:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_404:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_405:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_406:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_407:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_408:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_409:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_410:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_411:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_412:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_413:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_414:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_415:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_416:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_417:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_418:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_419:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_420:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_421:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_422:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_423:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_424:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_425:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_426:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_427:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_428:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_429:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_430:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_431:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_432:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_433:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_434:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_435:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_436:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_437:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_438:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_439:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_440:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_441:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_442:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_443:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_444:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_445:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_446:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_447:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_448:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_449:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_450:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_451:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_452:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_453:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_454:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_455:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_456:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_457:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_458:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_459:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_460:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_461:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_462:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_463:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_464:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_465:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_466:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_467:0", shape=(None,), dtype=string)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fc3d06bccd0> -------
INFO:tensorflow:------ features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'export', 'ps_num': 0, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'CPU', 'gpu_ids': [], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is /job:localhost/replica:0/task:0/CPU:0 -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fc3d0649100> emb_lookuped: Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_1331:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1331:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("ctr_tower/zeros:0", shape=(None,), dtype=float32), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1331:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("awake_tower/zeros:0", shape=(None,), dtype=float32), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("mmoe_tower/zeros:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("mmoe_tower/zeros_1:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("mmoe_tower/zeros_2:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
2025-11-25 10:06:21.524640: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511240000/model.ckpt-65248
2025-11-25 10:06:21.945190: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:06:21.945509: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/export_dir/temp-1764036377/saved_model.pb
INFO:tensorflow:mode: export device: CPU task_type: chief task_idx: 0 time_str: 202511240000 end_time_str: None waste: 0.10 mins
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_468:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_469:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_470:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_471:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_472:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_473:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_474:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_475:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_476:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_477:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_478:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_479:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_480:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_481:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_482:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_483:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_484:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_485:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_486:0", shape=(None,), dtype=string)
features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} tensors: 487
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
-------------------------------generate_body---------------------------------------
seq_idxs=[]
(Namespace(day='20251124'), [])
[INFO/MainProcess] process shutting down
==================warmup.py:  export_dir:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/export_dir ====================
2025-11-25 10:06:27.512802: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-25 10:06:27.512841: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-25 10:06:27.512847: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-25 10:06:27.512963: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-25 10:06:27.512984: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-25 10:06:27.512989: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
seq_idxs=[]
model_dir:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/export_dir
body_file:/opt/huangmian/yoyo_model/config/O35_mutil_cvr_v10_mmoe_senet/body.json
files: [1763552958, 1763553175, 1763553610, 1763554105, 1763554575, 1763555049, 1763555486, 1763555884, 1763556238, 1763556734, 1763558089, 1763558781, 1763559092, 1763559385, 1763559577, 1763559780, 1763559988, 1763560304, 1763560585, 1763560866, 1763561170, 1763561664, 1763562408, 1763563095, 1763563590, 1763564219, 1763564598, 1763564928, 1763565253, 1763565599, 1763565828, 1763566140, 1763566423, 1763566707, 1763566994, 1763567276, 1763567589, 1763567868, 1763568199, 1763568554, 1763568851, 1763569122, 1763569373, 1763569545, 1763570024, 1763570573, 1763570927, 1763571345, 1763571837, 1763572292, 1763572907, 1763573434, 1763573902, 1763574311, 1763574726, 1763575080, 1763575483, 1763575818, 1763576134, 1763576418, 1763576712, 1763577069, 1763577386, 1763577711, 1763578025, 1763578219, 1763578509, 1763578835, 1763579141, 1763579401, 1763579592, 1763579859, 1763580092, 1763580233, 1763580327, 1763580387, 1763580487, 1763580593, 1763580710, 1763623195, 1763623552, 1763691262, 1763876079, 1763877380, 1763951617, 1764036377]
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
eval data:202511240000
---------------------------------eval.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
---------------------------------main-eval-------------------------------------
grep: /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/202511240000.eval: No such file or directory
---------------------------------save_eval_metric------------------------------------
seq_idxs=[]
(Namespace(dm_date='202511240000', eval_path='/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/eval', model_version='O35_mutil_cvr_v10_mmoe_senet'), [])
line=task = O35_mutil_cvr_v10_mmoe_senet, time = 202511240000, awake/auc = 0.84379804, awake/cnt = 1757045, awake/ctr = 0.07869406, awake/mae = 0.12378075, awake/pcoc = 1.0505244, awake/prob = 0.082670026, ctr/auc = 0.89454526, ctr/cnt = 1757045, ctr/ctr = 0.19059956, ctr/mae = 0.19439799, ctr/pcoc = 1.1021285, ctr/prob = 0.2100652, global_step = 64904, lhb/auc = 0.8734791, lhb/cnt = 1339182, lhb/ctr = 0.0025597715, lhb/mae = 0.0050473465, lhb/pcoc = 1.0346079, lhb/prob = 0.0026483599, loss = 0.5778106, sd/auc = 0.86364156, sd/cnt = 1118861, sd/ctr = 0.03864734, sd/mae = 0.06728472, sd/pcoc = 1.0621182, sd/prob = 0.04104804, ymfw/auc = 0.7877168, ymfw/cnt = 309961, ymfw/ctr = 0.025341898, ymfw/mae = 0.044542786, ymfw/pcoc = 0.857534, ymfw/prob = 0.021731539

partition= dm_date=202511240000
write table value(['O35_mutil_cvr_v10_mmoe_senet', '{"task": "O35_mutil_cvr_v10_mmoe_senet", "time": "202511240000", "awake/auc": "0.84379804", "awake/cnt": "1757045", "awake/ctr": "0.07869406", "awake/mae": "0.12378075", "awake/pcoc": "1.0505244", "awake/prob": "0.082670026", "ctr/auc": "0.89454526", "ctr/cnt": "1757045", "ctr/ctr": "0.19059956", "ctr/mae": "0.19439799", "ctr/pcoc": "1.1021285", "ctr/prob": "0.2100652", "global_step": "64904", "lhb/auc": "0.8734791", "lhb/cnt": "1339182", "lhb/ctr": "0.0025597715", "lhb/mae": "0.0050473465", "lhb/pcoc": "1.0346079", "lhb/prob": "0.0026483599", "loss": "0.5778106", "sd/auc": "0.86364156", "sd/cnt": "1118861", "sd/ctr": "0.03864734", "sd/mae": "0.06728472", "sd/pcoc": "1.0621182", "sd/prob": "0.04104804", "ymfw/auc": "0.7877168", "ymfw/cnt": "309961", "ymfw/ctr": "0.025341898", "ymfw/mae": "0.044542786", "ymfw/pcoc": "0.857534", "ymfw/prob": "0.021731539"}', 'cvr', '2025-11-25 10:08:12'])
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
infer data:202511240000
---------------------------------infer.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
---------------------------------main-infer-------------------------------------
ckpt_dir=/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000, time_str=202511240000
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-25 10:08:24.898104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:24.898328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:24.905545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:24.905724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:24.905831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:24.905943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:time_str=20251124, end_time_str=20251124
INFO:tensorflow:train_date={'20251124': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-21-1190238-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-17-963526-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-05-283390-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-00-0-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-31-1757018-27.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-01-56678-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-20-1133560-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-25-1416950-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-12-680136-56678.gz', '/data/share/opt/data/O35_mutil_cvr/20251124/part-r-09-510102-56678.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 2
}
intra_op_parallelism_threads: 8
inter_op_parallelism_threads: 8
gpu_options {
  per_process_gpu_memory_fraction: 0.9
  allow_growth: true
  visible_device_list: "1"
}
allow_soft_placement: true
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: GPU
INFO:tensorflow:Using GPUs: 1
INFO:tensorflow:Batch sizes - Train: 5120, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 5120, 'train_epoch': 1, 'batch_size': 1024}
seq_idxs=[]
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_0.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-21-1190238-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-21-1190238-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa14ac4b2b0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:08:26.514997: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-25 10:08:26.515658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:26.515915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:26.516018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:26.887291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:26.887462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:26.887548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:26.887634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:08:26.949262: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:08:26.949373: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:08:27.051158: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:08:27.051995: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2025-11-25 10:08:29.313932: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1it [00:04,  4.37s/it]2049it [00:04, 640.49it/s]4097it [00:04, 1464.06it/s]6145it [00:04, 2484.27it/s]8193it [00:04, 3757.01it/s]10241it [00:05, 5249.38it/s]12289it [00:05, 6802.50it/s]14337it [00:05, 8501.65it/s]16385it [00:05, 10148.17it/s]18433it [00:05, 11785.90it/s]20481it [00:05, 13146.73it/s]22529it [00:05, 14073.06it/s]24577it [00:05, 14850.94it/s]26625it [00:05, 15466.91it/s]28673it [00:06, 15949.42it/s]30721it [00:06, 16428.81it/s]32769it [00:06, 16701.54it/s]34817it [00:06, 16258.67it/s]36865it [00:06, 16208.17it/s]38913it [00:06, 16201.20it/s]40961it [00:06, 16020.59it/s]43009it [00:06, 16222.56it/s]45057it [00:07, 15982.59it/s]47105it [00:07, 16356.70it/s]49153it [00:07, 15888.02it/s]51201it [00:07, 16578.27it/s]53249it [00:07, 15852.64it/s]55297it [00:07, 15970.34it/s]56678it [00:07, 7242.87it/s] 
I1125 10:08:35.280909 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125100835a3cfdc0b0ae8cdcftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_1.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-17-963526-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-17-963526-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147f0f100> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:08:40.030341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:40.164052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:40.164227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:40.164418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:40.164535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:40.164632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:08:40.218359: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:08:40.218488: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:08:40.293244: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:08:40.293375: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.08s/it]2049it [00:03, 892.09it/s]4097it [00:03, 1990.51it/s]6145it [00:03, 3297.13it/s]8193it [00:03, 4752.56it/s]10241it [00:03, 6269.19it/s]12289it [00:03, 7702.11it/s]14337it [00:04, 9125.69it/s]16385it [00:04, 10638.10it/s]18433it [00:04, 12059.92it/s]20481it [00:04, 13165.40it/s]22529it [00:04, 13632.82it/s]24577it [00:04, 13876.05it/s]26625it [00:04, 13971.21it/s]28673it [00:04, 14528.31it/s]30721it [00:05, 14691.73it/s]32769it [00:05, 14946.04it/s]34817it [00:05, 15046.48it/s]36865it [00:05, 15144.88it/s]38913it [00:05, 15480.77it/s]40961it [00:05, 15478.69it/s]43009it [00:05, 15273.46it/s]45057it [00:06, 15025.66it/s]47105it [00:06, 15081.85it/s]49153it [00:06, 15001.59it/s]51201it [00:06, 15097.79it/s]53249it [00:06, 15776.76it/s]55297it [00:06, 16141.32it/s]56678it [00:06, 8382.48it/s] 
I1125 10:08:46.998537 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125100846c6983c0a0a91316ctarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_2.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-05-283390-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-05-283390-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147ee4f70> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:08:51.586154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:51.663604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:51.663724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:51.663853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:51.663933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:08:51.664026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:08:51.716591: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:08:51.716695: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:08:51.793421: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:08:51.793571: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.09s/it]2049it [00:03, 890.55it/s]4097it [00:03, 1974.78it/s]6145it [00:03, 3259.79it/s]8193it [00:03, 4677.83it/s]10241it [00:03, 6242.56it/s]12289it [00:03, 7758.60it/s]14337it [00:04, 9247.18it/s]16385it [00:04, 10695.29it/s]18433it [00:04, 12178.21it/s]20481it [00:04, 13415.36it/s]22529it [00:04, 14091.23it/s]24577it [00:04, 14342.89it/s]26625it [00:04, 14763.56it/s]28673it [00:04, 14940.37it/s]30721it [00:05, 15154.48it/s]32769it [00:05, 14996.56it/s]34817it [00:05, 15090.33it/s]36865it [00:05, 15035.58it/s]38913it [00:05, 15088.42it/s]40961it [00:05, 14944.86it/s]43009it [00:05, 15022.03it/s]45057it [00:06, 15274.10it/s]47105it [00:06, 15224.13it/s]49153it [00:06, 15174.62it/s]51201it [00:06, 15242.28it/s]53249it [00:06, 15206.98it/s]55297it [00:06, 15230.72it/s]56678it [00:06, 8358.50it/s] 
I1125 10:08:58.395117 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112510085893334a1a0a90ae76target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_3.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-00-0-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-00-0-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a1f88d60> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:09:03.268374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:03.268543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:03.268636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:03.268765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:03.268842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:03.268908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:09:03.325962: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:03.326075: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:03.405722: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:09:03.405866: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.07s/it]2049it [00:03, 891.13it/s]4097it [00:03, 2000.94it/s]6145it [00:03, 3306.98it/s]8193it [00:03, 4788.85it/s]10241it [00:03, 6225.90it/s]12289it [00:03, 7800.72it/s]14337it [00:04, 9278.95it/s]16385it [00:04, 10504.78it/s]18433it [00:04, 11817.02it/s]20481it [00:04, 12674.66it/s]22529it [00:04, 13297.22it/s]24577it [00:04, 13663.27it/s]26625it [00:04, 14161.54it/s]28673it [00:04, 14402.99it/s]30721it [00:05, 14253.54it/s]32769it [00:05, 14586.03it/s]34817it [00:05, 14719.69it/s]36865it [00:05, 14333.83it/s]38913it [00:05, 14252.99it/s]40961it [00:05, 14173.96it/s]43009it [00:05, 14754.45it/s]45057it [00:06, 14715.48it/s]47105it [00:06, 14925.82it/s]49153it [00:06, 15061.08it/s]51201it [00:06, 15809.67it/s]53249it [00:06, 15684.23it/s]55297it [00:06, 16199.03it/s]56678it [00:06, 8327.22it/s] 
I1125 10:09:10.234175 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125100910dcc7dc0b0ae96da6target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_4.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-31-1757018-27.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-31-1757018-27.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0fcd349d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:09:15.007520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:15.007688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:15.007774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:15.007890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:15.007966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:15.008030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:09:15.065938: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:15.066042: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:15.139838: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:09:15.139975: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:01,  1.87s/it]27it [00:01, 14.24it/s]
I1125 10:09:16.884398 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125100916b1973c0a0a913d74target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_5.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-01-56678-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-01-56678-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147daed00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:09:20.557087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:20.557307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:20.557416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:20.557582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:20.557684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:20.557750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:09:20.606772: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:20.606870: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:20.691011: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:09:20.691159: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.41s/it]2049it [00:03, 813.44it/s]4097it [00:03, 1821.86it/s]6145it [00:03, 3031.56it/s]8193it [00:03, 4422.32it/s]10241it [00:04, 5883.06it/s]12289it [00:04, 7490.41it/s]14337it [00:04, 8919.58it/s]16385it [00:04, 10403.92it/s]18433it [00:04, 11913.79it/s]20481it [00:04, 13108.95it/s]22529it [00:04, 13875.78it/s]24577it [00:04, 14819.62it/s]26625it [00:05, 15446.77it/s]28673it [00:05, 15769.57it/s]30721it [00:05, 16276.63it/s]32769it [00:05, 16657.27it/s]34817it [00:05, 16932.92it/s]36865it [00:05, 17230.57it/s]38913it [00:05, 17146.90it/s]40961it [00:05, 17467.92it/s]43009it [00:06, 17258.27it/s]45057it [00:06, 17470.50it/s]47105it [00:06, 17518.87it/s]49153it [00:06, 17457.26it/s]51201it [00:06, 17576.87it/s]53249it [00:06, 17459.09it/s]55297it [00:06, 17208.17it/s]56678it [00:06, 8318.89it/s] 
I1125 10:09:27.262989 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125100927c756381a0a90a6fatarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_6.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-20-1133560-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-20-1133560-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147e8dcd0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:09:32.067717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:32.067955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:32.068066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:32.068224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:32.068310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:32.068397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:09:32.123166: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:32.123273: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:32.198734: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:09:32.198863: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.41s/it]2049it [00:03, 810.29it/s]4097it [00:03, 1819.23it/s]6145it [00:03, 3050.64it/s]8193it [00:03, 4452.92it/s]10241it [00:04, 5929.91it/s]12289it [00:04, 7471.08it/s]14337it [00:04, 9011.50it/s]16385it [00:04, 10418.90it/s]18433it [00:04, 11819.83it/s]20481it [00:04, 12763.90it/s]22529it [00:04, 13725.56it/s]24577it [00:04, 14836.69it/s]26625it [00:05, 15309.37it/s]28673it [00:05, 16078.25it/s]30721it [00:05, 16317.03it/s]32769it [00:05, 16759.13it/s]34817it [00:05, 16549.84it/s]36865it [00:05, 16808.09it/s]38913it [00:05, 16915.10it/s]40961it [00:05, 17431.74it/s]43009it [00:06, 16947.60it/s]45057it [00:06, 17361.19it/s]47105it [00:06, 17522.59it/s]49153it [00:06, 17713.32it/s]51201it [00:06, 16987.82it/s]53249it [00:06, 17393.82it/s]55297it [00:06, 17411.07it/s]56678it [00:06, 8303.21it/s] 
I1125 10:09:38.828421 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112510093854f5da0b0ae8c0d1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_7.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-25-1416950-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-25-1416950-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147fe0640> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:09:43.440679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:43.440955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:43.441068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:43.441240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:43.441352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:43.441450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:09:43.498067: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:43.498175: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:43.581396: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:09:43.581543: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.22s/it]2049it [00:03, 858.30it/s]4097it [00:03, 1922.32it/s]6145it [00:03, 3216.27it/s]8193it [00:03, 4693.02it/s]10241it [00:03, 6261.51it/s]12289it [00:04, 7898.11it/s]14337it [00:04, 9328.60it/s]16385it [00:04, 10795.54it/s]18433it [00:04, 12203.52it/s]20481it [00:04, 13464.61it/s]22529it [00:04, 14412.25it/s]24577it [00:04, 15208.48it/s]26625it [00:04, 15975.57it/s]28673it [00:04, 16448.95it/s]30721it [00:05, 16565.00it/s]32769it [00:05, 16818.03it/s]34817it [00:05, 16920.27it/s]36865it [00:05, 17445.57it/s]38913it [00:05, 17388.03it/s]40961it [00:05, 17172.66it/s]43009it [00:05, 17471.02it/s]45057it [00:05, 17155.40it/s]47105it [00:06, 17386.79it/s]49153it [00:06, 17475.94it/s]51201it [00:06, 16892.43it/s]53249it [00:06, 16546.27it/s]55297it [00:06, 16906.28it/s]56678it [00:06, 8614.64it/s] 
I1125 10:09:50.093597 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511251009508fc8dc0b0ae92f56target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_8.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-12-680136-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-12-680136-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147fc5580> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:09:54.797513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:54.797680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:54.797757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:54.797891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:54.797968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:09:54.798033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:09:54.846607: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:54.846720: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:09:54.930358: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:09:54.930508: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.37s/it]2049it [00:03, 817.46it/s]4097it [00:03, 1835.31it/s]6145it [00:03, 3065.87it/s]8193it [00:03, 4451.22it/s]10241it [00:04, 5954.49it/s]12289it [00:04, 7470.57it/s]14337it [00:04, 8936.63it/s]16385it [00:04, 10512.55it/s]18433it [00:04, 11730.03it/s]20481it [00:04, 13008.64it/s]22529it [00:04, 13877.97it/s]24577it [00:04, 14900.27it/s]26625it [00:05, 14865.18it/s]28673it [00:05, 15742.03it/s]30721it [00:05, 15873.71it/s]32769it [00:05, 16580.44it/s]34817it [00:05, 16511.59it/s]36865it [00:05, 16327.06it/s]38913it [00:05, 16602.84it/s]40961it [00:05, 17077.35it/s]43009it [00:06, 16883.99it/s]45057it [00:06, 16910.77it/s]47105it [00:06, 17062.92it/s]49153it [00:06, 17365.90it/s]51201it [00:06, 17336.95it/s]53249it [00:06, 17643.53it/s]55297it [00:06, 17594.08it/s]56678it [00:06, 8329.96it/s] 
I1125 10:10:01.523292 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112510100118a9fe0a0a913c25target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_9.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-09-510102-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-09-510102-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0fcd9adf0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:10:06.182907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:06.183152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:06.183268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:06.183452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:06.183568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:06.183657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:10:06.239207: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:06.239331: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:06.319583: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:10:06.319719: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.39s/it]2049it [00:03, 816.68it/s]4097it [00:03, 1840.02it/s]6145it [00:03, 3067.55it/s]8193it [00:03, 4470.42it/s]10241it [00:04, 5950.67it/s]12289it [00:04, 7481.64it/s]14337it [00:04, 8956.39it/s]16385it [00:04, 10338.07it/s]18433it [00:04, 11660.06it/s]20481it [00:04, 12767.94it/s]22529it [00:04, 13839.93it/s]24577it [00:04, 14668.69it/s]26625it [00:05, 15228.04it/s]28673it [00:05, 15703.89it/s]30721it [00:05, 16077.91it/s]32769it [00:05, 16269.53it/s]34817it [00:05, 16618.98it/s]36865it [00:05, 16999.66it/s]38913it [00:05, 17215.70it/s]40961it [00:05, 17219.79it/s]43009it [00:06, 17398.76it/s]45057it [00:06, 17261.17it/s]47105it [00:06, 17262.73it/s]49153it [00:06, 17103.04it/s]51201it [00:06, 17299.65it/s]53249it [00:06, 17143.62it/s]55297it [00:06, 17080.60it/s]56678it [00:06, 8315.91it/s] 
I1125 10:10:12.823862 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101012a3cfdc0b0ae8ec78target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_10.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-13-736814-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-13-736814-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a45e9070> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:10:17.636285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:17.636454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:17.636531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:17.636647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:17.636722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:17.636785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:10:17.684791: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:17.684899: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:17.772547: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:10:17.772681: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.21s/it]2049it [00:03, 861.08it/s]4097it [00:03, 1931.28it/s]6145it [00:03, 3199.93it/s]8193it [00:03, 4638.16it/s]10241it [00:03, 6196.27it/s]12289it [00:04, 7828.69it/s]14337it [00:04, 9228.79it/s]16385it [00:04, 10610.14it/s]18433it [00:04, 11631.35it/s]20481it [00:04, 12664.57it/s]22529it [00:04, 13792.52it/s]24577it [00:04, 14688.15it/s]26625it [00:04, 15157.91it/s]28673it [00:05, 15470.24it/s]30721it [00:05, 15521.40it/s]32769it [00:05, 16099.81it/s]34817it [00:05, 16498.29it/s]36865it [00:05, 16935.65it/s]38913it [00:05, 17134.72it/s]40961it [00:05, 17314.11it/s]43009it [00:05, 17478.24it/s]45057it [00:05, 17316.31it/s]47105it [00:06, 16928.11it/s]49153it [00:06, 17163.28it/s]51201it [00:06, 17527.22it/s]53249it [00:06, 17085.68it/s]55297it [00:06, 17179.92it/s]56678it [00:06, 8537.31it/s] 
I1125 10:10:24.181597 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101024c2c7dc0b0ae929a4target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_11.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-30-1700340-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-30-1700340-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0fcfd6e80> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:10:28.984541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:28.984722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:28.984800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:28.984916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:28.984992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:28.985057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:10:29.041128: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:29.041314: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:29.121338: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:10:29.121481: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.36s/it]2049it [00:03, 822.41it/s]4097it [00:03, 1848.43it/s]6145it [00:03, 3093.46it/s]8193it [00:03, 4490.79it/s]10241it [00:04, 6020.78it/s]12289it [00:04, 7492.49it/s]14337it [00:04, 8853.15it/s]16385it [00:04, 10455.78it/s]18433it [00:04, 12002.74it/s]20481it [00:04, 13338.91it/s]22529it [00:04, 14321.30it/s]24577it [00:04, 14762.24it/s]26625it [00:05, 15578.33it/s]28673it [00:05, 16133.07it/s]30721it [00:05, 16591.48it/s]32769it [00:05, 16847.52it/s]34817it [00:05, 17116.64it/s]36865it [00:05, 17125.15it/s]38913it [00:05, 16853.01it/s]40961it [00:05, 17308.90it/s]43009it [00:05, 17476.40it/s]45057it [00:06, 17956.64it/s]47105it [00:06, 18076.54it/s]49153it [00:06, 17426.11it/s]51201it [00:06, 17234.88it/s]53249it [00:06, 17443.91it/s]55297it [00:06, 17563.54it/s]56678it [00:06, 8427.70it/s] 
I1125 10:10:35.521559 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101035c2c7dc0b0ae92ce1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_12.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-27-1530306-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-27-1530306-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a09a2e50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:10:40.035776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:40.035947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:40.036024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:40.036140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:40.036216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:40.036293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:10:40.088897: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:40.089084: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:40.173021: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:10:40.173173: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.26s/it]2049it [00:03, 843.09it/s]4097it [00:03, 1891.79it/s]6145it [00:03, 3148.07it/s]8193it [00:03, 4559.55it/s]10241it [00:03, 6090.29it/s]12289it [00:04, 7655.48it/s]14337it [00:04, 9210.30it/s]16385it [00:04, 10614.69it/s]18433it [00:04, 12217.42it/s]20481it [00:04, 13217.86it/s]22529it [00:04, 14380.28it/s]24577it [00:04, 15019.14it/s]26625it [00:04, 15359.58it/s]28673it [00:05, 15134.95it/s]30721it [00:05, 15872.15it/s]32769it [00:05, 16001.23it/s]34817it [00:05, 16204.94it/s]36865it [00:05, 16243.95it/s]38913it [00:05, 16529.23it/s]40961it [00:05, 16661.73it/s]43009it [00:05, 17048.92it/s]45057it [00:06, 16622.12it/s]47105it [00:06, 16621.55it/s]49153it [00:06, 16403.83it/s]51201it [00:06, 16943.58it/s]53249it [00:06, 16606.66it/s]55297it [00:06, 16051.08it/s]56678it [00:06, 8400.90it/s] 
I1125 10:10:46.407525 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112510104693334a1a0a90cef8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_13.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-19-1076882-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-19-1076882-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0fcf3fb50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:10:51.199660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:51.213615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:51.213740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:51.213870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:51.213949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:10:51.214016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:10:51.279853: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:51.280078: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:10:51.358410: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:10:51.358535: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.33s/it]2049it [00:03, 829.35it/s]4097it [00:03, 1860.05it/s]6145it [00:03, 3076.26it/s]8193it [00:03, 4507.12it/s]10241it [00:04, 6016.72it/s]12289it [00:04, 7465.17it/s]14337it [00:04, 8880.36it/s]16385it [00:04, 10470.48it/s]18433it [00:04, 11963.59it/s]20481it [00:04, 13251.73it/s]22529it [00:04, 14264.80it/s]24577it [00:04, 15316.52it/s]26625it [00:05, 15682.22it/s]28673it [00:05, 16165.91it/s]30721it [00:05, 15759.60it/s]32769it [00:05, 16410.78it/s]34817it [00:05, 16063.63it/s]36865it [00:05, 16514.00it/s]38913it [00:05, 17049.48it/s]40961it [00:05, 17412.97it/s]43009it [00:05, 17422.94it/s]45057it [00:06, 17385.70it/s]47105it [00:06, 17014.17it/s]49153it [00:06, 16626.37it/s]51201it [00:06, 16969.87it/s]53249it [00:06, 17018.21it/s]55297it [00:06, 16962.03it/s]56678it [00:06, 8383.11it/s] 
I1125 10:10:57.625706 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101057c2c7dc0b0ae934c0target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_14.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-26-1473628-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-26-1473628-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0fcd2f370> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:11:02.209655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:02.209826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:02.209903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:02.210017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:02.210094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:02.210158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:11:02.275663: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:02.275784: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:02.368779: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:11:02.368927: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.34s/it]2049it [00:03, 827.18it/s]4097it [00:03, 1864.23it/s]6145it [00:03, 3090.65it/s]8193it [00:03, 4494.36it/s]10241it [00:04, 6040.29it/s]12289it [00:04, 7600.99it/s]14337it [00:04, 9013.53it/s]16385it [00:04, 10537.03it/s]18433it [00:04, 12024.50it/s]20481it [00:04, 13326.01it/s]22529it [00:04, 14337.38it/s]24577it [00:04, 15232.56it/s]26625it [00:05, 15380.14it/s]28673it [00:05, 15834.26it/s]30721it [00:05, 16004.52it/s]32769it [00:05, 16395.37it/s]34817it [00:05, 16544.75it/s]36865it [00:05, 16964.35it/s]38913it [00:05, 17115.01it/s]40961it [00:05, 17169.89it/s]43009it [00:05, 17106.98it/s]45057it [00:06, 17193.67it/s]47105it [00:06, 16981.70it/s]49153it [00:06, 17200.60it/s]51201it [00:06, 17114.74it/s]53249it [00:06, 17067.50it/s]55297it [00:06, 16914.04it/s]56678it [00:06, 8401.25it/s] 
I1125 10:11:08.894348 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101108c254381a0a9182d9target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_15.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-14-793492-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-14-793492-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147e5d0d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:11:13.461012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:13.461198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:13.461276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:13.461391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:13.461467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:13.461532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:11:13.529115: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:13.529305: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:13.607554: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:11:13.607719: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.29s/it]2049it [00:03, 839.02it/s]4097it [00:03, 1885.42it/s]6145it [00:03, 3114.45it/s]8193it [00:03, 4558.85it/s]10241it [00:03, 6108.51it/s]12289it [00:04, 7654.41it/s]14337it [00:04, 9137.02it/s]16385it [00:04, 10666.53it/s]18433it [00:04, 12120.18it/s]20481it [00:04, 13339.51it/s]22529it [00:04, 14264.05it/s]24577it [00:04, 15308.40it/s]26625it [00:04, 15443.87it/s]28673it [00:05, 16164.46it/s]30721it [00:05, 16258.99it/s]32769it [00:05, 16771.09it/s]34817it [00:05, 16340.74it/s]36865it [00:05, 17001.53it/s]38913it [00:05, 17077.57it/s]40961it [00:05, 17396.23it/s]43009it [00:05, 16958.46it/s]45057it [00:06, 16453.61it/s]47105it [00:06, 16990.28it/s]49153it [00:06, 17612.70it/s]51201it [00:06, 17244.07it/s]53249it [00:06, 17646.85it/s]55297it [00:06, 17383.13it/s]56678it [00:06, 8491.86it/s] 
I1125 10:11:20.038327 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101119d4334a1a0a913c89target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_16.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-06-340068-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-06-340068-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a45e9100> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:11:25.220888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:25.221053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:25.221129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:25.221243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:25.221319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:25.221383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:11:25.269369: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:25.269475: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:25.381820: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:11:25.381942: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.32s/it]2049it [00:03, 832.75it/s]4097it [00:03, 1867.00it/s]6145it [00:03, 3127.52it/s]8193it [00:03, 4498.67it/s]10241it [00:04, 6083.70it/s]12289it [00:04, 7610.05it/s]14337it [00:04, 9217.39it/s]16385it [00:04, 10526.42it/s]18433it [00:04, 12054.37it/s]20481it [00:04, 13190.61it/s]22529it [00:04, 14206.04it/s]24577it [00:04, 14870.81it/s]26625it [00:04, 15810.82it/s]28673it [00:05, 15909.52it/s]30721it [00:05, 16025.33it/s]32769it [00:05, 16325.86it/s]34817it [00:05, 17033.13it/s]36865it [00:05, 16790.13it/s]38913it [00:05, 16995.77it/s]40961it [00:05, 16977.24it/s]43009it [00:05, 17366.21it/s]45057it [00:06, 17099.22it/s]47105it [00:06, 17570.08it/s]49153it [00:06, 17101.85it/s]51201it [00:06, 17764.05it/s]53249it [00:06, 17214.06it/s]55297it [00:06, 17918.75it/s]56678it [00:06, 8457.87it/s] 
I1125 10:11:31.675768 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101131c756381a0a90ccb1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_17.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-10-566780-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-10-566780-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a4872a00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:11:36.352944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:36.353108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:36.353184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:36.353312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:36.353391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:36.353463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:11:36.405672: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:36.405777: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:36.480751: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:11:36.480879: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.26s/it]2049it [00:03, 846.88it/s]4097it [00:03, 1894.43it/s]6145it [00:03, 3179.26it/s]8193it [00:03, 4599.16it/s]10241it [00:03, 6207.31it/s]12289it [00:04, 7689.08it/s]14337it [00:04, 9167.74it/s]16385it [00:04, 10728.18it/s]18433it [00:04, 12371.90it/s]20481it [00:04, 13453.15it/s]22529it [00:04, 14478.12it/s]24577it [00:04, 14995.35it/s]26625it [00:04, 16072.92it/s]28673it [00:05, 16367.29it/s]30721it [00:05, 16799.74it/s]32769it [00:05, 16636.56it/s]34817it [00:05, 17103.32it/s]36865it [00:05, 17212.99it/s]38913it [00:05, 17669.71it/s]40961it [00:05, 17728.13it/s]43009it [00:05, 17678.45it/s]45057it [00:05, 17684.13it/s]47105it [00:06, 17876.75it/s]49153it [00:06, 18151.27it/s]51201it [00:06, 17957.79it/s]53249it [00:06, 17813.82it/s]55297it [00:06, 17878.76it/s]56678it [00:06, 8607.50it/s] 
I1125 10:11:42.665092 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101142a3cfdc0b0ae909d8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_18.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-03-170034-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-03-170034-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147f82460> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:11:47.232764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:47.232946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:47.233025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:47.233139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:47.233224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:47.233290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:11:47.285529: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:47.285640: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:47.369021: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:11:47.369150: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.06s/it]2049it [00:03, 899.26it/s]4097it [00:03, 2005.63it/s]6145it [00:03, 3309.95it/s]8193it [00:03, 4785.69it/s]10241it [00:03, 6338.90it/s]12289it [00:03, 7949.14it/s]14337it [00:04, 9310.72it/s]16385it [00:04, 10934.93it/s]18433it [00:04, 12471.39it/s]20481it [00:04, 13810.35it/s]22529it [00:04, 14723.02it/s]24577it [00:04, 15640.02it/s]26625it [00:04, 16183.77it/s]28673it [00:04, 16053.28it/s]30721it [00:04, 16637.21it/s]32769it [00:05, 16923.55it/s]34817it [00:05, 17161.59it/s]36865it [00:05, 16982.93it/s]38913it [00:05, 17215.00it/s]40961it [00:05, 17830.03it/s]43009it [00:05, 17525.29it/s]45057it [00:05, 17484.52it/s]47105it [00:05, 17020.94it/s]49153it [00:06, 17325.12it/s]51201it [00:06, 17550.31it/s]53249it [00:06, 17678.96it/s]55297it [00:06, 17693.68it/s]56678it [00:06, 8852.93it/s] 
I1125 10:11:53.419657 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112510115318a9fe0a0a915ebftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_19.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-04-226712-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-04-226712-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa1480da430> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:11:58.180810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:58.180973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:58.181056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:58.181169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:58.181244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:11:58.181307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:11:58.241947: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:58.242102: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:11:58.317236: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:11:58.317353: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.48s/it]2049it [00:03, 797.34it/s]4097it [00:03, 1792.87it/s]6145it [00:03, 3002.48it/s]8193it [00:04, 4375.76it/s]10241it [00:04, 5810.95it/s]12289it [00:04, 7295.71it/s]14337it [00:04, 8655.02it/s]16385it [00:04, 10122.16it/s]18433it [00:04, 11662.57it/s]20481it [00:04, 12867.31it/s]22529it [00:04, 14007.01it/s]24577it [00:05, 14911.09it/s]26625it [00:05, 15426.95it/s]28673it [00:05, 15423.65it/s]30721it [00:05, 15691.09it/s]32769it [00:05, 16086.86it/s]34817it [00:05, 16047.89it/s]36865it [00:05, 15859.66it/s]38913it [00:05, 16262.48it/s]40961it [00:06, 16555.47it/s]43009it [00:06, 16722.76it/s]45057it [00:06, 16794.16it/s]47105it [00:06, 16484.98it/s]49153it [00:06, 16461.35it/s]51201it [00:06, 16453.52it/s]53249it [00:06, 16743.96it/s]55297it [00:06, 16973.26it/s]56678it [00:06, 8128.96it/s] 
I1125 10:12:04.844741 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101204dcc7dc0b0ae9a583target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_20.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-28-1586984-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-28-1586984-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a41c72b0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:12:09.523758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:09.523976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:09.524065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:09.524215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:09.524328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:09.524418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:12:09.599692: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:09.599834: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:09.702402: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:12:09.702552: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.67s/it]2049it [00:03, 756.46it/s]4097it [00:03, 1711.03it/s]6145it [00:04, 2855.89it/s]8193it [00:04, 4161.30it/s]10241it [00:04, 5578.77it/s]12289it [00:04, 7018.70it/s]14337it [00:04, 8379.86it/s]16385it [00:04, 9752.72it/s]18433it [00:04, 11205.53it/s]20481it [00:05, 12443.92it/s]22529it [00:05, 13646.06it/s]24577it [00:05, 14463.15it/s]26625it [00:05, 15110.71it/s]28673it [00:05, 15785.65it/s]30721it [00:05, 16118.73it/s]32769it [00:05, 16417.74it/s]34817it [00:05, 16811.33it/s]36865it [00:06, 16978.95it/s]38913it [00:06, 16897.24it/s]40961it [00:06, 16945.98it/s]43009it [00:06, 15922.19it/s]45057it [00:06, 16105.83it/s]47105it [00:06, 16353.44it/s]49153it [00:06, 16792.17it/s]51201it [00:06, 16996.71it/s]53249it [00:07, 16817.91it/s]55297it [00:07, 17037.30it/s]56678it [00:07, 7907.68it/s] 
I1125 10:12:16.140475 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101216d4334a1a0a914f31target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_21.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-11-623458-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-11-623458-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147cb8850> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:12:20.570010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:20.570177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:20.570253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:20.570367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:20.570443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:20.570506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:12:20.629929: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:20.630088: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:20.727728: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:12:20.727884: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.20s/it]2049it [00:03, 861.47it/s]4097it [00:03, 1931.59it/s]6145it [00:03, 3212.72it/s]8193it [00:03, 4606.28it/s]10241it [00:03, 6095.80it/s]12289it [00:04, 7602.80it/s]14337it [00:04, 9041.72it/s]16385it [00:04, 10676.02it/s]18433it [00:04, 12179.71it/s]20481it [00:04, 13426.40it/s]22529it [00:04, 14354.74it/s]24577it [00:04, 15130.17it/s]26625it [00:04, 15664.74it/s]28673it [00:05, 16014.39it/s]30721it [00:05, 16543.01it/s]32769it [00:05, 16759.98it/s]34817it [00:05, 16813.17it/s]36865it [00:05, 16874.32it/s]38913it [00:05, 17515.71it/s]40961it [00:05, 17613.16it/s]43009it [00:05, 17892.94it/s]45057it [00:05, 17990.62it/s]47105it [00:06, 17859.60it/s]49153it [00:06, 17749.28it/s]51201it [00:06, 17700.93it/s]53249it [00:06, 17659.97it/s]55297it [00:06, 16978.39it/s]56678it [00:06, 8606.49it/s] 
I1125 10:12:27.088450 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101226c8c7dc0b0ae9b5a4target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_22.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-29-1643662-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-29-1643662-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147eff670> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:12:31.558176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:31.731642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:31.731758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:31.731889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:31.731972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:31.732056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:12:31.796947: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:31.797149: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:31.888255: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:12:31.888523: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.43s/it]2049it [00:03, 807.44it/s]4097it [00:03, 1819.49it/s]6145it [00:03, 3051.75it/s]8193it [00:03, 4415.93it/s]10241it [00:04, 5953.19it/s]12289it [00:04, 7428.42it/s]14337it [00:04, 8896.64it/s]16385it [00:04, 10433.53it/s]18433it [00:04, 11918.87it/s]20481it [00:04, 13133.46it/s]22529it [00:04, 13989.31it/s]24577it [00:04, 14839.74it/s]26625it [00:05, 15248.73it/s]28673it [00:05, 15843.28it/s]30721it [00:05, 16289.58it/s]32769it [00:05, 16611.14it/s]34817it [00:05, 17022.44it/s]36865it [00:05, 16912.45it/s]38913it [00:05, 17439.11it/s]40961it [00:05, 17183.42it/s]43009it [00:06, 17461.16it/s]45057it [00:06, 17360.24it/s]47105it [00:06, 17663.82it/s]49153it [00:06, 16810.91it/s]51201it [00:06, 17492.29it/s]53249it [00:06, 17515.33it/s]55297it [00:06, 17470.87it/s]56678it [00:06, 8309.15it/s] 
I1125 10:12:38.427700 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112510123894334a1a0a90e491target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_23.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-18-1020204-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-18-1020204-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0fcd32970> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:12:42.630114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:42.630275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:42.630358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:42.630481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:42.630563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:42.630632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:12:42.700332: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:42.700532: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:42.785312: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:12:42.785561: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.47s/it]2049it [00:03, 793.38it/s]4097it [00:03, 1775.02it/s]6050it [00:03, 2980.19it/s]7450it [00:04, 3832.11it/s]9217it [00:04, 5177.70it/s]11265it [00:04, 6830.80it/s]13313it [00:04, 8476.16it/s]15361it [00:04, 9877.22it/s]17409it [00:04, 11341.38it/s]19457it [00:04, 12631.98it/s]21505it [00:04, 13995.19it/s]23553it [00:05, 14841.63it/s]25601it [00:05, 15663.83it/s]27649it [00:05, 16238.36it/s]29697it [00:05, 16565.78it/s]31745it [00:05, 16792.35it/s]33793it [00:05, 17111.93it/s]35841it [00:05, 16549.17it/s]37889it [00:05, 16750.61it/s]39937it [00:05, 17014.54it/s]41985it [00:06, 17281.39it/s]44033it [00:06, 17326.70it/s]46081it [00:06, 17507.21it/s]48129it [00:06, 17386.46it/s]50177it [00:06, 17525.88it/s]52225it [00:06, 17358.00it/s]54273it [00:06, 17523.57it/s]56678it [00:06, 8208.30it/s] 
I1125 10:12:49.650168 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101249b2c8dc0b0ae9915ctarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_24.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-16-906848-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-16-906848-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147d17820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:12:54.421240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:54.421460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:54.421573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:54.421747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:54.421859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:12:54.421947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:12:54.493137: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:54.493312: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:12:54.813375: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:12:54.813526: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.55s/it]2049it [00:03, 781.92it/s]4097it [00:03, 1765.52it/s]6145it [00:03, 2956.48it/s]8193it [00:04, 4343.36it/s]10241it [00:04, 5838.17it/s]12289it [00:04, 7410.42it/s]14337it [00:04, 8817.96it/s]16385it [00:04, 10433.25it/s]18433it [00:04, 11917.16it/s]20481it [00:04, 13229.04it/s]22529it [00:04, 14357.48it/s]24577it [00:05, 15099.44it/s]26625it [00:05, 15590.62it/s]28673it [00:05, 16106.51it/s]30721it [00:05, 16467.24it/s]32769it [00:05, 16264.87it/s]34817it [00:05, 16496.55it/s]36865it [00:05, 16660.27it/s]38913it [00:05, 17025.81it/s]40961it [00:06, 17334.01it/s]43009it [00:06, 18029.18it/s]45057it [00:06, 17773.76it/s]47105it [00:06, 17902.14it/s]49153it [00:06, 17824.04it/s]51201it [00:06, 17803.26it/s]53249it [00:06, 17510.25it/s]55297it [00:06, 17222.48it/s]56678it [00:06, 8199.80it/s] 
I1125 10:13:01.309847 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112510130171c7dc0b0ae9843dtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_25.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-08-453424-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-08-453424-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a447b730> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:13:06.035617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:06.175201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:06.175356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:06.175520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:06.175605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:06.175678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:13:06.233956: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:06.234123: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:06.347897: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:13:06.348041: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.60s/it]2049it [00:03, 767.99it/s]4097it [00:03, 1749.29it/s]6145it [00:04, 2911.81it/s]8193it [00:04, 4305.53it/s]10241it [00:04, 5733.77it/s]12289it [00:04, 7252.02it/s]14337it [00:04, 8550.70it/s]16385it [00:04, 9962.00it/s]18433it [00:04, 11383.89it/s]20481it [00:04, 12916.98it/s]22529it [00:05, 13523.25it/s]24577it [00:05, 14159.00it/s]26625it [00:05, 14351.78it/s]28673it [00:05, 14526.84it/s]30721it [00:05, 14504.15it/s]32769it [00:05, 15027.03it/s]34817it [00:05, 15651.32it/s]36865it [00:05, 16207.96it/s]38913it [00:06, 16638.31it/s]40961it [00:06, 16906.50it/s]43009it [00:06, 17217.20it/s]45057it [00:06, 17205.79it/s]47105it [00:06, 17295.86it/s]49153it [00:06, 17205.91it/s]51201it [00:06, 17321.20it/s]53249it [00:06, 17347.63it/s]55297it [00:07, 17392.47it/s]56678it [00:07, 7997.97it/s] 
I1125 10:13:12.948976 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101312d3334a1a0434015atarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_26.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-02-113356-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-02-113356-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147cfc730> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:13:17.555974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:17.642700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:17.642934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:17.643098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:17.643214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:17.643312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:13:17.701968: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:17.702099: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:17.801803: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:13:17.801927: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.37s/it]2049it [00:03, 819.30it/s]4097it [00:03, 1853.14it/s]6145it [00:03, 3083.09it/s]8193it [00:03, 4468.70it/s]10241it [00:04, 5951.47it/s]12289it [00:04, 7427.05it/s]14337it [00:04, 8706.06it/s]16385it [00:04, 10172.41it/s]18433it [00:04, 11701.33it/s]20481it [00:04, 13023.82it/s]22529it [00:04, 14127.95it/s]24577it [00:04, 14864.24it/s]26625it [00:05, 15407.94it/s]28673it [00:05, 16015.04it/s]30721it [00:05, 16401.45it/s]32769it [00:05, 16537.84it/s]34817it [00:05, 16500.04it/s]36865it [00:05, 16277.92it/s]38913it [00:05, 16683.24it/s]40961it [00:05, 17251.74it/s]43009it [00:06, 17914.45it/s]45057it [00:06, 17681.01it/s]47105it [00:06, 17791.72it/s]49153it [00:06, 17945.69it/s]51201it [00:06, 18030.16it/s]53249it [00:06, 18100.39it/s]55297it [00:06, 17898.32it/s]56678it [00:06, 8374.73it/s] 
I1125 10:13:24.135400 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101324c8c7dc0b0ae9c9a4target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_27.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-24-1360272-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-24-1360272-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147c9ac10> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:13:28.810762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:29.033448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:29.033610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:29.033755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:29.033837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:29.033913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:13:29.096947: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:29.097108: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:29.199008: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:13:29.199168: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.55s/it]2049it [00:03, 778.53it/s]4097it [00:03, 1770.86it/s]6145it [00:03, 2957.76it/s]8193it [00:04, 4297.54it/s]10241it [00:04, 5731.44it/s]12289it [00:04, 7197.25it/s]14337it [00:04, 8672.87it/s]16385it [00:04, 10036.29it/s]18433it [00:04, 11381.48it/s]20481it [00:04, 12681.60it/s]22529it [00:05, 13733.36it/s]24577it [00:05, 14672.01it/s]26625it [00:05, 15341.63it/s]28673it [00:05, 15567.65it/s]30721it [00:05, 15895.12it/s]32769it [00:05, 15934.28it/s]34817it [00:05, 16111.47it/s]36865it [00:05, 16534.66it/s]38913it [00:06, 16808.81it/s]40961it [00:06, 17141.51it/s]43009it [00:06, 17207.83it/s]45057it [00:06, 17348.36it/s]47105it [00:06, 17490.49it/s]49153it [00:06, 17679.52it/s]51201it [00:06, 17380.50it/s]53249it [00:06, 17398.70it/s]55297it [00:06, 17280.69it/s]56678it [00:06, 8102.86it/s] 
I1125 10:13:35.834319 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101335da334a1a0a90cd2ftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_28.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-15-850170-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-15-850170-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a41b6670> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:13:40.306883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:40.455481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:40.455618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:40.455748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:40.455831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:40.455904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:13:40.521918: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:40.522049: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:40.603872: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:13:40.604012: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.24s/it]2049it [00:03, 852.16it/s]4097it [00:03, 1902.49it/s]6145it [00:03, 3151.52it/s]8193it [00:03, 4610.76it/s]10241it [00:03, 6088.15it/s]12289it [00:04, 7704.78it/s]14337it [00:04, 9074.97it/s]16385it [00:04, 10555.88it/s]18433it [00:04, 11824.33it/s]20481it [00:04, 13213.87it/s]22529it [00:04, 13801.74it/s]24577it [00:04, 14842.87it/s]26625it [00:04, 14975.16it/s]28673it [00:05, 14736.61it/s]30721it [00:05, 15314.82it/s]32769it [00:05, 15978.72it/s]34817it [00:05, 15675.48it/s]36865it [00:05, 15911.42it/s]38913it [00:05, 16168.38it/s]40961it [00:05, 16163.85it/s]43009it [00:05, 16340.85it/s]45057it [00:06, 16053.94it/s]47105it [00:06, 16626.95it/s]49153it [00:06, 16803.73it/s]51201it [00:06, 16334.39it/s]53249it [00:06, 16503.91it/s]55297it [00:06, 16748.19it/s]56678it [00:06, 8383.30it/s] 
I1125 10:13:46.981057 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101346d4334a1a0a916d74target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_29.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-07-396746-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-07-396746-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa0a41a91f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:13:51.477827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:51.478072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:51.478188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:51.478346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:51.478454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:13:51.478527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:13:51.530274: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:51.530382: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:13:51.614033: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:13:51.614174: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.22s/it]2049it [00:03, 857.32it/s]4097it [00:03, 1929.09it/s]6145it [00:03, 3197.63it/s]8193it [00:03, 4654.82it/s]10241it [00:03, 6240.55it/s]12289it [00:04, 7757.00it/s]14337it [00:04, 9304.08it/s]16385it [00:04, 10744.71it/s]18433it [00:04, 12297.12it/s]20481it [00:04, 13680.01it/s]22529it [00:04, 14717.06it/s]24577it [00:04, 15602.48it/s]26625it [00:04, 16140.96it/s]28673it [00:04, 16654.66it/s]30721it [00:05, 16677.16it/s]32769it [00:05, 17061.48it/s]34817it [00:05, 17267.21it/s]36865it [00:05, 17558.17it/s]38913it [00:05, 17782.38it/s]40961it [00:05, 17905.51it/s]43009it [00:05, 17925.15it/s]45057it [00:05, 17293.67it/s]47105it [00:06, 16995.38it/s]49153it [00:06, 17121.25it/s]51201it [00:06, 17434.20it/s]53249it [00:06, 17532.24it/s]55297it [00:06, 17448.73it/s]56678it [00:06, 8671.74it/s] 
I1125 10:13:58.049636 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511251013570fa9fe0a0a91c223target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_30.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-22-1246916-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-22-1246916-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147cdef40> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:14:02.606293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:02.606551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:02.606666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:02.606829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:02.606945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:02.607047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:14:02.666065: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:14:02.666178: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:14:02.749637: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-25 10:14:02.749898: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.02s/it]2049it [00:03, 911.67it/s]4097it [00:03, 2037.90it/s]6145it [00:03, 3375.56it/s]8193it [00:03, 4874.19it/s]10241it [00:03, 6433.51it/s]12289it [00:03, 8011.10it/s]14337it [00:03, 9407.62it/s]16385it [00:04, 10823.37it/s]18433it [00:04, 12245.67it/s]20481it [00:04, 13477.95it/s]22529it [00:04, 13950.61it/s]24577it [00:04, 14935.85it/s]26625it [00:04, 15325.25it/s]28673it [00:04, 15823.21it/s]30721it [00:04, 16249.97it/s]32769it [00:05, 16748.94it/s]34817it [00:05, 16981.79it/s]36865it [00:05, 16934.56it/s]38913it [00:05, 17113.14it/s]40961it [00:05, 17477.66it/s]43009it [00:05, 17550.84it/s]45057it [00:05, 17242.01it/s]47105it [00:05, 17316.83it/s]49153it [00:05, 17595.31it/s]51201it [00:06, 17902.12it/s]53249it [00:06, 17826.74it/s]55297it [00:06, 17564.89it/s]56678it [00:06, 8858.31it/s] 
I1125 10:14:09.131221 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101409dda3cc0b0ae96df1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511240000_31.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251124/part-r-23-1303594-56678.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251124/part-r-23-1303594-56678.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa14acbe0a0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['1'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa147dcdd00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-25 10:14:13.637003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:13.637173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:13.637249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:13.637374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:13.637450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-25 10:14:13.637514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 1, name: NVIDIA L20, pci bus id: 0000:00:04.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511230000/model.ckpt-64904
2025-11-25 10:14:13.691611: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:14:13.691741: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-25 10:14:13.768401: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-25 10:14:13.768524: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.89s/it]2049it [00:03, 946.69it/s]4097it [00:03, 2103.44it/s]6145it [00:03, 3438.76it/s]8193it [00:03, 4916.90it/s]10241it [00:03, 6445.89it/s]12289it [00:03, 8013.41it/s]14337it [00:03, 9453.67it/s]16385it [00:03, 11031.94it/s]18433it [00:04, 12450.31it/s]20481it [00:04, 13508.30it/s]22529it [00:04, 14577.60it/s]24577it [00:04, 15283.06it/s]26625it [00:04, 15873.93it/s]28673it [00:04, 16385.35it/s]30721it [00:04, 16363.08it/s]32769it [00:04, 16577.01it/s]34817it [00:05, 16852.79it/s]36865it [00:05, 17231.41it/s]38913it [00:05, 17510.56it/s]40961it [00:05, 17523.64it/s]43009it [00:05, 17343.20it/s]45057it [00:05, 17049.24it/s]47105it [00:05, 17028.63it/s]49153it [00:05, 17074.09it/s]51201it [00:06, 17088.36it/s]53249it [00:06, 17216.23it/s]55297it [00:06, 17197.24it/s]56678it [00:06, 8989.11it/s] 
I1125 10:14:20.075836 140331925182272 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251125101419c756381a0a9103a2target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824'>
INFO:tensorflow:mode: infer device: GPU task_type: chief task_idx: 0 time_str: 202511240000 end_time_str: None waste: 5.97 mins
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511240000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251125100824
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
----------------------------clear history data--------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
seq_idxs=[]
(Namespace(curr_date='20251124', data_path='/data/share/opt/data', del_date=None), [])
---------del_path=/data/share/opt/data/O35_mutil_cvr/20251025--------
Traceback (most recent call last):
  File "/opt/huangmian/yoyo_model/common/clear_history_data.py", line 31, in <module>
    del_path = os.path.join(args.data_path, data_nm, args.del_date)
  File "/root/anaconda3/envs/env_gpu/lib/python3.8/posixpath.py", line 90, in join
    genericpath._check_arg_types('join', a, *p)
  File "/root/anaconda3/envs/env_gpu/lib/python3.8/genericpath.py", line 152, in _check_arg_types
    raise TypeError(f'{funcname}() argument must be str, bytes, or '
TypeError: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
