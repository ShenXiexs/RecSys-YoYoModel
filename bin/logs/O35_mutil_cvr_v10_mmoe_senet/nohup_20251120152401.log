code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
--> time_str: 202511190000, end_date: 202511190000
---------------------------------main-train-------------------------------------
---------------------------------export.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
---------------------------------main-export-------------------------------------
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-20 15:25:52.464536: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-20 15:25:52.464560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-20 15:25:52.464572: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-20 15:25:52.464655: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-20 15:25:52.464669: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-20 15:25:52.464672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:Using CPU for training
INFO:tensorflow:time_str=20251119, end_time_str=20251119
INFO:tensorflow:train_date={'20251119': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-31-1981613-25.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-23-1470229-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-20-1278460-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-01-63923-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-26-1661998-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-22-1406306-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-14-894922-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-04-255692-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-05-319615-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-07-447461-63923.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511190000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 0
}
intra_op_parallelism_threads: 16
inter_op_parallelism_threads: 16
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: CPU
INFO:tensorflow:Batch sizes - Train: 5120, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 5120, 'train_epoch': 1, 'batch_size': 1024}
defalut feature:Tensor("StringJoin:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_1:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_2:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_3:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_4:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_5:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_6:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_7:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_8:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_9:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_10:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_11:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_12:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_13:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_14:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_15:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_16:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_17:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_18:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_19:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_20:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_21:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_22:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_23:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_24:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_25:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_26:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_27:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_28:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_29:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_30:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_31:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_32:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_33:0", shape=(None,), dtype=string)
feature:user__imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_34:0", shape=(None,), dtype=string)
feature:user__clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_35:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_36:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_37:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_38:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_39:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_40:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_41:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_42:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_43:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_44:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_45:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_46:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_47:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_48:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_49:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_50:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_51:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_52:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_53:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_54:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_55:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_56:0", shape=(None,), dtype=string)
feature:user__imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_57:0", shape=(None,), dtype=string)
feature:user__clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_58:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_59:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_60:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_61:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_62:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_63:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_64:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_65:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_66:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_67:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_68:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_69:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_70:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_71:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_72:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_73:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_74:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_75:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_76:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_77:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_78:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_79:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_80:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_81:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_82:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_83:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_84:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_85:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_86:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_87:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_88:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_89:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_90:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_91:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_92:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_93:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_94:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_95:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_96:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_97:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_98:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_99:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_100:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_101:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_102:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_103:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_104:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_105:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_106:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_107:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_108:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_109:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_110:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_111:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_112:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_113:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_114:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_115:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_116:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_117:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_118:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_119:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_120:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_121:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_122:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_123:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_124:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_125:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_126:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_127:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_128:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_129:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_130:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_131:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_132:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_133:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_134:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_135:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_136:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_137:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_138:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_139:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_140:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_141:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_142:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_143:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_144:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_145:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_146:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_147:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_148:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_149:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_150:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_151:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_152:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_153:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_154:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_155:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_156:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_157:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_158:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_159:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_160:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_161:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_162:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_163:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_164:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_165:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_166:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_167:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_168:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_169:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_170:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_171:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_172:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_173:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_174:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_175:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_176:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_177:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_178:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_179:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_180:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_181:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_182:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_183:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_184:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_185:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_186:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_187:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_188:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_189:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_190:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_191:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_192:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_193:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_194:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_195:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_196:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_197:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_198:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_199:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_200:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_201:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_202:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_203:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_204:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_205:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_206:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_207:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_208:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_209:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_210:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_211:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_212:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_213:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_214:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_215:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_216:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_217:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_218:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_219:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_220:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_221:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_222:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_223:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_224:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_225:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_226:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_227:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_228:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_229:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_230:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_231:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_232:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_233:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_234:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_235:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_236:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_237:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_238:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_239:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_240:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_241:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_242:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_243:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_244:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_245:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_246:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_247:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_248:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_249:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_250:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_251:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_252:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_253:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_254:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_255:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_256:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_257:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_258:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_259:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_260:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_261:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_262:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_263:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_264:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_265:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_266:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_267:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_268:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_269:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_270:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_271:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_272:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_273:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_274:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_275:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_276:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_277:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_278:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_279:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_280:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_281:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_282:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_283:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_284:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_285:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_286:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_287:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_288:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_289:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_290:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_291:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_292:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_293:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_294:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_295:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_296:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_297:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_298:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_299:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_300:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_301:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_302:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_303:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_304:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_305:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_306:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_307:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_308:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_309:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_310:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_311:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_312:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_313:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_314:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_315:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_316:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_317:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_318:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_319:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_320:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_321:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_322:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_323:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_324:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_325:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_326:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_327:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_328:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_329:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_330:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_331:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_332:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_333:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_334:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_335:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_336:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_337:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_338:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_339:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_340:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_341:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_342:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_343:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_344:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_345:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_346:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_347:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_348:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_349:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_350:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_351:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_352:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_353:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_354:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_355:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_356:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_357:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_358:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_359:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_360:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_361:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_362:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_363:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_364:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_365:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_366:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_367:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_368:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_369:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_370:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_371:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_372:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_373:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_374:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_375:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_376:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_377:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_378:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_379:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_380:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_381:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_382:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_383:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_384:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_385:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_386:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_387:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_388:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_389:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_390:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_391:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_392:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_393:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_394:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_395:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_396:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_397:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_398:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_399:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_400:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_401:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_402:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_403:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_404:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_405:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_406:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_407:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_408:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_409:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_410:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_411:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_412:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_413:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_414:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_415:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_416:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_417:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_418:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_419:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_420:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_421:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_422:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_423:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_424:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_425:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_426:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_427:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_428:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_429:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_430:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_431:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_432:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_433:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_434:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_435:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_436:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_437:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_438:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_439:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_440:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_441:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_442:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_443:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_444:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_445:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_446:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_447:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_448:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_449:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_450:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_451:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_452:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_453:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_454:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_455:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_456:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_457:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_458:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_459:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_460:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_461:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_462:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_463:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_464:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_465:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_466:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_467:0", shape=(None,), dtype=string)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f1c5faddd00> -------
INFO:tensorflow:------ features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'export', 'ps_num': 0, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'CPU', 'gpu_ids': [], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is /job:localhost/replica:0/task:0/CPU:0 -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f1c5fa6c130> emb_lookuped: Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_1331:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1331:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("ctr_tower/zeros:0", shape=(None,), dtype=float32), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1331:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("awake_tower/zeros:0", shape=(None,), dtype=float32), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("mmoe_tower/zeros:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("mmoe_tower/zeros_1:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("mmoe_tower/zeros_2:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
2025-11-20 15:25:55.754596: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511190000/model.ckpt-62245
2025-11-20 15:25:56.018970: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:25:56.019199: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/export_dir/temp-1763623552/saved_model.pb
INFO:tensorflow:mode: export device: CPU task_type: chief task_idx: 0 time_str: 202511190000 end_time_str: None waste: 0.07 mins
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_468:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_469:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_470:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_471:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_472:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_473:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_474:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_475:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_476:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_477:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_478:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_479:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_480:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_481:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_482:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_483:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_484:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_485:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_486:0", shape=(None,), dtype=string)
features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} tensors: 487
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
-------------------------------generate_body---------------------------------------
(Namespace(day='20251119'), [])
[INFO/MainProcess] process shutting down
==================warmup.py:  export_dir:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/export_dir ====================
2025-11-20 15:26:00.080827: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-20 15:26:00.080855: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-20 15:26:00.080859: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-20 15:26:00.080931: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-20 15:26:00.080944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-20 15:26:00.080947: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
model_dir:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/export_dir
body_file:/opt/huangmian/yoyo_model/config/O35_mutil_cvr_v10_mmoe_senet/body.json
files: [1763552958, 1763553175, 1763553610, 1763554105, 1763554575, 1763555049, 1763555486, 1763555884, 1763556238, 1763556734, 1763558089, 1763558781, 1763559092, 1763559385, 1763559577, 1763559780, 1763559988, 1763560304, 1763560585, 1763560866, 1763561170, 1763561664, 1763562408, 1763563095, 1763563590, 1763564219, 1763564598, 1763564928, 1763565253, 1763565599, 1763565828, 1763566140, 1763566423, 1763566707, 1763566994, 1763567276, 1763567589, 1763567868, 1763568199, 1763568554, 1763568851, 1763569122, 1763569373, 1763569545, 1763570024, 1763570573, 1763570927, 1763571345, 1763571837, 1763572292, 1763572907, 1763573434, 1763573902, 1763574311, 1763574726, 1763575080, 1763575483, 1763575818, 1763576134, 1763576418, 1763576712, 1763577069, 1763577386, 1763577711, 1763578025, 1763578219, 1763578509, 1763578835, 1763579141, 1763579401, 1763579592, 1763579859, 1763580092, 1763580233, 1763580327, 1763580387, 1763580487, 1763580593, 1763580710, 1763623195, 1763623552]
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
eval data:202511190000
---------------------------------eval.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
---------------------------------main-eval-------------------------------------
---------------------------------save_eval_metric------------------------------------
(Namespace(dm_date='202511190000', eval_path='/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/eval', model_version='O35_mutil_cvr_v10_mmoe_senet'), [])
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
infer data:202511190000
---------------------------------infer.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
---------------------------------main-infer-------------------------------------
ckpt_dir=/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000, time_str=202511190000
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-20 15:27:42.360224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:42.360361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:42.366011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:42.366136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:42.366215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:42.366291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:time_str=20251119, end_time_str=20251119
INFO:tensorflow:train_date={'20251119': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-20-1278460-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-07-447461-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-17-1086691-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-19-1214537-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-31-1981613-25.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-28-1789844-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-10-639230-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-01-63923-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-05-319615-63923.gz', '/data/share/opt/data/O35_mutil_cvr/20251119/part-r-29-1853767-63923.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 2
}
intra_op_parallelism_threads: 8
inter_op_parallelism_threads: 8
gpu_options {
  per_process_gpu_memory_fraction: 0.9
  allow_growth: true
  visible_device_list: "0"
}
allow_soft_placement: true
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: GPU
INFO:tensorflow:Using GPUs: 0
INFO:tensorflow:Batch sizes - Train: 5120, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 5120, 'train_epoch': 1, 'batch_size': 1024}
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_0.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-20-1278460-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-20-1278460-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d2a23a0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:27:43.710166: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-20 15:27:43.710656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:43.710828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:43.710904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:44.074033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:44.074174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:44.074259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:44.074345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:27:44.125478: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:27:44.125580: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:27:44.219434: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:27:44.220103: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2025-11-20 15:27:46.289541: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1it [00:03,  3.90s/it]2049it [00:04, 718.76it/s]4097it [00:04, 1648.97it/s]6145it [00:04, 2806.44it/s]8193it [00:04, 4206.84it/s]10241it [00:04, 5870.76it/s]13017it [00:04, 8687.10it/s]15361it [00:04, 10402.43it/s]18059it [00:04, 13281.46it/s]20481it [00:04, 14422.02it/s]23313it [00:05, 17333.03it/s]25612it [00:05, 17167.34it/s]28175it [00:05, 19135.59it/s]30721it [00:05, 18914.62it/s]33225it [00:05, 20417.91it/s]35841it [00:05, 19876.34it/s]38356it [00:05, 21203.75it/s]40938it [00:05, 22424.42it/s]43285it [00:06, 20577.29it/s]46081it [00:06, 20755.42it/s]49153it [00:06, 21382.31it/s]52225it [00:06, 21808.38it/s]55297it [00:06, 22041.45it/s]58369it [00:06, 22262.37it/s]61441it [00:06, 22419.57it/s]63923it [00:06, 9238.76it/s] 
I1120 15:27:52.100035 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112015275230f3da0b091d0c24target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_1.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-07-447461-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-07-447461-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4afb3310> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:27:56.953241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:56.953428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:56.953508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:56.953624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:56.953701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:27:56.953765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:27:56.997784: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:27:56.997891: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:27:57.067046: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:27:57.067194: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.68s/it]2049it [00:02, 1027.08it/s]4097it [00:02, 2297.84it/s]6145it [00:03, 3785.28it/s]8193it [00:03, 5497.02it/s]10241it [00:03, 7314.20it/s]12289it [00:03, 9096.78it/s]14337it [00:03, 10848.14it/s]16385it [00:03, 12258.05it/s]18433it [00:03, 13436.09it/s]20481it [00:03, 14938.67it/s]22861it [00:03, 17094.85it/s]25325it [00:04, 19041.19it/s]27610it [00:04, 20066.73it/s]29781it [00:04, 18515.95it/s]32034it [00:04, 19573.82it/s]34364it [00:04, 20593.07it/s]36682it [00:04, 21319.69it/s]38913it [00:04, 19295.89it/s]41222it [00:04, 20310.97it/s]43771it [00:04, 21743.16it/s]46081it [00:05, 19967.16it/s]48668it [00:05, 21545.71it/s]51201it [00:05, 20446.34it/s]53999it [00:05, 22429.72it/s]56321it [00:05, 20606.85it/s]59051it [00:05, 22360.98it/s]61362it [00:05, 22534.17it/s]63670it [00:05, 21916.11it/s]63923it [00:05, 10868.82it/s]
I1120 15:28:03.122909 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511201528038657381a08d313c8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_2.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-17-1086691-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-17-1086691-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbee3a0a730> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:28:07.764394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:07.764543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:07.764621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:07.764734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:07.764812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:07.764876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:28:07.808733: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:07.808836: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:08.055999: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:28:08.056138: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.84s/it]2049it [00:02, 978.12it/s]4097it [00:03, 2205.68it/s]6145it [00:03, 3674.17it/s]8193it [00:03, 5368.93it/s]10241it [00:03, 7214.75it/s]12289it [00:03, 9063.71it/s]14337it [00:03, 10689.78it/s]16385it [00:03, 12286.08it/s]18433it [00:03, 13667.04it/s]20481it [00:03, 15085.97it/s]23040it [00:04, 17661.21it/s]25589it [00:04, 19691.71it/s]27793it [00:04, 18532.20it/s]30350it [00:04, 20364.62it/s]32769it [00:04, 19394.52it/s]35279it [00:04, 20876.72it/s]37792it [00:04, 22027.58it/s]40081it [00:04, 20107.50it/s]42432it [00:04, 21007.43it/s]45057it [00:05, 20428.09it/s]48128it [00:05, 23130.50it/s]50520it [00:05, 21120.84it/s]53249it [00:05, 20823.34it/s]55569it [00:05, 21427.75it/s]58252it [00:05, 22867.54it/s]60593it [00:05, 20949.67it/s]62911it [00:05, 21537.99it/s]63923it [00:05, 10712.93it/s]
I1120 15:28:13.956371 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511201528131c344a1a08d3a9b0target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_3.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-19-1214537-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-19-1214537-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d2a2820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:28:18.774859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:18.775018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:18.775094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:18.775208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:18.775283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:18.775346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:28:18.818351: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:18.818450: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:18.885834: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:28:18.885960: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.78s/it]2049it [00:02, 993.21it/s]4097it [00:03, 2232.72it/s]6145it [00:03, 3710.72it/s]8193it [00:03, 5381.49it/s]10241it [00:03, 7148.70it/s]12289it [00:03, 8856.39it/s]14337it [00:03, 10521.12it/s]16385it [00:03, 12285.30it/s]18433it [00:03, 13550.77it/s]20481it [00:03, 14841.59it/s]22545it [00:04, 16245.63it/s]24656it [00:04, 17495.70it/s]27031it [00:04, 19175.26it/s]29441it [00:04, 20540.47it/s]31686it [00:04, 21081.66it/s]33883it [00:04, 19167.47it/s]36089it [00:04, 19948.31it/s]38280it [00:04, 20494.17it/s]40455it [00:04, 20851.36it/s]42704it [00:04, 21324.67it/s]45057it [00:05, 19804.42it/s]47124it [00:05, 20040.53it/s]49879it [00:05, 22149.70it/s]52225it [00:05, 20496.76it/s]54630it [00:05, 21460.30it/s]56823it [00:05, 21500.26it/s]59278it [00:05, 22366.62it/s]61543it [00:05, 19967.20it/s]63923it [00:05, 10671.48it/s]
I1120 15:28:25.053009 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152824a2eedc0b091d2e33target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_4.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-31-1981613-25.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-31-1981613-25.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4b195e20> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:28:29.434862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:29.435019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:29.435096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:29.435224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:29.435301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:29.435365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:28:29.478228: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:29.478336: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:29.545788: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:28:29.545915: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:01,  1.59s/it]25it [00:01, 15.49it/s]
I1120 15:28:31.369086 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152831d8e8da0b091d411ftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_5.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-28-1789844-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-28-1789844-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbdfa7a7d00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:28:34.823509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:34.823667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:34.823744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:34.823858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:34.823934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:34.824008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:28:34.867784: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:34.867885: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:34.935256: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:28:34.935406: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.79s/it]2049it [00:02, 993.60it/s]4097it [00:03, 2227.68it/s]6145it [00:03, 3729.30it/s]8193it [00:03, 5432.59it/s]10241it [00:03, 7194.55it/s]12289it [00:03, 9105.96it/s]14337it [00:03, 10796.45it/s]16385it [00:03, 12350.36it/s]18433it [00:03, 13526.42it/s]20929it [00:03, 16130.38it/s]23392it [00:04, 18216.68it/s]25601it [00:04, 17506.11it/s]28145it [00:04, 19508.98it/s]30721it [00:04, 19181.13it/s]33090it [00:04, 20332.98it/s]35353it [00:04, 20947.00it/s]37833it [00:04, 22011.82it/s]40105it [00:04, 20082.92it/s]42642it [00:04, 21498.06it/s]45057it [00:05, 20159.72it/s]47863it [00:05, 22243.71it/s]50177it [00:05, 20715.28it/s]53034it [00:05, 22794.89it/s]55389it [00:05, 20974.37it/s]58369it [00:05, 21207.21it/s]60794it [00:05, 21982.96it/s]63489it [00:05, 22560.42it/s]63923it [00:05, 10807.89it/s]
I1120 15:28:41.100846 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152841e7c7dc0b091cea87target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_6.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-10-639230-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-10-639230-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d306700> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:28:45.807557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:45.807737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:45.807818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:45.807933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:45.808010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:45.808074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:28:45.851675: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:45.851794: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:45.919650: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:28:45.919782: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.70s/it]2049it [00:02, 1019.85it/s]4097it [00:02, 2284.45it/s]6145it [00:03, 3777.66it/s]8193it [00:03, 5441.24it/s]10241it [00:03, 7290.47it/s]12289it [00:03, 9064.21it/s]14337it [00:03, 10735.67it/s]16385it [00:03, 12281.03it/s]18433it [00:03, 13775.96it/s]20991it [00:03, 16502.60it/s]23541it [00:03, 18734.36it/s]25715it [00:04, 17774.29it/s]28153it [00:04, 19451.66it/s]30536it [00:04, 20616.87it/s]32769it [00:04, 19112.49it/s]35315it [00:04, 20781.15it/s]37795it [00:04, 21877.93it/s]40069it [00:04, 19721.25it/s]42266it [00:04, 20312.75it/s]44983it [00:04, 22186.62it/s]47273it [00:05, 20390.44it/s]49942it [00:05, 22075.40it/s]52225it [00:05, 20201.86it/s]54846it [00:05, 21785.89it/s]57345it [00:05, 20544.37it/s]60181it [00:05, 22589.11it/s]62517it [00:05, 20672.49it/s]63923it [00:05, 10896.15it/s]
I1120 15:28:52.039378 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511201528519c334a1a08d3836etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_7.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-01-63923-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-01-63923-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4af4e7f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:28:56.703368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:56.703551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:56.703629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:56.703743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:56.703819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:28:56.703883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:28:56.747498: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:56.747611: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:28:56.815633: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:28:56.815793: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.66s/it]2049it [00:02, 1033.20it/s]4097it [00:02, 2326.91it/s]6145it [00:03, 3857.79it/s]8193it [00:03, 5546.87it/s]10241it [00:03, 7354.88it/s]12289it [00:03, 9111.82it/s]14337it [00:03, 10838.65it/s]16385it [00:03, 12279.75it/s]18433it [00:03, 13446.77it/s]20481it [00:03, 14958.12it/s]23007it [00:03, 17467.76it/s]25279it [00:04, 18823.38it/s]27498it [00:04, 19730.14it/s]29693it [00:04, 20346.93it/s]31844it [00:04, 18469.20it/s]33909it [00:04, 19049.08it/s]36040it [00:04, 19671.50it/s]38280it [00:04, 20441.40it/s]40376it [00:04, 20543.24it/s]42544it [00:04, 20873.11it/s]44658it [00:04, 20944.50it/s]47105it [00:05, 19894.69it/s]49455it [00:05, 20890.43it/s]52225it [00:05, 20495.55it/s]54690it [00:05, 21602.03it/s]57156it [00:05, 22444.54it/s]59432it [00:05, 20454.30it/s]61527it [00:05, 20429.31it/s]63923it [00:05, 10884.37it/s]
I1120 15:29:02.970616 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152902c254381a08d3cafbtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_8.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-05-319615-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-05-319615-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d2bf790> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:29:07.737149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:07.737290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:07.737367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:07.737478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:07.737554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:07.737616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:29:07.781261: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:07.781360: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:07.849415: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:29:07.849529: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.67s/it]2049it [00:02, 1023.01it/s]4097it [00:02, 2285.50it/s]6145it [00:03, 3800.41it/s]8193it [00:03, 5488.05it/s]10241it [00:03, 7349.56it/s]12289it [00:03, 9183.73it/s]14337it [00:03, 10777.87it/s]16385it [00:03, 12153.44it/s]18433it [00:03, 13458.62it/s]20634it [00:03, 15398.61it/s]22775it [00:03, 16869.95it/s]24960it [00:04, 18159.99it/s]27224it [00:04, 19369.92it/s]29561it [00:04, 20483.32it/s]31727it [00:04, 20730.77it/s]33884it [00:04, 18747.92it/s]35866it [00:04, 19036.12it/s]38077it [00:04, 19889.14it/s]40121it [00:04, 20030.43it/s]42324it [00:04, 20606.88it/s]44922it [00:04, 22174.37it/s]47165it [00:05, 20155.88it/s]49643it [00:05, 21430.83it/s]52225it [00:05, 20323.97it/s]54558it [00:05, 21122.44it/s]57159it [00:05, 22466.92it/s]59450it [00:05, 20451.21it/s]61876it [00:05, 21469.04it/s]63923it [00:05, 10839.34it/s]
I1120 15:29:13.898467 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152913b2c8dc0b091d3a64target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_9.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-29-1853767-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-29-1853767-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ae02340> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:29:18.504994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:18.505155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:18.505232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:18.505350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:18.505428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:18.505505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:29:18.549529: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:18.549630: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:18.617212: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:29:18.617316: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.77s/it]2049it [00:02, 994.85it/s]4097it [00:03, 2238.71it/s]6145it [00:03, 3736.75it/s]8193it [00:03, 5470.32it/s]10241it [00:03, 7240.36it/s]12289it [00:03, 9037.73it/s]14337it [00:03, 10842.79it/s]16385it [00:03, 12212.80it/s]18433it [00:03, 13440.17it/s]20957it [00:03, 16114.35it/s]23286it [00:04, 17869.03it/s]25601it [00:04, 17499.01it/s]28067it [00:04, 19301.81it/s]30549it [00:04, 20761.12it/s]32772it [00:04, 19029.82it/s]35149it [00:04, 20264.47it/s]37542it [00:04, 21258.32it/s]39937it [00:04, 19775.65it/s]42395it [00:04, 21042.70it/s]44574it [00:05, 21207.03it/s]47105it [00:05, 20354.52it/s]49769it [00:05, 22035.03it/s]52159it [00:05, 22550.10it/s]54457it [00:05, 20383.85it/s]57108it [00:05, 22017.09it/s]59375it [00:05, 22189.26it/s]61641it [00:05, 20069.25it/s]63923it [00:05, 10751.11it/s]
I1120 15:29:24.772261 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112015292494973c0a08d3cb1ctarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_10.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-14-894922-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-14-894922-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbeafb91dc0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:29:29.218579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:29.218735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:29.218811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:29.218925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:29.219001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:29.219064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:29:29.262580: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:29.262677: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:29.330559: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:29:29.330709: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.67s/it]2049it [00:02, 1030.40it/s]4097it [00:02, 2315.00it/s]6145it [00:03, 3822.07it/s]8193it [00:03, 5582.18it/s]10241it [00:03, 7348.59it/s]12289it [00:03, 9181.11it/s]14337it [00:03, 10772.85it/s]16385it [00:03, 12062.96it/s]18433it [00:03, 13381.27it/s]20638it [00:03, 15339.23it/s]23010it [00:03, 17383.57it/s]25336it [00:04, 18901.85it/s]27649it [00:04, 18076.28it/s]29995it [00:04, 19464.27it/s]32109it [00:04, 19914.78it/s]34272it [00:04, 20390.77it/s]36519it [00:04, 20980.79it/s]38776it [00:04, 21439.32it/s]40961it [00:04, 19363.84it/s]43217it [00:04, 20234.70it/s]46081it [00:05, 20224.61it/s]48538it [00:05, 21370.52it/s]51037it [00:05, 22361.05it/s]53313it [00:05, 20341.35it/s]55866it [00:05, 21724.12it/s]58355it [00:05, 22596.90it/s]60662it [00:05, 20181.87it/s]63053it [00:05, 21165.39it/s]63923it [00:05, 10872.02it/s]
I1120 15:29:35.369364 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152935a0cfdc0b091d0ec9target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_11.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-03-191769-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-03-191769-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4b12ca00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:29:39.949054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:39.949195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:39.949272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:39.949383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:39.949465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:39.949527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:29:39.992472: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:39.992566: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:40.059904: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:29:40.060040: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.66s/it]2049it [00:02, 1036.05it/s]4097it [00:02, 2312.55it/s]6145it [00:03, 3824.93it/s]8193it [00:03, 5526.46it/s]10241it [00:03, 7310.81it/s]12289it [00:03, 9070.89it/s]14337it [00:03, 10779.51it/s]16385it [00:03, 12353.20it/s]18433it [00:03, 13452.10it/s]20694it [00:03, 15528.96it/s]22916it [00:03, 17166.01it/s]25264it [00:04, 18801.38it/s]27565it [00:04, 19937.94it/s]29721it [00:04, 18349.18it/s]32132it [00:04, 19867.22it/s]34400it [00:04, 20636.49it/s]36705it [00:04, 21314.40it/s]38913it [00:04, 19316.82it/s]41080it [00:04, 19948.32it/s]43416it [00:04, 20893.72it/s]45558it [00:05, 20880.71it/s]48129it [00:05, 19964.42it/s]50600it [00:05, 21238.91it/s]52768it [00:05, 21318.23it/s]55297it [00:05, 20240.48it/s]57659it [00:05, 21143.86it/s]60000it [00:05, 21770.04it/s]62403it [00:05, 22409.19it/s]63923it [00:05, 10871.46it/s]
I1120 15:29:46.115264 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152946c8c7dc0b091d5f02target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_12.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-06-383538-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-06-383538-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d3a6790> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:29:50.845751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:50.845901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:50.845986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:50.846102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:50.846179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:29:50.846244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:29:50.890511: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:50.890605: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:29:51.085155: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:29:51.085270: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.74s/it]2049it [00:02, 1006.63it/s]4097it [00:02, 2257.85it/s]6145it [00:03, 3738.80it/s]8193it [00:03, 5433.37it/s]10241it [00:03, 7162.44it/s]12289it [00:03, 8937.71it/s]14337it [00:03, 10685.11it/s]16385it [00:03, 12149.75it/s]18433it [00:03, 13548.85it/s]20756it [00:03, 15756.67it/s]23169it [00:04, 17814.03it/s]25601it [00:04, 17676.11it/s]27856it [00:04, 18902.61it/s]30218it [00:04, 20149.75it/s]32724it [00:04, 21495.62it/s]34980it [00:04, 19636.68it/s]37435it [00:04, 20943.10it/s]39858it [00:04, 21847.78it/s]42113it [00:04, 19834.63it/s]44806it [00:05, 21723.33it/s]47105it [00:05, 20084.48it/s]50094it [00:05, 22669.76it/s]52450it [00:05, 20391.68it/s]55062it [00:05, 21869.88it/s]57341it [00:05, 21995.88it/s]59606it [00:05, 20293.34it/s]61966it [00:05, 21171.10it/s]63923it [00:05, 10775.43it/s]
I1120 15:29:57.224537 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120152957c557381a08d3e752target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_13.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-15-958845-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-15-958845-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbeafa45f40> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:30:01.865979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:01.866161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:01.866238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:01.866352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:01.866427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:01.866491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:30:01.910176: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:01.910270: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:01.977867: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:30:01.978114: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.87s/it]2049it [00:02, 967.35it/s]4097it [00:03, 2190.11it/s]6145it [00:03, 3644.78it/s]8193it [00:03, 5301.67it/s]10241it [00:03, 7055.81it/s]12289it [00:03, 8884.81it/s]14337it [00:03, 10783.45it/s]16385it [00:03, 12372.86it/s]18433it [00:03, 13798.64it/s]20481it [00:03, 15291.07it/s]22912it [00:04, 17524.85it/s]25324it [00:04, 19248.22it/s]27493it [00:04, 19911.60it/s]29697it [00:04, 18480.88it/s]32036it [00:04, 19780.50it/s]34275it [00:04, 20496.09it/s]36652it [00:04, 21417.66it/s]38913it [00:04, 19538.89it/s]41279it [00:04, 20647.16it/s]43723it [00:05, 21699.73it/s]45949it [00:05, 21792.31it/s]48168it [00:05, 19789.01it/s]50207it [00:05, 19837.32it/s]52233it [00:05, 19749.94it/s]54896it [00:05, 21690.23it/s]57345it [00:05, 20389.70it/s]59427it [00:05, 20445.70it/s]61502it [00:05, 20528.88it/s]63923it [00:06, 10576.30it/s]
I1120 15:30:08.277111 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153008d7334a1a08d2ffd1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_14.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-16-1022768-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-16-1022768-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ac1a0d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:30:13.011653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:13.011814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:13.011892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:13.012007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:13.012083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:13.012146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:30:13.054978: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:13.055075: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:13.122309: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:30:13.122437: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.75s/it]2049it [00:02, 1000.61it/s]4097it [00:02, 2251.28it/s]6145it [00:03, 3764.05it/s]8193it [00:03, 5502.54it/s]10241it [00:03, 7287.53it/s]12289it [00:03, 9162.18it/s]14337it [00:03, 10893.95it/s]16385it [00:03, 12302.26it/s]18433it [00:03, 13683.28it/s]20481it [00:03, 15078.16it/s]22873it [00:03, 17244.98it/s]25223it [00:04, 18866.98it/s]27378it [00:04, 19591.80it/s]29697it [00:04, 18548.65it/s]31868it [00:04, 19382.41it/s]33959it [00:04, 19800.09it/s]36175it [00:04, 20463.19it/s]38504it [00:04, 21272.87it/s]40724it [00:04, 21541.59it/s]43009it [00:04, 19567.16it/s]45929it [00:05, 22187.98it/s]48216it [00:05, 20453.98it/s]50331it [00:05, 20479.44it/s]52902it [00:05, 21917.70it/s]55297it [00:05, 20303.11it/s]57384it [00:05, 20415.23it/s]60018it [00:05, 22047.16it/s]62266it [00:05, 22044.87it/s]63923it [00:05, 10762.55it/s]
I1120 15:30:19.375779 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153019b2973c0a08d3828atarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_15.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-12-767076-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-12-767076-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4af03be0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:30:23.852053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:23.852228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:23.852322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:23.852440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:23.852518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:23.852582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:30:23.896422: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:23.896531: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:23.964944: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:30:23.965080: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.54s/it]2049it [00:02, 1079.89it/s]4097it [00:02, 2420.51it/s]6145it [00:02, 3988.30it/s]8193it [00:03, 5742.57it/s]10241it [00:03, 7552.16it/s]12289it [00:03, 9469.27it/s]14337it [00:03, 11132.65it/s]16385it [00:03, 12483.90it/s]18433it [00:03, 13580.01it/s]21001it [00:03, 16344.35it/s]23504it [00:03, 18481.32it/s]25636it [00:03, 17450.01it/s]27763it [00:04, 18413.41it/s]30231it [00:04, 20072.97it/s]32694it [00:04, 21323.76it/s]34934it [00:04, 19504.57it/s]37369it [00:04, 20794.42it/s]39917it [00:04, 22085.42it/s]42199it [00:04, 20105.92it/s]45043it [00:04, 22329.31it/s]47361it [00:04, 20319.46it/s]49612it [00:05, 20893.04it/s]52167it [00:05, 22161.23it/s]54445it [00:05, 20210.91it/s]56537it [00:05, 20398.85it/s]58949it [00:05, 21422.76it/s]61441it [00:05, 20106.61it/s]63923it [00:05, 11177.62it/s]
I1120 15:30:29.829151 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112015302930f3da0b091d37c4target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_16.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-27-1725921-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-27-1725921-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4b01ce80> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:30:34.437760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:34.515522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:34.515608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:34.515729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:34.515811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:34.515886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:30:34.559456: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:34.559566: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:34.627011: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:30:34.627234: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.70s/it]2049it [00:02, 1025.10it/s]4097it [00:02, 2304.81it/s]6145it [00:03, 3824.82it/s]8193it [00:03, 5577.91it/s]10241it [00:03, 7305.86it/s]12289it [00:03, 9032.48it/s]14337it [00:03, 10705.64it/s]16385it [00:03, 12207.30it/s]18433it [00:03, 13435.58it/s]20935it [00:03, 16060.22it/s]23352it [00:03, 18043.21it/s]25601it [00:04, 17495.19it/s]28118it [00:04, 19429.78it/s]30677it [00:04, 21060.60it/s]32933it [00:04, 19490.69it/s]35462it [00:04, 21012.07it/s]37823it [00:04, 21720.24it/s]40078it [00:04, 19793.07it/s]42443it [00:04, 20816.13it/s]45057it [00:04, 20212.53it/s]47836it [00:05, 22202.21it/s]50177it [00:05, 20682.44it/s]52309it [00:05, 20810.18it/s]55278it [00:05, 23234.82it/s]57658it [00:05, 21225.55it/s]60182it [00:05, 22295.55it/s]62472it [00:05, 20426.06it/s]63923it [00:05, 10924.28it/s]
I1120 15:30:40.559958 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153040b1973c0a08d3de3btarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_17.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-02-127846-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-02-127846-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf48282100> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:30:45.240692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:45.240843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:45.240920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:45.241034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:45.241111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:45.241175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:30:45.285052: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:45.285158: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:45.353170: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:30:45.353280: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.83s/it]2049it [00:02, 979.71it/s]4097it [00:03, 2193.03it/s]6145it [00:03, 3638.59it/s]8193it [00:03, 5273.71it/s]10241it [00:03, 6996.13it/s]12289it [00:03, 8760.27it/s]14337it [00:03, 10453.67it/s]16385it [00:03, 12022.30it/s]18433it [00:03, 13315.88it/s]20674it [00:03, 15362.18it/s]22549it [00:04, 15939.59it/s]24582it [00:04, 17058.26it/s]26626it [00:04, 17960.44it/s]28882it [00:04, 19229.75it/s]31064it [00:04, 19962.07it/s]33169it [00:04, 20274.52it/s]35257it [00:04, 20438.18it/s]37373it [00:04, 20649.58it/s]39469it [00:04, 20638.18it/s]41614it [00:05, 20877.89it/s]43718it [00:05, 20898.09it/s]45881it [00:05, 21115.46it/s]48001it [00:05, 21021.21it/s]50109it [00:05, 20883.23it/s]52225it [00:05, 18923.66it/s]54273it [00:05, 19328.42it/s]56788it [00:05, 20976.24it/s]58917it [00:05, 20992.43it/s]61038it [00:05, 21027.31it/s]63405it [00:06, 21801.78it/s]63923it [00:06, 10484.77it/s]
I1120 15:30:51.570645 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153051dcc7dc0b091d58eatarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_18.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-30-1917690-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-30-1917690-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ac1a400> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:30:55.919217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:55.919380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:55.919473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:55.919589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:55.919665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:30:55.919729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:30:55.962805: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:55.962910: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:30:56.030616: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:30:56.030762: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.53s/it]2049it [00:02, 1086.11it/s]4097it [00:02, 2438.74it/s]6145it [00:02, 4039.80it/s]8193it [00:02, 5804.47it/s]10241it [00:03, 7652.56it/s]12289it [00:03, 9480.96it/s]14337it [00:03, 11240.00it/s]16385it [00:03, 12680.19it/s]18433it [00:03, 14188.63it/s]20960it [00:03, 16806.94it/s]23553it [00:03, 17427.15it/s]26331it [00:03, 19988.36it/s]28673it [00:04, 19056.03it/s]31316it [00:04, 20928.55it/s]33793it [00:04, 19892.57it/s]36035it [00:04, 20540.08it/s]38518it [00:04, 21689.31it/s]40961it [00:04, 20271.78it/s]43143it [00:04, 20678.63it/s]45783it [00:04, 22241.57it/s]48129it [00:04, 20714.64it/s]50947it [00:05, 22722.07it/s]53283it [00:05, 20698.70it/s]55448it [00:05, 20949.49it/s]57692it [00:05, 21357.00it/s]60417it [00:05, 20811.38it/s]63362it [00:05, 23112.48it/s]63923it [00:05, 11310.69it/s]
I1120 15:31:01.825987 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153101c8c7dc0b091d76a8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_19.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-26-1661998-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-26-1661998-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d675d90> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:31:06.128876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:06.129039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:06.129115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:06.129230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:06.129305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:06.129369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:31:06.172596: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:06.172701: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:06.240142: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:31:06.240256: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.57s/it]2049it [00:02, 1067.17it/s]4097it [00:02, 2383.11it/s]6145it [00:02, 3921.86it/s]8193it [00:03, 5693.58it/s]10241it [00:03, 7492.82it/s]12289it [00:03, 9255.39it/s]14337it [00:03, 11136.46it/s]16385it [00:03, 12808.99it/s]18433it [00:03, 13960.43it/s]20481it [00:03, 15318.90it/s]22869it [00:03, 17442.08it/s]25385it [00:03, 19461.12it/s]27649it [00:04, 18411.03it/s]29962it [00:04, 19639.51it/s]32327it [00:04, 20726.67it/s]34817it [00:04, 19733.13it/s]37263it [00:04, 20982.59it/s]39691it [00:04, 21886.40it/s]41984it [00:04, 22179.65it/s]44248it [00:04, 20046.61it/s]46747it [00:04, 21376.30it/s]49116it [00:05, 22018.32it/s]51367it [00:05, 20043.52it/s]54238it [00:05, 22369.82it/s]56547it [00:05, 20397.37it/s]58664it [00:05, 20598.18it/s]61117it [00:05, 21672.91it/s]63335it [00:05, 21787.12it/s]63923it [00:05, 11110.64it/s]
I1120 15:31:12.326448 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153112c5c7dc0b091d2f16target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_20.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-24-1534152-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-24-1534152-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ae25820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:31:16.763576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:16.772860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:16.772979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:16.773094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:16.773171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:16.773235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:31:16.817006: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:16.817111: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:16.885952: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:31:16.886092: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.66s/it]2049it [00:02, 1043.00it/s]4097it [00:02, 2343.62it/s]6145it [00:02, 3871.22it/s]8193it [00:03, 5527.37it/s]10241it [00:03, 7327.50it/s]12289it [00:03, 9152.48it/s]14337it [00:03, 10800.04it/s]16385it [00:03, 12077.66it/s]18433it [00:03, 13252.82it/s]20513it [00:03, 14944.58it/s]22893it [00:03, 17092.56it/s]25272it [00:04, 18815.71it/s]27582it [00:04, 19967.12it/s]29744it [00:04, 18407.10it/s]32212it [00:04, 20057.53it/s]34374it [00:04, 20483.93it/s]36791it [00:04, 21518.20it/s]39012it [00:04, 19501.48it/s]41448it [00:04, 20806.19it/s]43888it [00:04, 21802.17it/s]46127it [00:05, 19747.47it/s]48626it [00:05, 21147.28it/s]50889it [00:05, 21556.31it/s]53249it [00:05, 19521.96it/s]55901it [00:05, 21360.65it/s]58369it [00:05, 20048.28it/s]61002it [00:05, 21680.32it/s]63479it [00:05, 22516.25it/s]63923it [00:05, 10899.69it/s]
I1120 15:31:22.863972 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153122d7334a1a08d316d7target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_21.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-11-703153-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-11-703153-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ae106d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:31:27.245307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:27.245470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:27.245547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:27.245660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:27.245735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:27.245797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:31:27.288957: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:27.289046: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:27.356456: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:31:27.356577: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.69s/it]2049it [00:02, 1026.53it/s]4097it [00:02, 2296.16it/s]6145it [00:03, 3807.15it/s]8193it [00:03, 5494.30it/s]10241it [00:03, 7334.64it/s]12289it [00:03, 9124.29it/s]14337it [00:03, 10823.85it/s]16385it [00:03, 12361.89it/s]18433it [00:03, 13388.78it/s]20481it [00:03, 14795.01it/s]22882it [00:03, 17021.24it/s]25345it [00:04, 18973.39it/s]27635it [00:04, 20026.26it/s]29803it [00:04, 18432.55it/s]32119it [00:04, 19673.68it/s]34575it [00:04, 21006.26it/s]36865it [00:04, 19353.46it/s]39185it [00:04, 20371.47it/s]41611it [00:04, 21437.86it/s]43876it [00:04, 21778.77it/s]46101it [00:05, 19624.01it/s]48777it [00:05, 21539.27it/s]51002it [00:05, 21581.32it/s]53211it [00:05, 21428.32it/s]55389it [00:05, 19528.16it/s]57394it [00:05, 19658.90it/s]59855it [00:05, 21033.82it/s]62465it [00:05, 20369.60it/s]63923it [00:05, 10828.46it/s]
I1120 15:31:33.211543 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153133c8c7dc0b091d80b8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_22.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-09-575307-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-09-575307-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ae25730> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:31:37.577780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:37.577939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:37.578017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:37.578135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:37.578213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:37.578288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:31:37.622712: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:37.622823: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:37.690826: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:31:37.690955: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.82s/it]2049it [00:02, 980.23it/s]4097it [00:03, 2205.38it/s]6145it [00:03, 3674.82it/s]8193it [00:03, 5352.22it/s]10241it [00:03, 7110.68it/s]12289it [00:03, 8769.21it/s]14337it [00:03, 10415.06it/s]16385it [00:03, 11978.89it/s]18433it [00:03, 13560.36it/s]21131it [00:03, 16622.76it/s]23490it [00:04, 18335.30it/s]25631it [00:04, 17435.26it/s]28188it [00:04, 19491.33it/s]30721it [00:04, 19003.70it/s]33134it [00:04, 20310.93it/s]35702it [00:04, 21744.39it/s]37980it [00:04, 19887.75it/s]40469it [00:04, 21200.84it/s]42676it [00:04, 21359.96it/s]45002it [00:05, 21891.19it/s]47239it [00:05, 19523.65it/s]50177it [00:05, 20145.51it/s]52935it [00:05, 22052.72it/s]55297it [00:05, 20519.06it/s]58369it [00:05, 20919.84it/s]60692it [00:05, 21498.23it/s]63489it [00:05, 22334.87it/s]63923it [00:05, 10668.09it/s]
I1120 15:31:43.730861 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153143e1c7dc0b091d6300target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_23.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-04-255692-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-04-255692-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4aadb460> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:31:48.039309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:48.039484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:48.039565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:48.039680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:48.039763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:48.039828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:31:48.083840: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:48.083936: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:48.152622: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:31:48.152730: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.66s/it]2049it [00:02, 1040.02it/s]4097it [00:02, 2333.81it/s]6145it [00:03, 3849.85it/s]8193it [00:03, 5567.81it/s]10241it [00:03, 7331.52it/s]12289it [00:03, 9140.72it/s]14337it [00:03, 10824.46it/s]16385it [00:03, 12502.06it/s]18433it [00:03, 13947.91it/s]20971it [00:03, 16613.64it/s]23327it [00:03, 18349.35it/s]25601it [00:04, 17783.88it/s]28114it [00:04, 19658.57it/s]30624it [00:04, 21111.44it/s]32877it [00:04, 19483.04it/s]35261it [00:04, 20630.38it/s]37811it [00:04, 21961.21it/s]40091it [00:04, 20095.12it/s]42595it [00:04, 21412.44it/s]44812it [00:04, 21447.06it/s]47010it [00:05, 21469.86it/s]49195it [00:05, 19719.53it/s]52225it [00:05, 20448.20it/s]54860it [00:05, 21980.66it/s]57345it [00:05, 20567.07it/s]59618it [00:05, 21126.87it/s]62110it [00:05, 22150.45it/s]63923it [00:05, 11003.95it/s]
I1120 15:31:54.116357 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112015315471c7dc0b091d5449target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_24.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-25-1598075-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-25-1598075-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d337e20> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:31:58.524085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:58.524251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:58.524338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:58.524451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:58.524526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:31:58.524589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:31:58.567363: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:58.567468: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:31:58.634867: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:31:58.634983: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.72s/it]2049it [00:02, 1015.34it/s]4097it [00:02, 2288.04it/s]6145it [00:03, 3782.59it/s]8193it [00:03, 5459.23it/s]10241it [00:03, 7350.07it/s]12289it [00:03, 9221.55it/s]14337it [00:03, 10959.91it/s]16385it [00:03, 12436.50it/s]18433it [00:03, 13761.96it/s]20908it [00:03, 16298.02it/s]23436it [00:03, 18524.95it/s]25601it [00:04, 17536.46it/s]27973it [00:04, 19100.78it/s]30418it [00:04, 20520.88it/s]32769it [00:04, 19221.32it/s]35097it [00:04, 20281.60it/s]37487it [00:04, 21264.69it/s]39694it [00:04, 21395.14it/s]41985it [00:04, 19681.35it/s]44306it [00:04, 20627.80it/s]46949it [00:05, 22234.70it/s]49226it [00:05, 20284.00it/s]51327it [00:05, 20478.52it/s]54182it [00:05, 22715.63it/s]56506it [00:05, 20705.92it/s]58819it [00:05, 21356.45it/s]61039it [00:05, 21589.82it/s]63489it [00:05, 21766.70it/s]63923it [00:05, 10873.81it/s]
I1120 15:32:04.909472 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511201532049c334a1a08d3bad0target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_25.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-08-511384-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-08-511384-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4b0c0d90> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:32:09.326038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:09.326199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:09.326276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:09.326391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:09.326467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:09.326529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:32:09.369921: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:09.370016: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:09.437389: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:32:09.437620: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.56s/it]2049it [00:02, 1073.76it/s]4097it [00:02, 2394.80it/s]6145it [00:02, 3948.64it/s]8193it [00:03, 5692.60it/s]10241it [00:03, 7441.78it/s]12289it [00:03, 9310.27it/s]14337it [00:03, 10999.26it/s]16385it [00:03, 12530.36it/s]18433it [00:03, 13885.06it/s]20481it [00:03, 15281.71it/s]22803it [00:03, 17246.67it/s]25099it [00:03, 18739.09it/s]27172it [00:04, 19250.90it/s]29551it [00:04, 20518.63it/s]31745it [00:04, 18757.43it/s]33873it [00:04, 19431.90it/s]36094it [00:04, 20199.84it/s]38353it [00:04, 20876.21it/s]40572it [00:04, 21253.97it/s]42885it [00:04, 21800.50it/s]45092it [00:04, 19841.53it/s]47942it [00:04, 22229.16it/s]50222it [00:05, 20089.85it/s]52679it [00:05, 21281.14it/s]55297it [00:05, 20257.87it/s]57385it [00:05, 20388.36it/s]59504it [00:05, 20605.21it/s]62150it [00:05, 22238.19it/s]63923it [00:05, 11079.32it/s]
I1120 15:32:15.296071 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153215b2973c0a08d3a6d5target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_26.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-13-830999-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-13-830999-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4add66d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:32:19.952537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:19.952701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:19.952778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:19.952894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:19.952970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:19.953034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:32:19.997373: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:19.997491: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:20.066131: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:32:20.066274: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.85s/it]2049it [00:02, 966.60it/s]4097it [00:03, 2184.24it/s]6145it [00:03, 3631.70it/s]8193it [00:03, 5273.72it/s]10241it [00:03, 7035.32it/s]12289it [00:03, 8901.63it/s]14337it [00:03, 10558.21it/s]16385it [00:03, 11938.50it/s]18433it [00:03, 13279.91it/s]20481it [00:04, 14811.81it/s]22529it [00:04, 16125.24it/s]24688it [00:04, 17524.36it/s]27022it [00:04, 19081.41it/s]29236it [00:04, 19927.51it/s]31501it [00:04, 20698.47it/s]33684it [00:04, 21024.31it/s]35850it [00:04, 18956.80it/s]37962it [00:04, 19543.20it/s]39980it [00:04, 19713.92it/s]41998it [00:05, 19814.11it/s]44310it [00:05, 20769.44it/s]46414it [00:05, 20686.84it/s]48782it [00:05, 21562.77it/s]50954it [00:05, 21556.37it/s]53249it [00:05, 19776.54it/s]55545it [00:05, 20653.75it/s]58145it [00:05, 22163.70it/s]60417it [00:05, 20106.74it/s]62690it [00:06, 20814.99it/s]63923it [00:06, 10504.66it/s]
I1120 15:32:26.472469 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153226d2334a1a02edc394target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_27.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-18-1150614-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-18-1150614-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ace3670> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:32:30.916448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:30.916603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:30.916683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:30.916797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:30.916873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:30.916950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:32:30.960988: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:30.961100: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:31.030285: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:32:31.030401: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.77s/it]2049it [00:02, 997.32it/s]4097it [00:03, 2226.45it/s]6145it [00:03, 3690.09it/s]8193it [00:03, 5374.72it/s]10241it [00:03, 7273.79it/s]12289it [00:03, 9043.31it/s]14337it [00:03, 10811.62it/s]16385it [00:03, 12381.61it/s]18433it [00:03, 13778.90it/s]20886it [00:03, 16262.64it/s]23523it [00:04, 18770.59it/s]25708it [00:04, 17852.35it/s]28398it [00:04, 20152.62it/s]30721it [00:04, 19055.34it/s]33175it [00:04, 20464.43it/s]35683it [00:04, 21703.57it/s]37958it [00:04, 19815.60it/s]40601it [00:04, 21554.86it/s]43009it [00:04, 20181.23it/s]45168it [00:05, 20549.01it/s]47718it [00:05, 21894.94it/s]50177it [00:05, 20808.80it/s]53163it [00:05, 23239.34it/s]55553it [00:05, 21125.75it/s]57741it [00:05, 21127.62it/s]59907it [00:05, 21193.04it/s]62064it [00:05, 21209.50it/s]63923it [00:05, 10778.73it/s]
I1120 15:32:37.075873 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112015323694334a1a08d385d7target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_28.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-00-0-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-00-0-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbee3a07790> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:32:41.440222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:41.452308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:41.452452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:41.452575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:41.452653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:41.452716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:32:41.496154: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:41.496261: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:41.563888: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:32:41.564017: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.59s/it]2049it [00:02, 1058.84it/s]4097it [00:02, 2368.10it/s]6145it [00:02, 3934.99it/s]8193it [00:03, 5676.60it/s]10241it [00:03, 7532.65it/s]12289it [00:03, 9411.15it/s]14337it [00:03, 11094.77it/s]16385it [00:03, 12462.23it/s]18433it [00:03, 13483.93it/s]20481it [00:03, 14990.02it/s]22860it [00:03, 17137.27it/s]25208it [00:03, 18776.37it/s]27622it [00:04, 20222.31it/s]29806it [00:04, 18652.49it/s]32161it [00:04, 19944.48it/s]34387it [00:04, 20578.21it/s]36735it [00:04, 21393.52it/s]38940it [00:04, 19420.37it/s]41090it [00:04, 19979.70it/s]43149it [00:04, 20140.73it/s]45505it [00:04, 21110.77it/s]48104it [00:05, 22518.29it/s]50387it [00:05, 20510.56it/s]52492it [00:05, 20500.37it/s]54580it [00:05, 20552.07it/s]56662it [00:05, 20477.24it/s]58729it [00:05, 20345.54it/s]60864it [00:05, 20636.00it/s]63344it [00:05, 21854.08it/s]63923it [00:05, 10997.76it/s]
I1120 15:32:47.631257 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511201532470fa9fe0a08d41b97target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_29.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-23-1470229-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-23-1470229-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d38a2e0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:32:52.506303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:52.619280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:52.635771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:52.635908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:52.637646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:32:52.637742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:32:52.681581: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:52.681689: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:32:52.749731: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:32:52.749829: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.67s/it]2049it [00:02, 1037.45it/s]4097it [00:02, 2328.12it/s]6145it [00:03, 3835.84it/s]8193it [00:03, 5546.12it/s]10241it [00:03, 7462.80it/s]12289it [00:03, 9214.61it/s]14337it [00:03, 10919.34it/s]16385it [00:03, 12488.82it/s]18433it [00:03, 13760.71it/s]20848it [00:03, 16157.95it/s]23284it [00:03, 18191.49it/s]25601it [00:04, 17721.65it/s]28165it [00:04, 19729.22it/s]30721it [00:04, 19232.31it/s]33279it [00:04, 20854.40it/s]35841it [00:04, 20009.49it/s]38221it [00:04, 20982.41it/s]40677it [00:04, 21942.13it/s]43009it [00:04, 20155.32it/s]45340it [00:04, 20985.76it/s]48129it [00:05, 20722.56it/s]50482it [00:05, 21455.83it/s]52803it [00:05, 21932.13it/s]55297it [00:05, 20440.27it/s]57389it [00:05, 20380.65it/s]60235it [00:05, 22578.07it/s]62539it [00:05, 20396.11it/s]63923it [00:05, 10968.76it/s]
I1120 15:32:58.761485 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112015325812344a1a08d36017target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_30.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-22-1406306-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-22-1406306-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4d2a8790> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:33:03.490849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:03.491014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:03.491092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:03.491208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:03.491285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:03.491348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:33:03.534304: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:33:03.534404: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:33:03.601487: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-20 15:33:03.601627: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.81s/it]2049it [00:02, 985.82it/s]4097it [00:03, 2213.92it/s]6145it [00:03, 3686.06it/s]8193it [00:03, 5354.83it/s]10241it [00:03, 7112.45it/s]12289it [00:03, 8881.70it/s]14337it [00:03, 10539.67it/s]16385it [00:03, 12176.55it/s]18433it [00:03, 13605.33it/s]21007it [00:03, 16381.61it/s]23540it [00:04, 18585.47it/s]25708it [00:04, 17654.96it/s]28117it [00:04, 19282.29it/s]30444it [00:04, 20340.37it/s]32769it [00:04, 19209.68it/s]35312it [00:04, 20845.51it/s]37889it [00:04, 20061.19it/s]40415it [00:04, 21416.48it/s]42926it [00:04, 22418.62it/s]45234it [00:05, 20448.64it/s]47352it [00:05, 20473.57it/s]50099it [00:05, 22384.32it/s]52393it [00:05, 20407.10it/s]55292it [00:05, 22692.70it/s]57637it [00:05, 20331.07it/s]60417it [00:05, 20258.26it/s]62880it [00:05, 21359.04it/s]63923it [00:05, 10695.79it/s]
I1120 15:33:09.923654 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153309d8c7dc0b091ce60ftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
----predict file:/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/logs/pred_202511190000_31.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251119/part-r-21-1342383-63923.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251119/part-r-21-1342383-63923.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fbf4d2bb430> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': True, 'senet_type': 'SeNet', 'senet_config': {'reduction_ratio': 3, 'excitation_activation': 'relu'}, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fbf4ae1f550> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:------senet out embedding: Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_3/activation_3/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_4/activation_4/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_8:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_8/activation_7/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_9/activation_8/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_14/activation_30/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_15/activation_31/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_18/activation_33/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_19/activation_34/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_22/activation_36/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_23/activation_37/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-20 15:33:14.198132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:14.198286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:14.198363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:14.198492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:14.198569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-20 15:33:14.198632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet/202511180000/model.ckpt-62245
2025-11-20 15:33:14.242111: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings_embeddings/embeddings_embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings/embeddings_embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings_embeddings/embeddings_embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:33:14.242217: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-20 15:33:14.309243: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-20 15:33:14.309356: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.62s/it]2049it [00:02, 1046.67it/s]4097it [00:02, 2356.38it/s]6145it [00:02, 3918.51it/s]8193it [00:03, 5646.14it/s]10241it [00:03, 7466.65it/s]12289it [00:03, 9152.08it/s]14337it [00:03, 10684.61it/s]16385it [00:03, 12152.46it/s]18433it [00:03, 13579.23it/s]20895it [00:03, 16101.39it/s]23553it [00:03, 17045.49it/s]26220it [00:04, 19382.61it/s]28673it [00:04, 18824.70it/s]31184it [00:04, 20399.62it/s]33793it [00:04, 19848.16it/s]36387it [00:04, 21397.96it/s]38913it [00:04, 20284.77it/s]41606it [00:04, 21987.22it/s]44033it [00:04, 20652.51it/s]46467it [00:04, 21607.57it/s]49153it [00:05, 20942.70it/s]51560it [00:05, 21754.73it/s]53786it [00:05, 21863.09it/s]56009it [00:05, 21932.54it/s]58369it [00:05, 20182.63it/s]60619it [00:05, 20803.07it/s]62739it [00:05, 20825.92it/s]63923it [00:05, 11036.48it/s]
I1120 15:33:20.128267 140460813391680 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251120153320b2c8dc0b091d84d7target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742'>
INFO:tensorflow:mode: infer device: GPU task_type: chief task_idx: 0 time_str: 202511190000 end_time_str: None waste: 5.68 mins
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511190000,feature_type=O35_mutil_cvr_v10_mmoe_senet,infer_time=20251120152742
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
----------------------------clear history data--------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10_mmoe_senet/train_config.py
(Namespace(data_path='/data/share/opt/data', del_date='20250821'), [])
---------del_path=/data/share/opt/data/O35_mutil_cvr/20250821--------
/data/share/opt/model/O35_mutil_cvr_v10_mmoe_senet
