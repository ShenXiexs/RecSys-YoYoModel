code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
--> time_str: 202511250000, end_date: 202511250000
---------------------------------main-train-------------------------------------
---------------------------------export.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-export-------------------------------------
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-26 09:18:43.979923: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-26 09:18:43.979955: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-26 09:18:43.979959: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-26 09:18:43.980075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-26 09:18:43.980094: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-26 09:18:43.980097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:Using CPU for training
INFO:tensorflow:time_str=20251125, end_time_str=20251125
INFO:tensorflow:train_date={'20251125': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-15-637845-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-04-170092-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-16-680368-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-11-467753-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-05-212615-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-25-1063075-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-01-42523-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-13-552799-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-03-127569-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-09-382707-42523.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511250000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 0
}
intra_op_parallelism_threads: 16
inter_op_parallelism_threads: 16
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: CPU
INFO:tensorflow:Batch sizes - Train: 1024, Eval: 5120
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 1024, 'train_epoch': 1, 'batch_size': 5120}
seq_idxs=[]
defalut feature:Tensor("StringJoin:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_1:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_2:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_3:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_4:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_5:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_6:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_7:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_8:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_9:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_10:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_11:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_12:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_13:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_14:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_15:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_16:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_17:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_18:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_19:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_20:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_21:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_22:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_23:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_24:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_25:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_26:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_27:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_28:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_29:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_30:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_31:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_32:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_33:0", shape=(None,), dtype=string)
feature:user__imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_34:0", shape=(None,), dtype=string)
feature:user__clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_35:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_36:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_37:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_38:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_39:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_40:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_41:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_42:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_43:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_44:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_45:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_46:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_47:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_48:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_49:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_50:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_51:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_52:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_53:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_54:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_55:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_56:0", shape=(None,), dtype=string)
feature:user__imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_57:0", shape=(None,), dtype=string)
feature:user__clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_58:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_59:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_60:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_61:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_62:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_63:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_64:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_65:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_66:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_67:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_68:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_69:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_70:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_71:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_72:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_73:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_74:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_75:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_76:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_77:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_78:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_79:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_80:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_81:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_82:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_83:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_84:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_85:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_86:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_87:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_88:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_89:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_90:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_91:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_92:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_93:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_94:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_95:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_96:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_97:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_98:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_99:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_100:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_101:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_102:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_103:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_104:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_105:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_106:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_107:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_108:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_109:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_110:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_111:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_112:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_113:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_114:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_115:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_116:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_117:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_118:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_119:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_120:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_121:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_122:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_123:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_124:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_125:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_126:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_127:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_128:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_129:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_130:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_131:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_132:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_133:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_134:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_135:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_136:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_137:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_138:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_139:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_140:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_141:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_142:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_143:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_144:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_145:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_146:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_147:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_148:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_149:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_150:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_151:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_152:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_153:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_154:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_155:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_156:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_157:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_158:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_159:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_160:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_161:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_162:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_163:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_164:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_165:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_166:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_167:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_168:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_169:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_170:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_171:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_172:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_173:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_174:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_175:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_176:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_177:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_178:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_179:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_180:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_181:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_182:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_183:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_184:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_185:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_186:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_187:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_188:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_189:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_190:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_191:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_192:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_193:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_194:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_195:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_196:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_197:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_198:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_199:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_200:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_201:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_202:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_203:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_204:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_205:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_206:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_207:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_208:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_209:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_210:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_211:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_212:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_213:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_214:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_215:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_216:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_217:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_218:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_219:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_220:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_221:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_222:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_223:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_224:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_225:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_226:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_227:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_228:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_229:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_230:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_231:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_232:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_233:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_234:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_235:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_236:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_237:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_238:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_239:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_240:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_241:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_242:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_243:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_244:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_245:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_246:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_247:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_248:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_249:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_250:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_251:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_252:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_253:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_254:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_255:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_256:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_257:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_258:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_259:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_260:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_261:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_262:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_263:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_264:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_265:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_266:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_267:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_268:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_269:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_270:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_271:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_272:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_273:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_274:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_275:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_276:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_277:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_278:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_279:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_280:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_281:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_282:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_283:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_284:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_285:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_286:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_287:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_288:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_289:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_290:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_291:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_292:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_293:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_294:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_295:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_296:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_297:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_298:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_299:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_300:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_301:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_302:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_303:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_304:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_305:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_306:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_307:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_308:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_309:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_310:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_311:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_312:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_313:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_314:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_315:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_316:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_317:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_318:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_319:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_320:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_321:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_322:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_323:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_324:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_325:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_326:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_327:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_328:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_329:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_330:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_331:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_332:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_333:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_334:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_335:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_336:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_337:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_338:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_339:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_340:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_341:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_342:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_343:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_344:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_345:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_346:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_347:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_348:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_349:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_350:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_351:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_352:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_353:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_354:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_355:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_356:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_357:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_358:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_359:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_360:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_361:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_362:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_363:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_364:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_365:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_366:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_367:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_368:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_369:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_370:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_371:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_372:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_373:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_374:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_375:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_376:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_377:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_378:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_379:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_380:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_381:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_382:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_383:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_384:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_385:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_386:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_387:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_388:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_389:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_390:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_391:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_392:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_393:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_394:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_395:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_396:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_397:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_398:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_399:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_400:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_401:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_402:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_403:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_404:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_405:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_406:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_407:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_408:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_409:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_410:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_411:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_412:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_413:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_414:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_415:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_416:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_417:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_418:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_419:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_420:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_421:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_422:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_423:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_424:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_425:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_426:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_427:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_428:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_429:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_430:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_431:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_432:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_433:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_434:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_435:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_436:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_437:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_438:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_439:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_440:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_441:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_442:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_443:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_444:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_445:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_446:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_447:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_448:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_449:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_450:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_451:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_452:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_453:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_454:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_455:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_456:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_457:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_458:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_459:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_460:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_461:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_462:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_463:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_464:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_465:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_466:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_467:0", shape=(None,), dtype=string)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f754167bcd0> -------
INFO:tensorflow:------ features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'export', 'ps_num': 0, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'CPU', 'gpu_ids': [], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is /job:localhost/replica:0/task:0/CPU:0 -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f7541608100> emb_lookuped: Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("ctr_tower/zeros:0", shape=(None,), dtype=float32), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("awake_tower/zeros:0", shape=(None,), dtype=float32), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("mmoe_tower/zeros:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("mmoe_tower/zeros_1:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("mmoe_tower/zeros_2:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
2025-11-26 09:18:47.622677: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511250000/model.ckpt-164921
2025-11-26 09:18:47.980092: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:18:47.980412: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: /data/share/opt/model/O35_mutil_cvr_v10/export_dir/temp-1764119924/saved_model.pb
INFO:tensorflow:mode: export device: CPU task_type: chief task_idx: 0 time_str: 202511250000 end_time_str: None waste: 0.08 mins
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_468:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_469:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_470:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_471:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_472:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_473:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_474:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_475:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_476:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_477:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_478:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_479:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_480:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_481:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_482:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_483:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_484:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_485:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_486:0", shape=(None,), dtype=string)
features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} tensors: 487
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
-------------------------------generate_body---------------------------------------
seq_idxs=[]
(Namespace(day='20251125'), [])
[INFO/MainProcess] process shutting down
==================warmup.py:  export_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir ====================
2025-11-26 09:18:52.852092: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-26 09:18:52.852124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-26 09:18:52.852128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-26 09:18:52.852217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-26 09:18:52.852250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-26 09:18:52.852254: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
seq_idxs=[]
model_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir
body_file:/opt/huangmian/yoyo_model/config/O35_mutil_cvr_v10/body.json
files: [1763089185, 1763175233, 1763346032, 1763432182, 1763518248, 1763604706, 1763691680, 1763875993, 1763877384, 1763951569, 1764036328, 1764119924]
/data/share/opt/model/O35_mutil_cvr_v10
eval data:202511250000
---------------------------------eval.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-eval-------------------------------------
grep: /data/share/opt/model/O35_mutil_cvr_v10/logs/202511250000.eval: No such file or directory
---------------------------------save_eval_metric------------------------------------
seq_idxs=[]
(Namespace(dm_date='202511250000', eval_path='/data/share/opt/model/O35_mutil_cvr_v10/logs/eval', model_version='O35_mutil_cvr_v10'), [])
line=task = O35_mutil_cvr_v10, time = 202511250000, awake/auc = 0.8440431, awake/cnt = 1318228, awake/ctr = 0.06559943, awake/mae = 0.1014906, awake/pcoc = 1.0581529, awake/prob = 0.06941422, ctr/auc = 0.86592764, ctr/cnt = 1318228, ctr/ctr = 0.13311885, ctr/mae = 0.16755183, ctr/pcoc = 1.1003312, ctr/prob = 0.14647482, global_step = 163633, lhb/auc = 0.9103074, lhb/cnt = 1018485, lhb/ctr = 0.0026568875, lhb/mae = 0.005167767, lhb/pcoc = 1.0142232, lhb/prob = 0.0026946769, loss = 0.5018761, sd/auc = 0.8752104, sd/cnt = 744117, sd/ctr = 0.031003188, sd/mae = 0.05160314, sd/pcoc = 1.0368608, sd/prob = 0.032145992, ymfw/auc = 0.7797974, ymfw/cnt = 231039, ymfw/ctr = 0.031747885, ymfw/mae = 0.059872154, ymfw/pcoc = 1.028038, ymfw/prob = 0.032638032

partition= dm_date=202511250000
write table value(['O35_mutil_cvr_v10', '{"task": "O35_mutil_cvr_v10", "time": "202511250000", "awake/auc": "0.8440431", "awake/cnt": "1318228", "awake/ctr": "0.06559943", "awake/mae": "0.1014906", "awake/pcoc": "1.0581529", "awake/prob": "0.06941422", "ctr/auc": "0.86592764", "ctr/cnt": "1318228", "ctr/ctr": "0.13311885", "ctr/mae": "0.16755183", "ctr/pcoc": "1.1003312", "ctr/prob": "0.14647482", "global_step": "163633", "lhb/auc": "0.9103074", "lhb/cnt": "1018485", "lhb/ctr": "0.0026568875", "lhb/mae": "0.005167767", "lhb/pcoc": "1.0142232", "lhb/prob": "0.0026946769", "loss": "0.5018761", "sd/auc": "0.8752104", "sd/cnt": "744117", "sd/ctr": "0.031003188", "sd/mae": "0.05160314", "sd/pcoc": "1.0368608", "sd/prob": "0.032145992", "ymfw/auc": "0.7797974", "ymfw/cnt": "231039", "ymfw/ctr": "0.031747885", "ymfw/mae": "0.059872154", "ymfw/pcoc": "1.028038", "ymfw/prob": "0.032638032"}', 'cvr', '2025-11-26 09:20:01'])
/data/share/opt/model/O35_mutil_cvr_v10
infer data:202511250000
---------------------------------infer.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-infer-------------------------------------
ckpt_dir=/data/share/opt/model/O35_mutil_cvr_v10/202511240000, time_str=202511250000
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-26 09:20:13.856291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:13.856427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:13.862439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:13.862575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:13.862657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:13.862733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:time_str=20251125, end_time_str=20251125
INFO:tensorflow:train_date={'20251125': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-29-1233167-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-30-1275690-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-12-510276-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-31-1318213-15.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-21-892983-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-08-340184-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-16-680368-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-24-1020552-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-28-1190644-42523.gz', '/data/share/opt/data/O35_mutil_cvr/20251125/part-r-00-0-42523.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511240000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 2
}
intra_op_parallelism_threads: 8
inter_op_parallelism_threads: 8
gpu_options {
  per_process_gpu_memory_fraction: 0.9
  allow_growth: true
  visible_device_list: "0"
}
allow_soft_placement: true
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: GPU
INFO:tensorflow:Using GPUs: 0
INFO:tensorflow:Batch sizes - Train: 1024, Eval: 5120
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 1024, 'train_epoch': 1, 'batch_size': 5120}
seq_idxs=[]
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_0.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-29-1233167-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-29-1233167-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5ea3e50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:20:15.321929: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-26 09:20:15.322534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:15.322694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:15.322772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:15.892025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:15.892173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:15.892262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:15.892349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:20:15.943563: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:15.943675: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:16.043621: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:20:16.044333: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2025-11-26 09:20:18.610296: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1it [00:04,  4.72s/it]5121it [00:04, 1446.72it/s]10241it [00:05, 3229.71it/s]15361it [00:05, 5336.12it/s]20481it [00:05, 7572.39it/s]25601it [00:05, 10033.94it/s]30721it [00:06, 12500.50it/s]35841it [00:06, 14627.62it/s]40961it [00:06, 18790.14it/s]42523it [00:06, 6594.36it/s] 
I1126 09:20:23.783044 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609202391973c0a0aeba8eetarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_1.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-30-1275690-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-30-1275690-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3be34c0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:20:28.130533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:28.315447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:28.315591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:28.315728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:28.315814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:28.315888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:20:28.365102: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:28.365203: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:28.436549: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:20:28.436779: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.80s/it]5121it [00:04, 1773.97it/s]10241it [00:04, 3895.22it/s]15361it [00:04, 6299.64it/s]20481it [00:04, 8805.50it/s]25601it [00:04, 11361.59it/s]30721it [00:05, 13569.93it/s]35841it [00:05, 15758.07it/s]40961it [00:05, 20206.34it/s]42523it [00:05, 7743.68it/s] 
I1126 09:20:33.858415 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092033da334a1a0aeb1ce9target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_2.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-12-510276-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-12-510276-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5f78ca0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:20:37.800577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:37.800796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:37.800910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:37.801076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:37.801196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:37.801283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:20:37.856991: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:37.857097: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:37.947488: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:20:37.947782: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.91s/it]5121it [00:04, 1729.50it/s]10241it [00:04, 3784.51it/s]15361it [00:04, 6123.09it/s]20481it [00:04, 8633.88it/s]25601it [00:05, 10845.36it/s]30721it [00:05, 13222.02it/s]35841it [00:05, 15218.94it/s]41056it [00:05, 19720.63it/s]42523it [00:05, 7510.97it/s] 
I1126 09:20:43.627506 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092043d8334a1a0aeb64f5target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_3.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-31-1318213-15.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-31-1318213-15.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3b00fa0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:20:47.628065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:47.628218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:47.628298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:47.628416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:47.628495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:47.628562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:20:47.689194: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:47.689349: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:47.781991: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:20:47.782123: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:01,  1.85s/it]15it [00:01,  7.99it/s]
I1126 09:20:49.686336 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609204993334a1a0aeb7206target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_4.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-21-892983-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-21-892983-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3bdc220> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:20:53.158530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:53.158807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:53.158931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:53.159098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:53.159208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:20:53.159299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:20:53.213320: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:53.213453: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:20:53.285100: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:20:53.285249: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.82s/it]5121it [00:04, 1774.47it/s]10241it [00:04, 3873.03it/s]15361it [00:04, 6269.63it/s]20481it [00:04, 8787.55it/s]25601it [00:04, 11253.80it/s]30721it [00:05, 13611.89it/s]35841it [00:05, 14995.24it/s]40961it [00:05, 18924.77it/s]42523it [00:05, 7619.73it/s] 
I1126 09:20:58.803527 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511260920588fc8dc0b0b46e03dtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_5.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-08-340184-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-08-340184-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3d71c40> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:21:02.971284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:02.971576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:02.971700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:02.971867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:02.971975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:02.972064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:21:03.025385: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:03.025501: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:03.096693: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:21:03.096823: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.55s/it]5121it [00:03, 1886.19it/s]10241it [00:03, 4106.28it/s]15361it [00:04, 6535.50it/s]20481it [00:04, 9102.17it/s]25601it [00:04, 11602.48it/s]30721it [00:04, 13824.37it/s]35841it [00:05, 15743.61it/s]40961it [00:05, 19523.56it/s]42523it [00:05, 7999.24it/s] 
I1126 09:21:08.290574 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092108e1cfdc0b0b46fd22target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_6.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-16-680368-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-16-680368-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5ef9760> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:21:12.138594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:12.138767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:12.138847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:12.138968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:12.139065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:12.139131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:21:12.185782: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:12.185897: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:12.258333: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:21:12.258474: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.49s/it]5121it [00:03, 1915.60it/s]10241it [00:03, 4143.24it/s]15361it [00:04, 6578.30it/s]20481it [00:04, 9168.36it/s]25601it [00:04, 11638.36it/s]30721it [00:04, 13847.10it/s]35841it [00:05, 15914.61it/s]40961it [00:05, 20029.13it/s]42523it [00:05, 8097.17it/s] 
I1126 09:21:17.706989 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092117d8c7dc0b0b4664fatarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_7.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-24-1020552-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-24-1020552-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d36874c0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:21:21.390378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:21.390548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:21.390638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:21.390770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:21.390851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:21.390915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:21:21.447034: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:21.447144: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:21.517961: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:21:21.518083: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.60s/it]5121it [00:03, 1870.38it/s]10241it [00:04, 4078.08it/s]15361it [00:04, 6384.55it/s]20481it [00:04, 8949.42it/s]25601it [00:04, 11409.35it/s]30721it [00:04, 13646.03it/s]35841it [00:05, 15536.04it/s]40961it [00:05, 19871.10it/s]42523it [00:05, 7929.41it/s] 
I1126 09:21:27.235191 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092127e1c7dc0b0b471610target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_8.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-28-1190644-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-28-1190644-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3ca77f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:21:31.448356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:31.448536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:31.448617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:31.448738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:31.448817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:31.448892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:21:31.493247: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:31.493359: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:31.572605: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:21:31.572732: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.83s/it]5121it [00:04, 1767.29it/s]10241it [00:04, 3858.16it/s]15361it [00:04, 6208.38it/s]20481it [00:04, 8696.76it/s]25601it [00:04, 10989.57it/s]30721it [00:05, 12603.27it/s]35841it [00:05, 14091.57it/s]40961it [00:05, 17650.38it/s]42523it [00:05, 7432.89it/s] 
I1126 09:21:37.224966 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092137d7334a1a0aeb02catarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_9.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-00-0-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-00-0-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f062e56aca0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:21:41.084908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:41.085140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:41.085239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:41.085360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:41.085440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:41.085507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:21:41.137152: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:41.137272: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:41.209579: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:21:41.209715: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.62s/it]5121it [00:03, 1863.00it/s]10241it [00:04, 4043.66it/s]15361it [00:04, 6508.23it/s]20481it [00:04, 9002.71it/s]25601it [00:04, 11454.66it/s]30721it [00:04, 13775.88it/s]35841it [00:05, 15622.22it/s]40961it [00:05, 19607.16it/s]42523it [00:05, 7912.87it/s] 
I1126 09:21:46.610452 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092146d4334a1a0aebe3d9target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_10.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-20-850460-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-20-850460-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d1575b20> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:21:50.608767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:50.608941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:50.609022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:50.609144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:50.609224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:21:50.609290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:21:50.654059: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:50.654171: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:21:50.733384: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:21:50.733545: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.81s/it]5121it [00:04, 1775.39it/s]10241it [00:04, 3885.79it/s]15361it [00:04, 6216.20it/s]20481it [00:04, 8698.37it/s]25601it [00:04, 11052.59it/s]30721it [00:05, 12926.95it/s]35841it [00:05, 14325.92it/s]40961it [00:05, 18435.10it/s]42523it [00:05, 7523.22it/s] 
I1126 09:21:56.295734 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092156e5cfdc0b0b4695dftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_11.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-02-85046-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-02-85046-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d0f74e50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:22:00.277785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:00.277955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:00.278035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:00.278155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:00.278234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:00.278298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:22:00.322490: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:00.322605: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:00.399123: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:22:00.399245: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.62s/it]5121it [00:03, 1861.08it/s]10241it [00:04, 4051.51it/s]15361it [00:04, 6479.60it/s]20481it [00:04, 8900.40it/s]25601it [00:04, 11299.29it/s]30721it [00:05, 13160.38it/s]35841it [00:05, 15163.04it/s]40961it [00:05, 18985.44it/s]42523it [00:05, 7827.18it/s] 
I1126 09:22:05.844543 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092205d2f2dc0b0b46ecbetarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_12.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-14-595322-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-14-595322-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5f36100> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:22:09.676580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:09.676757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:09.676840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:09.676963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:09.677062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:09.677129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:22:09.722100: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:09.722204: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:09.801488: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:22:09.801612: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.88s/it]5121it [00:04, 1742.41it/s]10241it [00:04, 3818.67it/s]15361it [00:04, 6100.32it/s]20481it [00:04, 8510.68it/s]25601it [00:05, 10557.09it/s]30721it [00:05, 12584.18it/s]35841it [00:05, 14114.73it/s]40961it [00:05, 18063.87it/s]42523it [00:05, 7360.64it/s] 
I1126 09:22:15.434646 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092215dda3cc0b0b46daf3target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_13.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-09-382707-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-09-382707-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f062f3a1d90> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:22:19.206750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:19.206924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:19.207002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:19.207131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:19.207209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:19.207273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:22:19.264003: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:19.264107: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:19.335986: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:22:19.336115: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.64s/it]5121it [00:03, 1856.46it/s]10241it [00:04, 4025.63it/s]15361it [00:04, 6468.62it/s]20481it [00:04, 9056.13it/s]25601it [00:04, 11220.66it/s]30721it [00:05, 13125.72it/s]35841it [00:05, 14473.51it/s]40961it [00:05, 18524.44it/s]42523it [00:05, 7758.18it/s] 
I1126 09:22:24.710110 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609222412344a1a0aeb67c1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_14.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-15-637845-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-15-637845-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3a78700> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:22:28.553053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:28.553224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:28.553305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:28.553441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:28.553523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:28.553589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:22:28.611638: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:28.611753: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:28.685279: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:22:28.685418: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.81s/it]5121it [00:04, 1771.41it/s]10241it [00:04, 3851.14it/s]15361it [00:04, 6208.29it/s]20481it [00:04, 8623.19it/s]25601it [00:04, 10968.20it/s]30721it [00:05, 12907.99it/s]35841it [00:05, 14484.86it/s]40961it [00:05, 18307.69it/s]42523it [00:05, 7501.21it/s] 
I1126 09:22:34.384394 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609223494334a1a0aeb7cdetarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_15.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-07-297661-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-07-297661-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3cb6460> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:22:38.519115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:38.519289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:38.519368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:38.519499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:38.519579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:38.519644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:22:38.565099: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:38.565265: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:38.642710: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:22:38.642863: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.72s/it]5121it [00:03, 1811.53it/s]10241it [00:04, 3883.43it/s]15361it [00:04, 6260.70it/s]20481it [00:04, 8524.24it/s]25601it [00:04, 10754.85it/s]30721it [00:05, 12969.68it/s]35841it [00:05, 14571.31it/s]40961it [00:05, 18225.37it/s]42523it [00:05, 7563.95it/s] 
I1126 09:22:44.233266 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609224471c7dc0b0b471c65target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_16.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-03-127569-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-03-127569-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d375ea90> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:22:47.873632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:48.027124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:48.027235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:48.027366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:48.027460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:48.027536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:22:48.072241: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:48.072344: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:48.149509: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:22:48.149652: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.57s/it]5121it [00:03, 1882.67it/s]10241it [00:04, 4073.91it/s]15361it [00:04, 6472.17it/s]20481it [00:04, 8773.83it/s]25601it [00:04, 11015.47it/s]30721it [00:05, 12911.17it/s]35841it [00:05, 14449.00it/s]40961it [00:05, 18175.84it/s]42523it [00:05, 7755.86it/s] 
I1126 09:22:53.588722 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092253c756381a0aeb8468target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_17.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-17-722891-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-17-722891-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3a59d60> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:22:57.382650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:57.382825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:57.382907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:57.383029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:57.383109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:22:57.383174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:22:57.431794: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:57.431915: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:22:57.505995: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:22:57.506137: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.48s/it]5121it [00:03, 1925.93it/s]10241it [00:03, 4190.43it/s]15361it [00:04, 6649.93it/s]20481it [00:04, 9098.62it/s]25601it [00:04, 11446.00it/s]30721it [00:04, 13439.03it/s]35841it [00:05, 14794.28it/s]40961it [00:05, 18950.91it/s]42523it [00:05, 7992.51it/s] 
I1126 09:23:02.731449 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092302e5cfdc0b0b46abedtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_18.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-27-1148121-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-27-1148121-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d393f820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:23:06.509490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:06.509676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:06.509758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:06.509879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:06.509960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:06.510026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:23:06.555926: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:06.556022: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:06.635756: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:23:06.635890: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.66s/it]5121it [00:03, 1834.45it/s]10241it [00:04, 4010.71it/s]15361it [00:04, 6452.70it/s]20481it [00:04, 9013.45it/s]25601it [00:04, 11566.88it/s]30721it [00:05, 13305.63it/s]35841it [00:05, 14998.75it/s]40961it [00:05, 18825.95it/s]42523it [00:05, 7795.74it/s] 
I1126 09:23:12.189594 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511260923121c344a1a0aebfbc1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_19.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-10-425230-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-10-425230-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3d01760> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:23:15.885357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:15.940241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:15.940351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:15.940482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:15.940578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:15.940652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:23:15.998283: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:15.998398: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:16.070884: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:23:16.071024: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.56s/it]5121it [00:03, 1889.01it/s]10241it [00:04, 4080.43it/s]15361it [00:04, 6526.77it/s]20481it [00:04, 9081.92it/s]25601it [00:04, 11560.97it/s]30721it [00:04, 13917.17it/s]35841it [00:05, 15699.85it/s]40961it [00:05, 20091.94it/s]42523it [00:05, 8007.12it/s] 
I1126 09:23:21.222319 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092321dda3cc0b0b46f1b2target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_20.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-26-1105598-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-26-1105598-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5e46b20> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:23:25.195975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:25.196150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:25.196230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:25.196350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:25.196443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:25.196510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:23:25.245223: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:25.245343: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:25.315067: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:23:25.315213: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.48s/it]5121it [00:03, 1934.17it/s]10241it [00:03, 4203.42it/s]15361it [00:04, 6682.82it/s]20481it [00:04, 9244.39it/s]25601it [00:04, 11478.13it/s]30721it [00:04, 13523.33it/s]35841it [00:05, 15614.89it/s]40961it [00:05, 19890.02it/s]42523it [00:05, 8119.77it/s] 
I1126 09:23:30.693331 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092330d8c7dc0b0b4690e6target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_21.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-19-807937-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-19-807937-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5ebd9d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:23:34.701320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:34.701492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:34.701573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:34.701690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:34.701770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:34.701834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:23:34.748886: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:34.748994: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:34.993685: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:23:34.993811: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.64s/it]5121it [00:03, 1826.36it/s]10241it [00:04, 3974.16it/s]15361it [00:04, 6270.51it/s]20481it [00:04, 8621.54it/s]25601it [00:04, 10889.60it/s]30721it [00:05, 13184.40it/s]35841it [00:05, 15036.48it/s]40961it [00:05, 19312.18it/s]42523it [00:05, 7731.18it/s] 
I1126 09:23:40.404056 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609234093334a1a0aeba7e8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_22.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-11-467753-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-11-467753-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3735b50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:23:44.350603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:44.350846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:44.350958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:44.351113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:44.351228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:44.351318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:23:44.417984: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:44.418147: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:44.496877: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:23:44.497013: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.93s/it]5121it [00:04, 1718.40it/s]10241it [00:04, 3780.20it/s]15361it [00:04, 6073.01it/s]20481it [00:04, 8557.43it/s]25601it [00:05, 10944.51it/s]30721it [00:05, 13355.19it/s]35841it [00:05, 15393.74it/s]40961it [00:05, 19796.85it/s]42523it [00:05, 7514.07it/s] 
I1126 09:23:50.064719 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609234997334a1a0aec339ctarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_23.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-01-42523-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-01-42523-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d367c430> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:23:54.014808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:54.015016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:54.015124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:54.015273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:54.015399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:23:54.015496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:23:54.068035: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:54.068168: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:23:54.153274: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:23:54.153434: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.86s/it]5121it [00:04, 1745.56it/s]10241it [00:04, 3804.32it/s]15361it [00:04, 6114.98it/s]20481it [00:04, 8590.69it/s]25601it [00:05, 11051.79it/s]30721it [00:05, 13239.83it/s]35841it [00:05, 15236.75it/s]40961it [00:05, 19379.34it/s]42523it [00:05, 7554.58it/s] 
I1126 09:23:59.457278 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511260923591c344a1a0aec0960target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_24.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-06-255138-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-06-255138-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5f78b50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:24:03.345816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:03.345987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:03.346079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:03.346212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:03.346293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:03.346358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:24:03.394905: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:03.395006: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:03.465404: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:24:03.465546: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.12s/it]5121it [00:04, 1642.84it/s]10241it [00:04, 3574.67it/s]15361it [00:04, 5824.25it/s]20481it [00:05, 8249.29it/s]25601it [00:05, 10612.63it/s]30721it [00:05, 13009.76it/s]35841it [00:05, 14922.13it/s]40961it [00:05, 19145.68it/s]42523it [00:05, 7205.13it/s] 
I1126 09:24:09.177237 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609240912344a1a0aeb87a8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_25.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-18-765414-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-18-765414-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f062e418880> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:24:12.865014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:12.973116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:12.973230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:12.973363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:12.973445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:12.973529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:24:13.022115: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:13.022255: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:13.101512: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-26 09:24:13.101642: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.98s/it]5121it [00:04, 1690.24it/s]10241it [00:04, 3704.81it/s]15361it [00:04, 5998.19it/s]20481it [00:04, 8376.41it/s]25601it [00:05, 10818.42it/s]30721it [00:05, 13059.11it/s]35841it [00:05, 15133.56it/s]40961it [00:05, 19267.56it/s]42523it [00:05, 7387.85it/s] 
I1126 09:24:18.505146 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609241870c7dc0b0b47244etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_26.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-25-1063075-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-25-1063075-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3b08e50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:24:22.349652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:22.349813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:22.349893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:22.350012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:22.350092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:22.350157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:24:22.407473: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:22.407629: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:22.485397: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:24:22.485522: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.89s/it]5121it [00:04, 1724.06it/s]10241it [00:04, 3783.51it/s]15361it [00:04, 6103.71it/s]20481it [00:04, 8539.34it/s]25601it [00:05, 10994.57it/s]30721it [00:05, 13026.48it/s]35841it [00:05, 14991.57it/s]40961it [00:05, 18688.26it/s]42523it [00:05, 7455.24it/s] 
I1126 09:24:28.033287 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511260924278657381a0aeba592target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_27.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-22-935506-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-22-935506-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d389b730> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:24:32.017863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:32.018034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:32.018129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:32.018255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:32.018336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:32.018402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:24:32.066913: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:32.067033: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:32.144009: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:24:32.144188: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.90s/it]5121it [00:04, 1729.35it/s]10241it [00:04, 3788.28it/s]15361it [00:04, 6070.67it/s]20481it [00:04, 8568.40it/s]25601it [00:05, 11014.29it/s]30721it [00:05, 13311.02it/s]35841it [00:05, 15370.52it/s]40961it [00:05, 19599.40it/s]42523it [00:05, 7530.08it/s] 
I1126 09:24:37.786893 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092437d8e8da0b0b476bedtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_28.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-13-552799-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-13-552799-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3a76fa0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:24:41.618896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:41.619069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:41.619149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:41.619268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:41.619348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:41.619426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:24:41.665063: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:41.665175: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:41.742170: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:24:41.742312: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.06s/it]5121it [00:04, 1673.13it/s]10241it [00:04, 3641.00it/s]15361it [00:04, 5925.03it/s]20481it [00:04, 8309.76it/s]25601it [00:05, 10843.51it/s]30721it [00:05, 13223.78it/s]35841it [00:05, 15233.48it/s]40961it [00:05, 19535.12it/s]42523it [00:05, 7331.72it/s] 
I1126 09:24:47.542798 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609244754f5da0b0b46accdtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_29.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-05-212615-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-05-212615-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3a351f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:24:51.431577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:51.431826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:51.431937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:51.432084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:51.432167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:24:51.432233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:24:51.488431: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:51.488589: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:24:51.564810: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:24:51.564936: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.82s/it]5121it [00:04, 1766.71it/s]10241it [00:04, 3847.36it/s]15361it [00:04, 6196.82it/s]20481it [00:04, 8691.86it/s]25601it [00:04, 11055.91it/s]30721it [00:05, 13376.05it/s]35841it [00:05, 14966.14it/s]40961it [00:05, 19302.51it/s]42523it [00:05, 7593.13it/s] 
I1126 09:24:57.099882 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609245794334a1a0aeba70dtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_30.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-23-978029-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-23-978029-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d5ebbc40> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:25:00.939881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:00.940056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:00.940154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:00.940284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:00.940364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:00.940430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:25:00.989339: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:25:00.989435: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:25:01.071335: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:25:01.071477: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.88s/it]5121it [00:04, 1726.94it/s]10241it [00:04, 3784.29it/s]15361it [00:04, 6126.51it/s]20481it [00:04, 8527.79it/s]25601it [00:05, 10954.94it/s]30721it [00:05, 13119.73it/s]35841it [00:05, 15222.62it/s]40961it [00:05, 19128.20it/s]42523it [00:05, 7499.36it/s] 
I1126 09:25:06.984441 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112609250694973c0a0aec5be1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511250000_31.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251125/part-r-04-170092-42523.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251125/part-r-04-170092-42523.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f06d5ef51f0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f06d3c8e130> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-26 09:25:10.776301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:10.776454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:10.776534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:10.776652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:10.776732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-26 09:25:10.776820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511240000/model.ckpt-163633
2025-11-26 09:25:10.835179: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:25:10.835288: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-26 09:25:10.908388: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-26 09:25:10.908529: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.79s/it]5121it [00:04, 1769.44it/s]10241it [00:04, 3875.13it/s]15361it [00:04, 6235.81it/s]20481it [00:04, 8736.86it/s]25601it [00:04, 11060.30it/s]30721it [00:05, 13237.82it/s]35841it [00:05, 15361.32it/s]40961it [00:05, 19672.08it/s]42523it [00:05, 7656.03it/s] 
I1126 09:25:16.333028 139668538341184 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251126092516e1c7dc0b0b475d45target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013'>
INFO:tensorflow:mode: infer device: GPU task_type: chief task_idx: 0 time_str: 202511250000 end_time_str: None waste: 5.08 mins
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511250000,feature_type=O35_mutil_cvr_v10,infer_time=20251126092013
/data/share/opt/model/O35_mutil_cvr_v10
----------------------------clear history data--------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
seq_idxs=[]
(Namespace(curr_date='20251125', data_path='/data/share/opt/data', del_date=None), [])
---------del_path=/data/share/opt/data/O35_mutil_cvr/20251026--------
Traceback (most recent call last):
  File "/opt/huangmian/yoyo_model/common/clear_history_data.py", line 31, in <module>
    del_path = os.path.join(args.data_path, data_nm, args.del_date)
  File "/root/anaconda3/envs/env_gpu/lib/python3.8/posixpath.py", line 90, in join
    genericpath._check_arg_types('join', a, *p)
  File "/root/anaconda3/envs/env_gpu/lib/python3.8/genericpath.py", line 152, in _check_arg_types
    raise TypeError(f'{funcname}() argument must be str, bytes, or '
TypeError: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'
 /data/share/opt/model/O35_mutil_cvr_v10/export_dir/1763089185 diff days 11 
/data/share/opt/model/O35_mutil_cvr_v10
