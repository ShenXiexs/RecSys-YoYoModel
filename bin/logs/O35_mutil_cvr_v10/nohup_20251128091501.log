code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
--> time_str: 202511270000, end_date: 202511270000
---------------------------------main-train-------------------------------------
---------------------------------export.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-export-------------------------------------
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-28 10:21:31.020274: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-28 10:21:31.020304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-28 10:21:31.020308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-28 10:21:31.020414: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-28 10:21:31.020437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-28 10:21:31.020441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:Using CPU for training
INFO:tensorflow:time_str=20251127, end_time_str=20251127
INFO:tensorflow:train_date={'20251127': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-11-283481-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-06-154626-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-10-257710-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-14-360794-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-18-463878-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-25-644275-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-20-515420-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-08-206168-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-19-489649-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-31-798901-3.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511270000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 0
}
intra_op_parallelism_threads: 16
inter_op_parallelism_threads: 16
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: CPU
INFO:tensorflow:Batch sizes - Train: 2048, Eval: 5120
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 2048, 'train_epoch': 1, 'batch_size': 5120}
seq_idxs=[]
defalut feature:Tensor("StringJoin:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_1:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_2:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_3:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_4:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_5:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_6:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_7:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_8:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_9:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_10:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_11:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_12:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_13:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_14:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_15:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_16:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_17:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_18:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_19:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_20:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_21:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_22:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_23:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_24:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_25:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_26:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_27:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_28:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_29:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_30:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_31:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_32:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_33:0", shape=(None,), dtype=string)
feature:user__imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_34:0", shape=(None,), dtype=string)
feature:user__clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_35:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_36:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_37:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_38:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_39:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_40:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_41:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_42:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_43:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_44:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_45:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_46:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_47:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_48:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_49:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_50:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_51:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_52:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_53:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_54:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_55:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_56:0", shape=(None,), dtype=string)
feature:user__imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_57:0", shape=(None,), dtype=string)
feature:user__clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_58:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_59:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_60:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_61:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_62:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_63:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_64:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_65:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_66:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_67:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_68:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_69:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_70:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_71:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_72:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_73:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_74:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_75:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_76:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_77:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_78:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_79:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_80:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_81:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_82:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_83:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_84:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_85:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_86:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_87:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_88:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_89:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_90:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_91:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_92:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_93:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_94:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_95:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_96:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_97:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_98:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_99:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_100:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_101:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_102:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_103:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_104:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_105:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_106:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_107:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_108:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_109:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_110:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_111:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_112:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_113:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_114:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_115:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_116:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_117:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_118:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_119:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_120:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_121:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_122:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_123:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_124:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_125:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_126:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_127:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_128:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_129:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_130:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_131:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_132:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_133:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_134:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_135:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_136:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_137:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_138:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_139:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_140:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_141:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_142:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_143:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_144:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_145:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_146:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_147:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_148:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_149:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_150:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_151:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_152:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_153:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_154:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_155:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_156:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_157:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_158:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_159:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_160:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_161:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_162:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_163:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_164:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_165:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_166:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_167:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_168:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_169:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_170:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_171:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_172:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_173:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_174:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_175:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_176:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_177:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_178:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_179:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_180:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_181:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_182:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_183:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_184:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_185:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_186:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_187:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_188:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_189:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_190:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_191:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_192:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_193:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_194:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_195:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_196:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_197:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_198:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_199:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_200:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_201:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_202:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_203:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_204:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_205:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_206:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_207:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_208:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_209:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_210:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_211:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_212:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_213:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_214:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_215:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_216:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_217:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_218:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_219:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_220:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_221:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_222:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_223:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_224:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_225:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_226:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_227:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_228:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_229:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_230:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_231:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_232:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_233:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_234:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_235:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_236:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_237:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_238:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_239:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_240:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_241:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_242:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_243:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_244:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_245:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_246:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_247:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_248:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_249:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_250:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_251:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_252:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_253:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_254:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_255:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_256:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_257:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_258:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_259:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_260:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_261:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_262:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_263:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_264:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_265:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_266:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_267:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_268:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_269:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_270:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_271:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_272:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_273:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_274:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_275:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_276:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_277:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_278:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_279:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_280:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_281:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_282:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_283:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_284:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_285:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_286:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_287:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_288:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_289:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_290:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_291:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_292:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_293:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_294:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_295:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_296:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_297:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_298:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_299:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_300:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_301:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_302:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_303:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_304:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_305:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_306:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_307:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_308:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_309:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_310:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_311:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_312:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_313:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_314:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_315:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_316:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_317:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_318:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_319:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_320:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_321:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_322:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_323:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_324:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_325:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_326:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_327:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_328:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_329:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_330:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_331:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_332:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_333:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_334:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_335:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_336:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_337:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_338:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_339:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_340:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_341:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_342:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_343:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_344:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_345:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_346:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_347:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_348:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_349:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_350:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_351:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_352:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_353:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_354:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_355:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_356:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_357:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_358:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_359:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_360:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_361:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_362:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_363:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_364:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_365:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_366:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_367:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_368:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_369:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_370:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_371:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_372:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_373:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_374:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_375:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_376:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_377:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_378:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_379:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_380:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_381:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_382:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_383:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_384:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_385:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_386:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_387:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_388:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_389:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_390:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_391:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_392:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_393:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_394:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_395:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_396:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_397:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_398:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_399:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_400:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_401:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_402:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_403:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_404:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_405:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_406:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_407:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_408:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_409:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_410:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_411:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_412:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_413:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_414:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_415:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_416:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_417:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_418:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_419:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_420:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_421:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_422:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_423:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_424:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_425:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_426:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_427:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_428:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_429:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_430:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_431:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_432:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_433:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_434:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_435:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_436:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_437:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_438:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_439:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_440:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_441:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_442:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_443:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_444:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_445:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_446:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_447:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_448:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_449:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_450:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_451:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_452:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_453:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_454:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_455:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_456:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_457:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_458:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_459:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_460:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_461:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_462:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_463:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_464:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_465:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_466:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_467:0", shape=(None,), dtype=string)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fc3dd9b2cd0> -------
INFO:tensorflow:------ features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'export', 'ps_num': 0, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'CPU', 'gpu_ids': [], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is /job:localhost/replica:0/task:0/CPU:0 -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fc3dd93f100> emb_lookuped: Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("ctr_tower/zeros:0", shape=(None,), dtype=float32), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("awake_tower/zeros:0", shape=(None,), dtype=float32), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("mmoe_tower/zeros:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("mmoe_tower/zeros_1:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("mmoe_tower/zeros_2:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
2025-11-28 10:21:35.208145: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511270000/model.ckpt-165786
2025-11-28 10:21:35.547443: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:21:35.547777: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: /data/share/opt/model/O35_mutil_cvr_v10/export_dir/temp-1764296491/saved_model.pb
INFO:tensorflow:mode: export device: CPU task_type: chief task_idx: 0 time_str: 202511270000 end_time_str: None waste: 0.10 mins
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_468:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_469:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_470:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_471:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_472:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_473:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_474:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_475:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_476:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_477:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_478:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_479:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_480:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_481:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_482:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_483:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_484:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_485:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_486:0", shape=(None,), dtype=string)
features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} tensors: 487
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
-------------------------------generate_body---------------------------------------
seq_idxs=[]
(Namespace(day='20251127'), [])
[INFO/MainProcess] process shutting down
==================warmup.py:  export_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir ====================
2025-11-28 10:21:41.761182: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-28 10:21:41.761221: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-28 10:21:41.761227: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-28 10:21:41.761315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-28 10:21:41.761339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-28 10:21:41.761344: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
seq_idxs=[]
model_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir
body_file:/opt/huangmian/yoyo_model/config/O35_mutil_cvr_v10/body.json
files: [1763346032, 1763432182, 1763518248, 1763604706, 1763691680, 1763875993, 1763877384, 1763951569, 1764036328, 1764119924, 1764209552, 1764296491]
/data/share/opt/model/O35_mutil_cvr_v10
eval data:202511270000
---------------------------------eval.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-eval-------------------------------------
grep: /data/share/opt/model/O35_mutil_cvr_v10/logs/202511270000.eval: No such file or directory
---------------------------------save_eval_metric------------------------------------
seq_idxs=[]
(Namespace(dm_date='202511270000', eval_path='/data/share/opt/model/O35_mutil_cvr_v10/logs/eval', model_version='O35_mutil_cvr_v10'), [])
line=task = O35_mutil_cvr_v10, time = 202511270000, awake/auc = 0.73724073, awake/cnt = 798904, awake/ctr = 0.068316095, awake/mae = 0.18303733, awake/pcoc = 2.315165, awake/prob = 0.15816303, ctr/auc = 0.74122584, ctr/cnt = 798904, ctr/ctr = 0.14045116, ctr/mae = 0.30365455, ctr/pcoc = 2.1482863, ctr/prob = 0.30172932, global_step = 165395, lhb/auc = 0.9006346, lhb/cnt = 639654, lhb/ctr = 0.0022355837, lhb/mae = 0.006570511, lhb/pcoc = 2.0107217, lhb/prob = 0.004495137, loss = 1.1371869, sd/auc = 0.7835233, sd/cnt = 265536, sd/ctr = 0.049420793, sd/mae = 0.10339181, sd/pcoc = 1.4548322, sd/prob = 0.07189896, ymfw/auc = 0.5807522, ymfw/cnt = 137323, ymfw/ctr = 0.040583152, ymfw/mae = 0.120913506, ymfw/pcoc = 2.1921089, ymfw/prob = 0.08896269

partition= dm_date=202511270000
write table value(['O35_mutil_cvr_v10', '{"task": "O35_mutil_cvr_v10", "time": "202511270000", "awake/auc": "0.73724073", "awake/cnt": "798904", "awake/ctr": "0.068316095", "awake/mae": "0.18303733", "awake/pcoc": "2.315165", "awake/prob": "0.15816303", "ctr/auc": "0.74122584", "ctr/cnt": "798904", "ctr/ctr": "0.14045116", "ctr/mae": "0.30365455", "ctr/pcoc": "2.1482863", "ctr/prob": "0.30172932", "global_step": "165395", "lhb/auc": "0.9006346", "lhb/cnt": "639654", "lhb/ctr": "0.0022355837", "lhb/mae": "0.006570511", "lhb/pcoc": "2.0107217", "lhb/prob": "0.004495137", "loss": "1.1371869", "sd/auc": "0.7835233", "sd/cnt": "265536", "sd/ctr": "0.049420793", "sd/mae": "0.10339181", "sd/pcoc": "1.4548322", "sd/prob": "0.07189896", "ymfw/auc": "0.5807522", "ymfw/cnt": "137323", "ymfw/ctr": "0.040583152", "ymfw/mae": "0.120913506", "ymfw/pcoc": "2.1921089", "ymfw/prob": "0.08896269"}', 'cvr', '2025-11-28 10:22:49'])
/data/share/opt/model/O35_mutil_cvr_v10
infer data:202511270000
---------------------------------infer.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-infer-------------------------------------
ckpt_dir=/data/share/opt/model/O35_mutil_cvr_v10/202511260000, time_str=202511270000
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-28 10:23:03.266876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:03.267050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:03.274734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:03.274918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:03.275030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:03.275137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:time_str=20251127, end_time_str=20251127
INFO:tensorflow:train_date={'20251127': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-04-103084-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-21-541191-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-02-51542-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-22-566962-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-16-412336-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-15-386565-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-17-438107-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-27-695817-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-19-489649-25771.gz', '/data/share/opt/data/O35_mutil_cvr/20251127/part-r-29-747359-25771.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511260000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 2
}
intra_op_parallelism_threads: 8
inter_op_parallelism_threads: 8
gpu_options {
  per_process_gpu_memory_fraction: 0.9
  allow_growth: true
  visible_device_list: "0"
}
allow_soft_placement: true
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: GPU
INFO:tensorflow:Using GPUs: 0
INFO:tensorflow:Batch sizes - Train: 2048, Eval: 5120
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 2048, 'train_epoch': 1, 'batch_size': 5120}
seq_idxs=[]
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_0.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-04-103084-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-04-103084-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa643080820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:23:04.857255: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-28 10:23:04.857808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:04.857967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:04.858048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:05.278166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:05.278316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:05.278403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:05.278488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:23:05.333088: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:05.333194: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:05.424054: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:23:05.425081: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2025-11-28 10:23:07.828166: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1it [00:04,  4.52s/it]5121it [00:04, 1500.17it/s]10241it [00:05, 3318.83it/s]15361it [00:05, 5289.31it/s]20481it [00:05, 7397.03it/s]25771it [00:05, 4523.58it/s]
I1128 10:23:11.755553 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102311da334a1a0bab3bbdtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_1.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-21-541191-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-21-541191-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa5b52bae50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:23:16.077442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:16.077646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:16.077753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:16.077906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:16.078014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:16.078098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:23:16.144727: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:16.144850: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:16.250221: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:23:16.250394: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.48s/it]5121it [00:04, 1503.49it/s]10241it [00:04, 3344.58it/s]15361it [00:05, 5475.68it/s]20481it [00:05, 7586.02it/s]25771it [00:07, 3475.82it/s]
I1128 10:23:23.311368 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102323c254381a0bac3d87target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_2.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-02-51542-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-02-51542-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa57c06faf0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:23:27.578168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:27.578399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:27.578528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:27.578682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:27.578819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:27.578910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:23:27.634746: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:27.634888: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:27.731787: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:23:27.731922: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.19s/it]5121it [00:04, 1593.26it/s]10241it [00:04, 3536.82it/s]15361it [00:04, 5615.05it/s]20481it [00:05, 7894.05it/s]25771it [00:05, 4856.04it/s]
I1128 10:23:32.856168 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102332d4334a1a0bac01actarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_3.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-22-566962-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-22-566962-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa61166aa90> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:23:37.054469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:37.054688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:37.054796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:37.054947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:37.055056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:37.055142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:23:37.118892: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:37.119030: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:37.221402: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:23:37.221561: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.69s/it]5121it [00:04, 1431.64it/s]10241it [00:05, 3127.73it/s]15361it [00:05, 5037.23it/s]20481it [00:05, 7035.48it/s]25771it [00:05, 4349.71it/s]
I1128 10:23:42.778295 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810234294334a1a0bab7eedtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_4.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-16-412336-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-16-412336-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642b372b0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:23:47.046361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:47.046567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:47.046676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:47.046828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:47.046936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:47.047020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:23:47.110149: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:47.110291: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:47.212423: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:23:47.212578: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.59s/it]5121it [00:04, 1465.40it/s]10241it [00:05, 3280.88it/s]15361it [00:05, 5325.12it/s]20481it [00:05, 7336.12it/s]25771it [00:05, 4511.82it/s]
I1128 10:23:52.583184 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102352d2f2dc0b0c0d4dc8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_5.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-15-386565-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-15-386565-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642e01670> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:23:56.719508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:56.719724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:56.719846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:56.720002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:56.720111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:23:56.720198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:23:56.786059: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:56.786202: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:23:56.891086: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:23:56.891216: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.64s/it]5121it [00:04, 1458.20it/s]10241it [00:05, 3175.02it/s]15361it [00:05, 5062.23it/s]20481it [00:05, 7077.97it/s]25771it [00:05, 4386.30it/s]
I1128 10:24:02.473371 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810240259c7dc0b0c0d5f33target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_6.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-17-438107-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-17-438107-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642d8b6d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:24:06.481671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:06.481884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:06.481992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:06.482142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:06.482249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:06.482334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:24:06.550018: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:06.550151: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:06.656943: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:24:06.657073: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.38s/it]5121it [00:04, 1535.97it/s]10241it [00:04, 3319.03it/s]15361it [00:05, 5279.68it/s]20481it [00:05, 7403.32it/s]25771it [00:05, 4602.20it/s]
I1128 10:24:12.172401 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810241254f5da0b0c0cdf1etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_7.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-27-695817-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-27-695817-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642e385b0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:24:16.213362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:16.213578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:16.213686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:16.213839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:16.213956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:16.214041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:24:16.283798: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:16.283934: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:16.389300: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:24:16.389602: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.45s/it]5121it [00:04, 1508.72it/s]10241it [00:04, 3328.94it/s]15361it [00:05, 5349.52it/s]20481it [00:05, 7578.20it/s]25771it [00:05, 4640.75it/s]
I1128 10:24:21.597057 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102421cbcfdc0b0c0d9b38target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_8.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-19-489649-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-19-489649-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642e15e80> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:24:26.096708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:26.096929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:26.097038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:26.097194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:26.097303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:26.097389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:24:26.170744: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:26.170927: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:26.279259: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:24:26.279403: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.30s/it]5121it [00:04, 1573.64it/s]10241it [00:04, 3419.32it/s]15361it [00:05, 5523.12it/s]20481it [00:05, 7778.39it/s]25771it [00:05, 4758.76it/s]
I1128 10:24:31.608921 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102431e5cfdc0b0c0d0384target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_9.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-29-747359-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-29-747359-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa611875070> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:24:35.549798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:35.550023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:35.550134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:35.550287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:35.550395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:35.550488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:24:35.619707: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:35.619854: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:35.727178: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:24:35.727336: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.51s/it]5121it [00:04, 1515.67it/s]10241it [00:04, 3317.90it/s]15361it [00:05, 5325.12it/s]20481it [00:05, 7572.86it/s]25771it [00:05, 4597.90it/s]
I1128 10:24:41.029762 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810244093334a1a0babb848target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_10.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-09-231939-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-09-231939-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa5bf913490> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:24:45.145486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:45.145684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:45.145791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:45.145942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:45.146051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:45.146148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:24:45.210909: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:45.211057: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:45.313042: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:24:45.313186: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.52s/it]5121it [00:04, 1484.90it/s]10241it [00:05, 3323.10it/s]15361it [00:05, 5348.10it/s]20481it [00:05, 7395.59it/s]25771it [00:05, 4565.80it/s]
I1128 10:24:50.410899 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102450c6983c0a0bac50d2target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_11.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-13-335023-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-13-335023-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642b931f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:24:54.445804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:54.446041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:54.446150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:54.446306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:54.446415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:24:54.446500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:24:54.517995: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:54.518126: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:24:54.627561: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:24:54.627710: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.82s/it]5121it [00:05, 1398.93it/s]10241it [00:05, 3102.56it/s]15361it [00:05, 4976.07it/s]20481it [00:05, 7016.16it/s]25771it [00:05, 4306.82it/s]
I1128 10:25:00.048757 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102459c254381a0bac5867target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_12.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-01-25771-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-01-25771-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642dbaaf0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:25:03.731471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:03.731712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:03.731851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:03.732049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:03.732178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:03.732273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:25:03.803120: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:03.803244: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:03.910899: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:25:03.911053: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.60s/it]5121it [00:04, 1468.33it/s]10241it [00:05, 3228.16it/s]15361it [00:05, 5172.98it/s]20481it [00:05, 7404.17it/s]25771it [00:05, 4503.40it/s]
I1128 10:25:09.039450 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810250854f5da0b0c0cee76target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_13.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-20-515420-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-20-515420-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642ccd2b0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:25:13.454708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:13.454926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:13.455034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:13.455198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:13.455308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:13.455407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:25:13.523477: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:13.523623: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:13.628601: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:25:13.628738: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.32s/it]5121it [00:04, 1560.83it/s]10241it [00:04, 3364.98it/s]15361it [00:05, 5414.31it/s]20481it [00:05, 7459.43it/s]25771it [00:05, 4660.78it/s]
I1128 10:25:18.855431 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102518d8334a1a0baba55ctarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_14.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-07-180397-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-07-180397-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642ac7ca0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:25:22.928034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:22.928244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:22.928355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:22.928512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:22.928622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:22.928709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:25:22.997760: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:22.997912: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:23.103255: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:25:23.103395: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.41s/it]5121it [00:04, 1546.76it/s]10241it [00:04, 3342.15it/s]15361it [00:05, 5457.79it/s]20481it [00:05, 7479.54it/s]25771it [00:05, 4635.25it/s]
I1128 10:25:28.385141 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810252818a9fe0a0bac35d4target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_15.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-12-309252-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-12-309252-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa6430435e0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:25:32.632031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:32.632243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:32.632353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:32.632515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:32.632627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:32.632713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:25:32.704826: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:32.704983: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:32.813689: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:25:32.813838: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.35s/it]5121it [00:04, 1551.88it/s]10241it [00:04, 3363.66it/s]15361it [00:05, 5414.86it/s]20481it [00:05, 7459.31it/s]25771it [00:05, 4647.14it/s]
I1128 10:25:38.120802 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102538c557381a0bac5460target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_16.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-28-721588-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-28-721588-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642a69340> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:25:42.358034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:42.358252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:42.358375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:42.358528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:42.358638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:42.358725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:25:42.423722: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:42.423859: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:42.528940: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:25:42.529065: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.37s/it]5121it [00:04, 1524.83it/s]10241it [00:04, 3334.40it/s]15361it [00:05, 5318.02it/s]20481it [00:05, 7414.07it/s]25771it [00:05, 4629.52it/s]
I1128 10:25:47.731678 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102547b0973c0a0bac4266target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_17.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-18-463878-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-18-463878-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa611813400> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:25:51.782156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:51.782387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:51.782497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:51.782656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:51.782765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:25:51.782860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:25:51.851786: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:51.851933: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:25:51.954210: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:25:51.954357: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.50s/it]5121it [00:04, 1515.16it/s]10241it [00:05, 3275.12it/s]15361it [00:05, 5229.85it/s]20481it [00:05, 7221.03it/s]25771it [00:05, 4514.65it/s]
I1128 10:25:57.169523 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810255794334a1a0baba3cbtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_18.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-30-773130-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-30-773130-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa5b55ba9a0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:26:01.199268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:01.199497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:01.199622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:01.199780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:01.199891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:01.199977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:26:01.269400: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:01.269568: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:01.376869: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:26:01.385083: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.67s/it]5121it [00:04, 1469.03it/s]10241it [00:05, 3242.91it/s]15361it [00:05, 5177.79it/s]20481it [00:05, 7288.38it/s]25771it [00:05, 4449.81it/s]
I1128 10:26:06.811499 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810260691973c0a0bac1085target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_19.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-08-206168-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-08-206168-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642de7c10> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:26:10.792922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:10.793136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:10.793257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:10.793413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:10.793524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:10.793612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:26:10.866085: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:10.866251: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:10.972792: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:26:10.972934: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.60s/it]5121it [00:04, 1489.03it/s]10241it [00:05, 3243.64it/s]15361it [00:05, 5228.80it/s]20481it [00:05, 7488.08it/s]25771it [00:05, 4541.68it/s]
I1128 10:26:16.229176 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102616d8334a1a0babb575target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_20.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-24-618504-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-24-618504-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642b6e910> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:26:20.451923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:20.452126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:20.452236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:20.452390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:20.452500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:20.452587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:26:20.524746: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:20.524904: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:20.622040: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:26:20.622218: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.50s/it]5121it [00:04, 1524.95it/s]10241it [00:04, 3322.71it/s]15361it [00:05, 5343.77it/s]20481it [00:05, 7574.65it/s]25771it [00:05, 4599.78it/s]
I1128 10:26:25.864882 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102625c254381a0bac70c7target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_21.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-14-360794-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-14-360794-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa6116dd430> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:26:30.026287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:30.026507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:30.026648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:30.026805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:30.026915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:30.027002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:26:30.099373: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:30.099537: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:30.212420: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:26:30.212840: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.71s/it]5121it [00:04, 1450.85it/s]10241it [00:05, 3184.26it/s]15361it [00:05, 5283.05it/s]20481it [00:05, 7496.46it/s]25771it [00:05, 4471.60it/s]
I1128 10:26:35.503185 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810263530f3da0b0c0d8d8etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_22.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-10-257710-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-10-257710-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642cf7430> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:26:39.450955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:39.457685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:39.459620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:39.459830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:39.459974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:39.460374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:26:39.526864: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:39.527008: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:39.635545: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:26:39.635704: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.44s/it]5121it [00:04, 1518.33it/s]10241it [00:04, 3325.47it/s]15361it [00:05, 5281.49it/s]20481it [00:05, 7456.33it/s]25771it [00:05, 4612.77it/s]
I1128 10:26:44.815143 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810264412344a1a0baba57btarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_23.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-25-644275-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-25-644275-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa5b81e5820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:26:48.774098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:48.774301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:48.774408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:48.774561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:48.774669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:48.774755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:26:48.843534: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:48.843683: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:48.951446: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:26:48.951587: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.33s/it]5121it [00:04, 1546.85it/s]10241it [00:04, 3334.82it/s]15361it [00:05, 5440.39it/s]20481it [00:05, 7523.75it/s]25771it [00:05, 4662.30it/s]
I1128 10:26:54.167874 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102654e5cfdc0b0c0d2c9ftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_24.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-05-128855-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-05-128855-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642eb3730> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:26:58.206319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:58.206524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:58.206645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:58.206799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:58.206908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:26:58.206994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:26:58.275730: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:58.275891: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:26:58.383501: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:26:58.383675: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.90s/it]5121it [00:04, 1703.70it/s]10241it [00:04, 3644.53it/s]15361it [00:04, 5889.76it/s]20481it [00:04, 8009.82it/s]25771it [00:05, 5066.44it/s]
I1128 10:27:03.185235 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810270393973c0a0bac7844target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_25.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-00-0-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-00-0-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642fea5e0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:27:07.135785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:07.136003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:07.136113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:07.136279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:07.136391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:07.136478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:27:07.206795: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:07.206949: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:07.314046: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:27:07.314171: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.78s/it]5121it [00:04, 1776.23it/s]10241it [00:04, 3795.11it/s]15361it [00:04, 6063.88it/s]20481it [00:04, 8372.15it/s]25771it [00:04, 5260.01it/s]
I1128 10:27:11.871890 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102711e7c7dc0b0c0d6fb8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_26.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-23-592733-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-23-592733-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642b50580> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:27:15.736468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:15.736638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:15.736720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:15.736845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:15.736925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:15.737001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:27:15.782995: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:15.783104: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:15.887457: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:27:15.887633: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.88s/it]5121it [00:04, 1706.78it/s]10241it [00:04, 3682.01it/s]15361it [00:04, 5858.50it/s]20481it [00:04, 7958.28it/s]25771it [00:05, 5068.72it/s]
I1128 10:27:20.599449 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102720c557381a0bac7220target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_27.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-26-670046-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-26-670046-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa642df6a00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:27:24.301118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:24.301300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:24.301381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:24.301506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:24.301587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:24.301652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:27:24.350048: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:24.350145: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:24.421965: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:27:24.422104: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.61s/it]5121it [00:03, 1827.28it/s]10241it [00:04, 3920.06it/s]15361it [00:04, 6109.60it/s]20481it [00:04, 8367.67it/s]25771it [00:04, 5399.61it/s]
I1128 10:27:29.116666 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102728b2973c0a0bac00f6target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_28.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-31-798901-3.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-31-798901-3.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa5547f6d90> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:27:33.268216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:33.268442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:33.268553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:33.268710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:33.268819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:33.268906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:27:33.337470: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:33.337623: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:33.443505: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:27:33.443644: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.30s/it]3it [00:02,  1.29it/s]
I1128 10:27:35.283086 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102735d8c7dc0b0c0d1674target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_29.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-11-283481-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-11-283481-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa611775b50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:27:38.864940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:38.865163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:38.865276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:38.865430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:38.865539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:38.865626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:27:38.935902: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:38.936056: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:39.043849: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:27:39.044224: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.97s/it]5121it [00:04, 1677.69it/s]10241it [00:04, 3633.54it/s]15361it [00:04, 5693.89it/s]20481it [00:05, 7738.20it/s]25771it [00:07, 3489.41it/s]
I1128 10:27:45.913761 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251128102745a3cfdc0b0c0d501btarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_30.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-06-154626-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-06-154626-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa5b5210b50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:27:49.950518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:49.950736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:49.950857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:49.951019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:49.951129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:49.951215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:27:50.023584: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:50.023724: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:50.139551: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-28 10:27:50.139684: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.46s/it]5121it [00:04, 1490.81it/s]10241it [00:05, 3269.31it/s]15361it [00:05, 5310.94it/s]20481it [00:05, 7605.12it/s]25771it [00:05, 4590.87it/s]
I1128 10:27:55.328876 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511281027551c344a1a0bac3ecftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511270000_31.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251127/part-r-03-77313-25771.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251127/part-r-03-77313-25771.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 5120)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa6430b3b20> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa64307b820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-28 10:27:59.066404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:59.066697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:59.066820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:59.066987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:59.067113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-28 10:27:59.067204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511260000/model.ckpt-165395
2025-11-28 10:27:59.138594: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:59.138768: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-28 10:27:59.241249: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-28 10:27:59.241404: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:04,  4.26s/it]5121it [00:04, 1565.14it/s]10241it [00:04, 3408.38it/s]15361it [00:05, 5445.41it/s]20481it [00:05, 7798.14it/s]25771it [00:05, 4779.67it/s]
I1128 10:28:04.460235 140352742827840 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112810280412344a1a0babbe9etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303'>
INFO:tensorflow:mode: infer device: GPU task_type: chief task_idx: 0 time_str: 202511270000 end_time_str: None waste: 5.06 mins
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511270000,feature_type=O35_mutil_cvr_v10,infer_time=20251128102303
/data/share/opt/model/O35_mutil_cvr_v10
----------------------------clear history data--------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
seq_idxs=[]
(Namespace(curr_date='20251127', data_path='/data/share/opt/data', del_date=None), [])
---------del_path=/data/share/opt/data/O35_mutil_cvr/20251028--------
 /data/share/opt/model/O35_mutil_cvr_v10/export_dir/1763346032 diff days 11 
/data/share/opt/model/O35_mutil_cvr_v10
