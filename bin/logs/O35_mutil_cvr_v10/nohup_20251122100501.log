nohup: ignoring input
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
--> time_str: 202511210000, end_date: 202511210000
---------------------------------main-train-------------------------------------
---------------------------------export.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-export-------------------------------------
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-23 13:33:13.748196: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-23 13:33:13.748246: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:33:13.748252: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:33:13.748380: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-23 13:33:13.748403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-23 13:33:13.748408: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:Using CPU for training
INFO:tensorflow:time_str=20251121, end_time_str=20251121
INFO:tensorflow:train_date={'20251121': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-10-911920-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-25-2279800-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-11-1003112-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-18-1641456-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-12-1094304-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-23-2097416-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-08-729536-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-26-2370992-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-13-1185496-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-28-2553376-91192.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511210000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 0
}
intra_op_parallelism_threads: 16
inter_op_parallelism_threads: 16
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: CPU
INFO:tensorflow:Batch sizes - Train: 2048, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 2048, 'train_epoch': 1, 'batch_size': 1024}
seq_idxs=[]
defalut feature:Tensor("StringJoin:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_1:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_2:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_3:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_4:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_5:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_6:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_7:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_8:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_9:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_10:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_11:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_12:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_13:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_14:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_15:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_16:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_17:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_18:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_19:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_20:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_21:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_22:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_23:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_24:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_25:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_26:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_27:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_28:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_29:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_30:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_31:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_32:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_33:0", shape=(None,), dtype=string)
feature:user__imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_34:0", shape=(None,), dtype=string)
feature:user__clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_35:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_36:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_37:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_38:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_39:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_40:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_41:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_42:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_43:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_44:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_45:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_46:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_47:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_48:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_49:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_50:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_51:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_52:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_53:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_54:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_55:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_56:0", shape=(None,), dtype=string)
feature:user__imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_57:0", shape=(None,), dtype=string)
feature:user__clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_58:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_59:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_60:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_61:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_62:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_63:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_64:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_65:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_66:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_67:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_68:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_69:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_70:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_71:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_72:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_73:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_74:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_75:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_76:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_77:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_78:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_79:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_80:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_81:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_82:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_83:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_84:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_85:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_86:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_87:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_88:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_89:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_90:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_91:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_92:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_93:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_94:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_95:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_96:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_97:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_98:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_99:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_100:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_101:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_102:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_103:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_104:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_105:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_106:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_107:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_108:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_109:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_110:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_111:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_112:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_113:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_114:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_115:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_116:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_117:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_118:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_119:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_120:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_121:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_122:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_123:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_124:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_125:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_126:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_127:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_128:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_129:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_130:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_131:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_132:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_133:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_134:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_135:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_136:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_137:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_138:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_139:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_140:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_141:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_142:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_143:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_144:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_145:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_146:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_147:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_148:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_149:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_150:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_151:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_152:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_153:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_154:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_155:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_156:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_157:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_158:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_159:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_160:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_161:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_162:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_163:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_164:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_165:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_166:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_167:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_168:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_169:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_170:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_171:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_172:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_173:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_174:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_175:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_176:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_177:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_178:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_179:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_180:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_181:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_182:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_183:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_184:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_185:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_186:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_187:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_188:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_189:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_190:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_191:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_192:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_193:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_194:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_195:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_196:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_197:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_198:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_199:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_200:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_201:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_202:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_203:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_204:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_205:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_206:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_207:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_208:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_209:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_210:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_211:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_212:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_213:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_214:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_215:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_216:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_217:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_218:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_219:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_220:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_221:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_222:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_223:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_224:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_225:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_226:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_227:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_228:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_229:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_230:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_231:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_232:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_233:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_234:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_235:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_236:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_237:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_238:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_239:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_240:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_241:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_242:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_243:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_244:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_245:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_246:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_247:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_248:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_249:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_250:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_251:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_252:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_253:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_254:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_255:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_256:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_257:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_258:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_259:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_260:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_261:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_262:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_263:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_264:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_265:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_266:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_267:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_268:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_269:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_270:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_271:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_272:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_273:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_274:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_275:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_276:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_277:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_278:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_279:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_280:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_281:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_282:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_283:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_284:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_285:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_286:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_287:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_288:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_289:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_290:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_291:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_292:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_293:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_294:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_295:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_296:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_297:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_298:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_299:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_300:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_301:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_302:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_303:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_304:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_305:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_306:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_307:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_308:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_309:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_310:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_311:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_312:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_313:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_314:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_315:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_316:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_317:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_318:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_319:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_320:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_321:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_322:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_323:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_324:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_325:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_326:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_327:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_328:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_329:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_330:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_331:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_332:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_333:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_334:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_335:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_336:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_337:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_338:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_339:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_340:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_341:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_342:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_343:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_344:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_345:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_346:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_347:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_348:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_349:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_350:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_351:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_352:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_353:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_354:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_355:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_356:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_357:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_358:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_359:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_360:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_361:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_362:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_363:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_364:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_365:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_366:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_367:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_368:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_369:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_370:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_371:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_372:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_373:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_374:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_375:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_376:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_377:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_378:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_379:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_380:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_381:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_382:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_383:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_384:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_385:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_386:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_387:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_388:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_389:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_390:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_391:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_392:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_393:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_394:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_395:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_396:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_397:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_398:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_399:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_400:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_401:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_402:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_403:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_404:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_405:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_406:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_407:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_408:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_409:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_410:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_411:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_412:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_413:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_414:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_415:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_416:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_417:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_418:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_419:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_420:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_421:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_422:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_423:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_424:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_425:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_426:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_427:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_428:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_429:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_430:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_431:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_432:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_433:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_434:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_435:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_436:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_437:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_438:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_439:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_440:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_441:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_442:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_443:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_444:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_445:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_446:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_447:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_448:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_449:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_450:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_451:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_452:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_453:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_454:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_455:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_456:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_457:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_458:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_459:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_460:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_461:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_462:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_463:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_464:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_465:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_466:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_467:0", shape=(None,), dtype=string)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fa8fcc69370> -------
INFO:tensorflow:------ features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'export', 'ps_num': 0, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'CPU', 'gpu_ids': [], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is /job:localhost/replica:0/task:0/CPU:0 -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7fa8fcc695b0> emb_lookuped: Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("ctr_tower/zeros:0", shape=(None,), dtype=float32), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("awake_tower/zeros:0", shape=(None,), dtype=float32), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("mmoe_tower/zeros:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("mmoe_tower/zeros_1:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("mmoe_tower/zeros_2:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
2025-11-23 13:33:17.312337: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 13:33:17.640807: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:33:17.641138: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: /data/share/opt/model/O35_mutil_cvr_v10/export_dir/temp-1763875993/saved_model.pb
INFO:tensorflow:mode: export device: CPU task_type: chief task_idx: 0 time_str: 202511210000 end_time_str: None waste: 0.08 mins
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_468:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_469:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_470:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_471:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_472:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_473:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_474:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_475:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_476:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_477:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_478:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_479:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_480:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_481:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_482:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_483:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_484:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_485:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_486:0", shape=(None,), dtype=string)
features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} tensors: 487
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
-------------------------------generate_body---------------------------------------
seq_idxs=[]
(Namespace(day='20251121'), [])
[INFO/MainProcess] process shutting down
==================warmup.py:  export_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir ====================
2025-11-23 13:33:22.256105: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-23 13:33:22.256144: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:33:22.256149: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:33:22.256239: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-23 13:33:22.256257: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-23 13:33:22.256262: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
seq_idxs=[]
model_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir
body_file:/opt/huangmian/yoyo_model/config/O35_mutil_cvr_v10/body.json
files: [1762765103, 1762841767, 1762925502, 1763006534, 1763089185, 1763175233, 1763346032, 1763432182, 1763518248, 1763604706, 1763691680, 1763875993]
/data/share/opt/model/O35_mutil_cvr_v10
eval data:202511210000
---------------------------------eval.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-eval-------------------------------------
---------------------------------save_eval_metric------------------------------------
/data/share/opt/model/O35_mutil_cvr_v10/logs/202511210000.eval not metrice date, please check code!
/data/share/opt/model/O35_mutil_cvr_v10
infer data:202511210000
---------------------------------infer.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-infer-------------------------------------
ckpt_dir=/data/share/opt/model/O35_mutil_cvr_v10/202511200000, time_str=202511210000
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-23 13:35:52.190472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:52.190649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:52.198210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:52.198400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:52.198516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:52.198623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:time_str=20251121, end_time_str=20251121
INFO:tensorflow:train_date={'20251121': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-00-0-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-25-2279800-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-29-2644568-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-16-1459072-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-10-911920-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-01-91192-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-02-182384-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-05-455960-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-22-2006224-91192.gz', '/data/share/opt/data/O35_mutil_cvr/20251121/part-r-03-273576-91192.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511200000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 2
}
intra_op_parallelism_threads: 8
inter_op_parallelism_threads: 8
gpu_options {
  per_process_gpu_memory_fraction: 0.9
  allow_growth: true
  visible_device_list: "0"
}
allow_soft_placement: true
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: GPU
INFO:tensorflow:Using GPUs: 0
INFO:tensorflow:Batch sizes - Train: 2048, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 2048, 'train_epoch': 1, 'batch_size': 1024}
seq_idxs=[]
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_0.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-00-0-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-00-0-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051deb6610> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:35:53.988942: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-23 13:35:53.989523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:53.989697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:53.989800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:54.473298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:54.473494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:54.473617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:35:54.473753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:35:54.536028: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:35:54.536170: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:35:54.671356: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:35:54.674747: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2025-11-23 13:35:57.327470: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1it [00:05,  5.10s/it]2049it [00:05, 551.06it/s]4097it [00:05, 1269.18it/s]6145it [00:05, 2164.83it/s]8193it [00:05, 3233.70it/s]10241it [00:05, 4452.39it/s]12289it [00:05, 5770.31it/s]14337it [00:06, 7047.68it/s]16385it [00:06, 8034.44it/s]18433it [00:06, 9192.10it/s]20429it [00:06, 10989.85it/s]21930it [00:06, 10748.67it/s]23553it [00:06, 10759.63it/s]25601it [00:07, 11385.89it/s]27649it [00:07, 11721.93it/s]29697it [00:07, 12162.95it/s]31745it [00:07, 12665.56it/s]33793it [00:07, 13191.48it/s]35841it [00:07, 13152.04it/s]37865it [00:07, 14700.92it/s]39413it [00:08, 13489.55it/s]40961it [00:08, 12394.78it/s]43009it [00:08, 12814.09it/s]45057it [00:08, 12709.33it/s]47105it [00:08, 12499.07it/s]49153it [00:08, 12589.51it/s]51201it [00:08, 12839.99it/s]53249it [00:09, 13044.61it/s]55297it [00:09, 13516.30it/s]57345it [00:09, 13622.82it/s]59393it [00:09, 13488.11it/s]61441it [00:09, 13674.91it/s]63489it [00:09, 13819.88it/s]65537it [00:10, 14149.94it/s]67585it [00:10, 14099.85it/s]69223it [00:10, 14619.62it/s]70704it [00:10, 13443.47it/s]72705it [00:10, 13951.22it/s]74753it [00:10, 14392.65it/s]76801it [00:10, 14622.46it/s]78849it [00:10, 14751.37it/s]80897it [00:11, 14624.15it/s]82945it [00:11, 14388.85it/s]84993it [00:11, 14467.13it/s]87039it [00:11, 15871.25it/s]88668it [00:11, 13871.48it/s]90113it [00:11, 12829.31it/s]91192it [00:11, 7698.85it/s] 
I1123 13:36:07.013729 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133606c756381a09e39856target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_1.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-25-2279800-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-25-2279800-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dbb1520> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:36:13.064200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:13.064425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:13.064539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:13.064704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:13.064817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:13.064908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:36:13.137593: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:36:13.137742: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:36:13.248961: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:36:13.249111: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.90s/it]2049it [00:04, 712.47it/s]4097it [00:04, 1611.65it/s]6145it [00:04, 2702.07it/s]8193it [00:04, 3958.92it/s]10241it [00:04, 5390.10it/s]12289it [00:04, 6939.39it/s]14337it [00:04, 8383.17it/s]16385it [00:05, 9570.74it/s]18433it [00:05, 10599.56it/s]20481it [00:05, 11357.87it/s]22529it [00:05, 11962.45it/s]24577it [00:05, 11994.79it/s]26625it [00:05, 12492.44it/s]28673it [00:05, 12952.90it/s]30721it [00:06, 12925.47it/s]32769it [00:06, 12967.48it/s]34817it [00:06, 13134.42it/s]36865it [00:06, 13311.60it/s]38913it [00:06, 13138.06it/s]40961it [00:06, 13121.29it/s]43009it [00:07, 12875.42it/s]45057it [00:07, 13066.93it/s]47105it [00:07, 12928.73it/s]49153it [00:07, 12762.24it/s]51201it [00:07, 12934.11it/s]53249it [00:07, 13220.93it/s]55297it [00:07, 13089.13it/s]57345it [00:08, 12985.70it/s]59393it [00:08, 13506.32it/s]61441it [00:08, 13725.07it/s]63489it [00:08, 13544.89it/s]65537it [00:08, 13581.18it/s]67585it [00:08, 13701.75it/s]69633it [00:09, 13868.77it/s]71681it [00:09, 14244.81it/s]73729it [00:09, 14843.92it/s]75777it [00:09, 15209.97it/s]77825it [00:09, 15359.22it/s]79873it [00:09, 15346.80it/s]81921it [00:09, 15223.00it/s]83969it [00:09, 14778.74it/s]86017it [00:10, 15130.81it/s]88065it [00:10, 15038.51it/s]90113it [00:10, 14717.19it/s]91192it [00:10, 8740.09it/s] 
I1123 13:36:23.449149 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313362371c7dc0b0a368bf9target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_2.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-29-2644568-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-29-2644568-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f04b6137e50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:36:29.226441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:29.226687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:29.226801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:29.226984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:29.227097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:29.227189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:36:29.301071: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:36:29.301217: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:36:29.412244: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:36:29.412392: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.82s/it]2049it [00:03, 722.66it/s]4097it [00:04, 1614.56it/s]6145it [00:04, 2704.47it/s]8193it [00:04, 3966.50it/s]10241it [00:04, 5280.07it/s]12289it [00:04, 6576.02it/s]14337it [00:04, 7746.65it/s]16385it [00:05, 8924.67it/s]18433it [00:05, 9885.15it/s]19708it [00:05, 10273.22it/s]21505it [00:05, 10867.83it/s]23553it [00:05, 11726.60it/s]25601it [00:05, 12096.60it/s]27649it [00:05, 12294.80it/s]29697it [00:06, 12599.80it/s]31590it [00:06, 13955.15it/s]33070it [00:06, 12171.52it/s]34817it [00:06, 11627.59it/s]36865it [00:06, 12408.98it/s]38913it [00:06, 12796.41it/s]40961it [00:07, 12892.20it/s]43009it [00:07, 12862.08it/s]45057it [00:07, 12895.30it/s]47105it [00:07, 12848.07it/s]49039it [00:07, 14239.14it/s]50525it [00:07, 12565.47it/s]52225it [00:07, 12224.37it/s]53911it [00:07, 13269.58it/s]55302it [00:08, 12083.16it/s]57345it [00:08, 12580.97it/s]59393it [00:08, 12801.63it/s]61441it [00:08, 13101.45it/s]63489it [00:08, 13008.45it/s]65537it [00:08, 13169.90it/s]67585it [00:09, 13105.54it/s]69633it [00:09, 13570.13it/s]71681it [00:09, 14052.33it/s]73729it [00:09, 14232.79it/s]75777it [00:09, 14123.11it/s]77825it [00:09, 14406.97it/s]79873it [00:09, 14997.15it/s]81921it [00:10, 14989.96it/s]83969it [00:10, 14541.85it/s]86017it [00:10, 14351.82it/s]88065it [00:10, 14302.23it/s]90113it [00:10, 14904.83it/s]91192it [00:10, 8578.96it/s] 
I1123 13:36:39.860514 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133639b2973c0a09e3dfb8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_3.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-16-1459072-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-16-1459072-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051d9c69a0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:36:45.049261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:45.049424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:45.049504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:45.049621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:45.049699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:36:45.049763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:36:45.101745: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:36:45.101893: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:36:45.187309: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:36:45.187446: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.69s/it]2049it [00:03, 745.37it/s]4097it [00:03, 1683.24it/s]6145it [00:04, 2813.97it/s]8193it [00:04, 4120.31it/s]10241it [00:04, 5504.00it/s]12289it [00:04, 6864.68it/s]14337it [00:04, 8176.70it/s]16381it [00:04, 10053.53it/s]17909it [00:04, 10150.31it/s]19457it [00:05, 10281.41it/s]21505it [00:05, 11355.39it/s]23553it [00:05, 11913.04it/s]25601it [00:05, 12440.79it/s]27649it [00:05, 12768.03it/s]29697it [00:05, 13041.48it/s]31745it [00:06, 13174.33it/s]33793it [00:06, 13417.62it/s]35841it [00:06, 13364.41it/s]37889it [00:06, 13187.18it/s]39937it [00:06, 12809.72it/s]41985it [00:06, 12896.56it/s]44033it [00:06, 13226.13it/s]46081it [00:07, 13347.55it/s]48129it [00:07, 13231.97it/s]50177it [00:07, 13071.92it/s]52225it [00:07, 12997.08it/s]54273it [00:07, 13257.17it/s]56321it [00:07, 13485.84it/s]57853it [00:07, 13889.28it/s]59393it [00:08, 13106.66it/s]61441it [00:08, 13241.10it/s]63489it [00:08, 13635.03it/s]65537it [00:08, 14091.00it/s]67585it [00:08, 13899.89it/s]69633it [00:08, 13569.00it/s]71681it [00:09, 14153.81it/s]73729it [00:09, 14848.06it/s]75777it [00:09, 14873.67it/s]77825it [00:09, 14787.61it/s]79873it [00:09, 14194.93it/s]81921it [00:09, 14091.93it/s]83969it [00:09, 14289.22it/s]86017it [00:09, 14108.68it/s]88065it [00:10, 14111.97it/s]90113it [00:10, 14126.30it/s]91192it [00:10, 8825.97it/s] 
I1123 13:36:55.403968 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133655dcc7dc0b0a36c3b4target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_4.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-10-911920-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-10-911920-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f04b63d1790> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:37:00.849008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:00.849235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:00.849361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:00.849535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:00.849651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:00.849743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:37:00.908463: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:00.908585: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:00.991975: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:37:00.992120: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.84s/it]2049it [00:03, 720.51it/s]3534it [00:04, 1396.44it/s]5121it [00:04, 2231.99it/s]7169it [00:04, 3540.11it/s]9217it [00:04, 4964.96it/s]11265it [00:04, 6373.48it/s]13313it [00:04, 7929.48it/s]15361it [00:05, 9287.19it/s]17409it [00:05, 10366.28it/s]19457it [00:05, 11095.62it/s]21178it [00:05, 12284.80it/s]22642it [00:05, 11679.05it/s]24577it [00:05, 11859.33it/s]26272it [00:05, 12972.05it/s]27690it [00:05, 11947.94it/s]29697it [00:06, 12239.53it/s]30981it [00:06, 12371.78it/s]32769it [00:06, 12159.12it/s]34817it [00:06, 12620.08it/s]36865it [00:06, 12744.44it/s]38913it [00:06, 12726.63it/s]40961it [00:06, 12901.01it/s]43009it [00:07, 12955.67it/s]45057it [00:07, 13386.54it/s]47105it [00:07, 13501.48it/s]49153it [00:07, 13677.19it/s]51201it [00:07, 13583.56it/s]53249it [00:07, 13770.08it/s]55297it [00:08, 13652.73it/s]57345it [00:08, 13656.08it/s]59393it [00:08, 13806.44it/s]61441it [00:08, 13982.09it/s]63489it [00:08, 14135.26it/s]65537it [00:08, 14688.82it/s]67585it [00:08, 14810.87it/s]69633it [00:09, 14480.82it/s]71681it [00:09, 14666.77it/s]73729it [00:09, 14567.14it/s]75777it [00:09, 14598.97it/s]77825it [00:09, 14650.31it/s]79873it [00:09, 14942.80it/s]81921it [00:09, 15307.68it/s]83969it [00:09, 15059.59it/s]86017it [00:10, 14756.34it/s]88065it [00:10, 14817.47it/s]90113it [00:10, 15115.32it/s]91192it [00:10, 8742.63it/s] 
I1123 13:37:11.520759 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133711d2f2dc0b0a3692aetarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_5.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-01-91192-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-01-91192-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f0391e69d00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:37:17.282518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:17.282741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:17.282858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:17.283023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:17.283139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:17.283227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:37:17.339029: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:17.339189: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:17.422476: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:37:17.422611: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.63s/it]2049it [00:03, 759.65it/s]4097it [00:03, 1707.88it/s]5888it [00:04, 2768.77it/s]7219it [00:04, 3553.14it/s]9217it [00:04, 5007.80it/s]11265it [00:04, 6532.34it/s]13313it [00:04, 7978.66it/s]15361it [00:04, 9238.95it/s]17409it [00:04, 10245.17it/s]19457it [00:05, 11184.59it/s]21505it [00:05, 11918.44it/s]23553it [00:05, 12161.18it/s]25601it [00:05, 12374.13it/s]27649it [00:05, 12559.49it/s]29697it [00:05, 12514.53it/s]31745it [00:06, 12873.08it/s]33793it [00:06, 13120.21it/s]35841it [00:06, 13443.76it/s]37889it [00:06, 13422.26it/s]39937it [00:06, 13786.22it/s]41985it [00:06, 13837.60it/s]44033it [00:06, 13717.25it/s]46081it [00:07, 13745.81it/s]48129it [00:07, 13463.93it/s]50177it [00:07, 13067.93it/s]52225it [00:07, 12993.21it/s]54273it [00:07, 12819.36it/s]56321it [00:07, 13044.73it/s]58369it [00:07, 13249.19it/s]60417it [00:08, 13596.06it/s]62465it [00:08, 13900.63it/s]64513it [00:08, 14060.83it/s]66561it [00:08, 14703.18it/s]68609it [00:08, 15165.88it/s]70657it [00:08, 14341.26it/s]72705it [00:08, 14332.96it/s]74753it [00:09, 14169.59it/s]76801it [00:09, 14054.59it/s]78849it [00:09, 14270.74it/s]80897it [00:09, 14392.64it/s]82945it [00:09, 14142.85it/s]84993it [00:09, 13795.61it/s]87041it [00:10, 13773.72it/s]89089it [00:10, 14005.66it/s]91192it [00:10, 8879.20it/s] 
I1123 13:37:27.868216 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133727a2eedc0b0a36b6c1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_6.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-02-182384-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-02-182384-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051db3c7c0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:37:33.426700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:33.426919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:33.427033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:33.427185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:33.427306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:33.427410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:37:33.501926: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:33.502081: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:33.610971: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:37:33.611143: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.45s/it]2049it [00:03, 799.35it/s]4097it [00:03, 1789.88it/s]6145it [00:03, 2960.47it/s]8193it [00:04, 4300.13it/s]10241it [00:04, 5716.87it/s]12289it [00:04, 7198.16it/s]14337it [00:04, 8544.90it/s]16385it [00:04, 9783.91it/s]18433it [00:04, 10612.20it/s]20481it [00:04, 11268.44it/s]22529it [00:05, 11971.28it/s]24577it [00:05, 12520.62it/s]26625it [00:05, 12813.70it/s]28673it [00:05, 13154.46it/s]30721it [00:05, 13534.12it/s]32769it [00:05, 13838.65it/s]34817it [00:05, 14070.45it/s]36865it [00:06, 13996.63it/s]38913it [00:06, 14221.53it/s]40961it [00:06, 14366.00it/s]43009it [00:06, 14187.35it/s]45057it [00:06, 13989.84it/s]47105it [00:06, 14339.31it/s]49153it [00:06, 14200.55it/s]51201it [00:07, 14013.01it/s]53249it [00:07, 13810.95it/s]55297it [00:07, 13612.80it/s]57345it [00:07, 13452.44it/s]59393it [00:07, 13733.96it/s]61441it [00:07, 13575.88it/s]63489it [00:08, 13375.54it/s]65537it [00:08, 13327.87it/s]67585it [00:08, 13218.70it/s]69633it [00:08, 13207.22it/s]71681it [00:08, 13219.67it/s]73729it [00:08, 13457.72it/s]75777it [00:08, 13240.84it/s]77825it [00:09, 13428.45it/s]79873it [00:09, 13672.35it/s]81921it [00:09, 13811.59it/s]83969it [00:09, 14101.36it/s]86017it [00:09, 14048.75it/s]88065it [00:09, 13941.37it/s]90113it [00:09, 14020.01it/s]91192it [00:10, 9088.48it/s] 
I1123 13:37:43.331375 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313374312344a1a09e3a83etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_7.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-05-455960-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-05-455960-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051df10e50> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:37:48.975427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:48.975644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:48.975763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:48.975919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:48.976028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:37:48.976117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:37:49.042562: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:49.042704: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:37:49.147921: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:37:49.148072: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.37s/it]2049it [00:03, 817.09it/s]4097it [00:03, 1835.90it/s]6145it [00:03, 3045.41it/s]8193it [00:03, 4388.88it/s]10241it [00:04, 5786.96it/s]12289it [00:04, 7201.68it/s]14337it [00:04, 8563.20it/s]16385it [00:04, 9669.67it/s]18433it [00:04, 10568.27it/s]20481it [00:04, 11583.22it/s]22529it [00:04, 12368.84it/s]24577it [00:05, 12860.82it/s]26625it [00:05, 13246.09it/s]28673it [00:05, 13298.83it/s]30721it [00:05, 13597.83it/s]32769it [00:05, 14407.82it/s]34817it [00:05, 15279.82it/s]36865it [00:05, 16071.66it/s]38913it [00:06, 15885.63it/s]40961it [00:06, 15269.33it/s]43009it [00:06, 14745.79it/s]45057it [00:06, 14405.68it/s]47105it [00:06, 14510.67it/s]49153it [00:06, 14196.62it/s]51201it [00:06, 14145.52it/s]53249it [00:07, 14105.22it/s]55297it [00:07, 13971.66it/s]57345it [00:07, 13877.88it/s]59393it [00:07, 13762.86it/s]61441it [00:07, 13754.26it/s]63489it [00:07, 13790.41it/s]65537it [00:07, 13805.84it/s]67585it [00:08, 13897.73it/s]69633it [00:08, 13826.99it/s]71681it [00:08, 14027.83it/s]73729it [00:08, 14142.24it/s]75777it [00:08, 14142.10it/s]77825it [00:08, 14128.09it/s]79873it [00:08, 14230.47it/s]81921it [00:09, 14108.78it/s]83969it [00:09, 14007.47it/s]86017it [00:09, 13798.77it/s]88065it [00:09, 13868.14it/s]90113it [00:09, 13952.71it/s]91192it [00:09, 9308.77it/s] 
I1123 13:37:58.697045 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133758dda3cc0b0a367a75target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_8.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-22-2006224-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-22-2006224-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dedd2e0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:38:04.551646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:04.551859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:04.551966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:04.552120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:04.552238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:04.552327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:38:04.622148: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:04.622298: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:04.729443: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:38:04.729604: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.51s/it]2049it [00:03, 785.41it/s]4097it [00:03, 1766.88it/s]6145it [00:03, 2930.48it/s]8193it [00:04, 4264.59it/s]10241it [00:04, 5693.96it/s]12289it [00:04, 7085.38it/s]14337it [00:04, 8481.80it/s]16385it [00:04, 9720.89it/s]18433it [00:04, 10722.10it/s]20481it [00:04, 11418.93it/s]22529it [00:05, 11995.17it/s]24577it [00:05, 12377.21it/s]26625it [00:05, 12984.87it/s]28673it [00:05, 13242.75it/s]30721it [00:05, 13584.27it/s]32769it [00:05, 13697.28it/s]34817it [00:05, 14782.21it/s]36865it [00:06, 15271.40it/s]38913it [00:06, 15639.74it/s]40961it [00:06, 15027.24it/s]43009it [00:06, 14656.06it/s]45057it [00:06, 14353.06it/s]47105it [00:06, 13954.20it/s]49153it [00:06, 13799.80it/s]51201it [00:07, 13665.04it/s]53249it [00:07, 13568.48it/s]55297it [00:07, 13566.32it/s]57345it [00:07, 13509.53it/s]59393it [00:07, 13505.72it/s]61441it [00:07, 13565.99it/s]63489it [00:08, 13608.64it/s]65537it [00:08, 13915.99it/s]67585it [00:08, 14252.32it/s]69633it [00:08, 14371.66it/s]71681it [00:08, 14092.26it/s]73729it [00:08, 14110.58it/s]75777it [00:08, 14020.92it/s]77825it [00:09, 14008.06it/s]79873it [00:09, 14056.27it/s]81921it [00:09, 14026.88it/s]83969it [00:09, 13842.63it/s]86017it [00:09, 13777.37it/s]88065it [00:09, 13955.77it/s]90113it [00:09, 14123.55it/s]91192it [00:09, 9134.42it/s] 
I1123 13:38:14.668220 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133814b1973c0a09e4639btarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_9.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-03-273576-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-03-273576-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051de7e1c0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:38:19.950989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:19.951158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:19.951236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:19.951353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:19.951451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:19.951519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:38:19.998669: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:19.998790: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:20.071092: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:38:20.071254: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.88s/it]2049it [00:03, 949.85it/s]4097it [00:03, 2103.56it/s]6145it [00:03, 3456.92it/s]8193it [00:03, 4917.54it/s]10241it [00:03, 6436.84it/s]12289it [00:03, 7864.57it/s]14337it [00:03, 9135.06it/s]16385it [00:04, 10351.86it/s]18433it [00:04, 11359.38it/s]20481it [00:04, 12155.42it/s]22529it [00:04, 12596.46it/s]24577it [00:04, 13236.97it/s]26625it [00:04, 13717.98it/s]28673it [00:04, 13891.96it/s]30721it [00:05, 14128.22it/s]32769it [00:05, 14788.38it/s]34817it [00:05, 15210.91it/s]36865it [00:05, 15560.93it/s]38913it [00:05, 15840.72it/s]40961it [00:05, 15979.39it/s]43009it [00:05, 15275.93it/s]45057it [00:05, 15307.80it/s]47105it [00:06, 15034.62it/s]49153it [00:06, 14959.85it/s]51201it [00:06, 14499.15it/s]53249it [00:06, 14212.03it/s]55297it [00:06, 13997.88it/s]57345it [00:06, 13962.57it/s]59393it [00:06, 13861.94it/s]61441it [00:07, 13776.98it/s]63489it [00:07, 13667.15it/s]65537it [00:07, 13803.08it/s]67585it [00:07, 13658.42it/s]69633it [00:07, 13549.21it/s]71681it [00:07, 13611.15it/s]73729it [00:08, 13717.47it/s]75777it [00:08, 13777.57it/s]77825it [00:08, 14556.15it/s]79873it [00:08, 14478.23it/s]81921it [00:08, 14311.17it/s]83969it [00:08, 14081.39it/s]86017it [00:08, 14210.19it/s]88065it [00:08, 14849.57it/s]90113it [00:09, 14788.84it/s]91192it [00:09, 9931.59it/s] 
I1123 13:38:29.499711 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313382959c7dc0b0a36a83etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_10.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-07-638344-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-07-638344-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dc8fbb0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:38:34.954417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:34.954585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:34.954664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:34.954780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:34.954857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:34.954923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:38:35.000844: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:35.000948: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:35.071358: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:38:35.071504: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.12s/it]2049it [00:03, 878.80it/s]4097it [00:03, 1962.83it/s]6145it [00:03, 3223.92it/s]8193it [00:03, 4667.59it/s]10241it [00:03, 6180.51it/s]12289it [00:03, 7619.26it/s]14337it [00:04, 8876.59it/s]16385it [00:04, 9947.98it/s]18433it [00:04, 10863.95it/s]20481it [00:04, 11698.43it/s]22529it [00:04, 12237.42it/s]24577it [00:04, 12700.47it/s]26625it [00:05, 13038.68it/s]28673it [00:05, 13252.76it/s]30721it [00:05, 13271.26it/s]32769it [00:05, 13272.29it/s]34817it [00:05, 13652.06it/s]36865it [00:05, 13799.40it/s]38913it [00:05, 13889.75it/s]40961it [00:06, 13717.71it/s]43009it [00:06, 13669.66it/s]45057it [00:06, 13616.91it/s]47105it [00:06, 13595.73it/s]49153it [00:06, 13506.14it/s]51201it [00:06, 13541.32it/s]53249it [00:06, 13518.84it/s]55297it [00:07, 13662.66it/s]57345it [00:07, 13962.50it/s]59393it [00:07, 14112.69it/s]61441it [00:07, 13985.01it/s]63489it [00:07, 14123.54it/s]65537it [00:07, 14148.91it/s]67585it [00:07, 14107.68it/s]69633it [00:08, 13955.89it/s]71681it [00:08, 13856.65it/s]73729it [00:08, 13882.81it/s]75777it [00:08, 13934.74it/s]77825it [00:08, 13896.93it/s]79873it [00:08, 13940.01it/s]81921it [00:09, 13861.30it/s]83969it [00:09, 13769.66it/s]86017it [00:09, 13741.39it/s]88065it [00:09, 13805.62it/s]90113it [00:09, 13517.62it/s]91192it [00:09, 9413.77it/s] 
I1123 13:38:44.571398 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313384459c7dc0b0a36ac2etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_11.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-23-2097416-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-23-2097416-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051d98eeb0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:38:50.437704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:50.437921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:50.438032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:50.438184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:50.438294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:38:50.438392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:38:50.507558: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:50.507698: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:38:50.615900: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:38:50.616048: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.53s/it]2049it [00:03, 781.41it/s]4097it [00:03, 1756.38it/s]6145it [00:03, 2913.79it/s]8193it [00:04, 4229.86it/s]10241it [00:04, 5620.43it/s]12289it [00:04, 7105.85it/s]14337it [00:04, 8513.91it/s]16385it [00:04, 9631.36it/s]18433it [00:04, 10729.77it/s]20481it [00:05, 11495.59it/s]22529it [00:05, 12107.70it/s]24577it [00:05, 12508.09it/s]26625it [00:05, 12755.20it/s]28673it [00:05, 12768.42it/s]30721it [00:05, 13168.78it/s]32769it [00:05, 13965.03it/s]34817it [00:06, 14389.96it/s]36865it [00:06, 14892.97it/s]38913it [00:06, 14604.75it/s]40961it [00:06, 14250.18it/s]43009it [00:06, 13968.69it/s]45057it [00:06, 13847.17it/s]47105it [00:06, 13762.27it/s]49153it [00:07, 13665.70it/s]51201it [00:07, 13593.92it/s]53249it [00:07, 13629.75it/s]55297it [00:07, 13894.67it/s]57345it [00:07, 13780.70it/s]59393it [00:07, 13698.91it/s]61441it [00:07, 13650.00it/s]63489it [00:08, 13941.95it/s]65537it [00:08, 14031.47it/s]67585it [00:08, 13950.58it/s]69633it [00:08, 13689.16it/s]71681it [00:08, 13723.38it/s]73729it [00:08, 13709.09it/s]75777it [00:08, 13871.73it/s]77825it [00:09, 13945.04it/s]79873it [00:09, 13946.20it/s]81921it [00:09, 13858.09it/s]83969it [00:09, 14034.66it/s]86017it [00:09, 14139.86it/s]88065it [00:09, 14026.99it/s]90113it [00:10, 13699.06it/s]91192it [00:10, 9052.59it/s] 
I1123 13:39:00.357969 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313390070c7dc0b0a36ad8etarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_12.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-17-1550264-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-17-1550264-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051ded0a00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:39:06.330115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:06.330338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:06.330455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:06.330624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:06.330742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:06.330839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:39:06.401362: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:06.401493: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:06.511424: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:39:06.511590: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.43s/it]2049it [00:03, 805.17it/s]4097it [00:03, 1809.83it/s]6145it [00:03, 2993.67it/s]8193it [00:04, 4321.76it/s]10241it [00:04, 5778.56it/s]12289it [00:04, 7271.41it/s]14337it [00:04, 8705.31it/s]16385it [00:04, 9835.31it/s]18433it [00:04, 10968.67it/s]20481it [00:04, 11796.01it/s]22529it [00:05, 12433.06it/s]24577it [00:05, 12664.50it/s]26625it [00:05, 12780.89it/s]28673it [00:05, 13097.59it/s]30721it [00:05, 13047.35it/s]32769it [00:05, 13714.27it/s]34817it [00:05, 13717.06it/s]36865it [00:06, 13875.12it/s]38913it [00:06, 13896.94it/s]40961it [00:06, 13916.96it/s]43009it [00:06, 13935.78it/s]45057it [00:06, 13944.38it/s]47105it [00:06, 13954.04it/s]49153it [00:06, 13943.23it/s]51201it [00:07, 14361.24it/s]53249it [00:07, 14248.10it/s]55297it [00:07, 14188.47it/s]57345it [00:07, 14146.69it/s]59393it [00:07, 13976.70it/s]61441it [00:07, 13892.18it/s]63489it [00:07, 13752.28it/s]65537it [00:08, 13782.55it/s]67585it [00:08, 13816.87it/s]69633it [00:08, 13715.64it/s]71681it [00:08, 13794.21it/s]73729it [00:08, 13876.38it/s]75777it [00:08, 13903.92it/s]77825it [00:09, 13812.32it/s]79873it [00:09, 13960.99it/s]81921it [00:09, 13912.91it/s]83969it [00:09, 14030.46it/s]86017it [00:09, 14032.18it/s]88065it [00:09, 13861.35it/s]90113it [00:09, 13940.48it/s]91192it [00:09, 9181.27it/s] 
I1123 13:39:16.311166 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133916b2973c0a09e40c46target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_13.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-12-1094304-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-12-1094304-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dd06df0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:39:21.859640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:21.859859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:21.859980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:21.860138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:21.860249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:21.860340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:39:21.930179: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:21.930318: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:22.040193: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:39:22.040350: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.45s/it]2049it [00:03, 800.82it/s]4097it [00:03, 1796.63it/s]6145it [00:03, 2995.54it/s]8193it [00:04, 4332.79it/s]10241it [00:04, 5785.31it/s]12289it [00:04, 7250.14it/s]14337it [00:04, 8657.82it/s]16385it [00:04, 9980.23it/s]18433it [00:04, 11069.43it/s]20481it [00:04, 11933.78it/s]22529it [00:05, 12476.91it/s]24577it [00:05, 13013.67it/s]26625it [00:05, 13366.08it/s]28673it [00:05, 13498.81it/s]30721it [00:05, 13796.27it/s]32769it [00:05, 14747.61it/s]34817it [00:05, 14574.26it/s]36865it [00:06, 14632.79it/s]38913it [00:06, 14578.60it/s]40961it [00:06, 14481.92it/s]43009it [00:06, 14315.18it/s]45057it [00:06, 13941.59it/s]47105it [00:06, 13981.05it/s]49153it [00:06, 13810.17it/s]51201it [00:07, 13849.32it/s]53249it [00:07, 13909.42it/s]55297it [00:07, 13882.01it/s]57345it [00:07, 13881.94it/s]59393it [00:07, 14781.29it/s]61441it [00:07, 14799.82it/s]63489it [00:07, 14460.54it/s]65537it [00:08, 14213.19it/s]67585it [00:08, 13779.16it/s]69633it [00:08, 14371.58it/s]71681it [00:08, 14187.23it/s]73729it [00:08, 13990.65it/s]75777it [00:08, 14029.87it/s]77825it [00:08, 13903.81it/s]79873it [00:09, 13921.97it/s]81921it [00:09, 13941.23it/s]83969it [00:09, 13819.61it/s]86017it [00:09, 13934.16it/s]88065it [00:09, 13786.51it/s]90113it [00:09, 13671.64it/s]91192it [00:09, 9251.04it/s] 
I1123 13:39:31.514722 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123133931d8e8da0b0a36ea55target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_14.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-15-1367880-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-15-1367880-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dc1dd90> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:39:36.913602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:36.913818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:36.913928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:36.914093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:36.914205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:36.914297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:39:36.986208: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:36.986358: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:37.095372: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:39:37.095514: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.40s/it]2049it [00:03, 810.62it/s]4097it [00:03, 1814.58it/s]6145it [00:03, 3005.34it/s]8193it [00:04, 4311.77it/s]10241it [00:04, 5718.74it/s]12289it [00:04, 7145.76it/s]14337it [00:04, 8443.76it/s]16385it [00:04, 9572.23it/s]18433it [00:04, 10678.02it/s]20481it [00:04, 11542.27it/s]22529it [00:05, 12200.43it/s]24577it [00:05, 12543.65it/s]26625it [00:05, 13042.86it/s]28673it [00:05, 13458.22it/s]30721it [00:05, 13604.79it/s]32769it [00:05, 14054.66it/s]34817it [00:05, 14739.50it/s]36865it [00:06, 14693.99it/s]38913it [00:06, 15099.82it/s]40961it [00:06, 14838.67it/s]43009it [00:06, 14817.66it/s]45057it [00:06, 14486.95it/s]47105it [00:06, 14095.27it/s]49153it [00:06, 13994.78it/s]51201it [00:07, 13999.69it/s]53249it [00:07, 13972.79it/s]55297it [00:07, 13807.77it/s]57345it [00:07, 13755.95it/s]59393it [00:07, 13732.81it/s]61441it [00:07, 13922.17it/s]63489it [00:07, 14134.74it/s]65537it [00:08, 13988.75it/s]67585it [00:08, 14371.51it/s]69633it [00:08, 14406.66it/s]71681it [00:08, 14577.67it/s]73729it [00:08, 14807.79it/s]75777it [00:08, 14914.03it/s]77825it [00:08, 14672.29it/s]79873it [00:09, 14246.81it/s]81921it [00:09, 14251.54it/s]83969it [00:09, 14168.66it/s]86017it [00:09, 13984.33it/s]88065it [00:09, 13969.16it/s]90113it [00:09, 13776.77it/s]91192it [00:09, 9269.20it/s] 
I1123 13:39:46.707269 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313394694334a1a09e3e739target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_15.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-08-729536-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-08-729536-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051db9d070> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:39:52.374187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:52.374398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:52.374519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:52.374680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:52.374791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:39:52.374882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:39:52.444908: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:52.445065: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:39:52.553953: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:39:52.554096: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.55s/it]2049it [00:03, 778.74it/s]4097it [00:03, 1740.33it/s]6145it [00:04, 2897.00it/s]8193it [00:04, 4201.34it/s]10241it [00:04, 5600.39it/s]12289it [00:04, 6988.98it/s]14337it [00:04, 8380.89it/s]16385it [00:04, 9641.74it/s]18433it [00:04, 10712.47it/s]20481it [00:05, 11451.66it/s]22529it [00:05, 11893.33it/s]24577it [00:05, 12311.75it/s]26625it [00:05, 12698.63it/s]28673it [00:05, 13146.42it/s]30721it [00:05, 13281.89it/s]32769it [00:05, 13487.17it/s]34817it [00:06, 13564.93it/s]36865it [00:06, 13653.39it/s]38913it [00:06, 13655.94it/s]40961it [00:06, 13723.26it/s]43009it [00:06, 13795.45it/s]45057it [00:06, 13761.61it/s]47105it [00:06, 13744.10it/s]49153it [00:07, 13842.71it/s]51201it [00:07, 13898.33it/s]53249it [00:07, 13777.48it/s]55297it [00:07, 13704.67it/s]57345it [00:07, 13685.65it/s]59393it [00:07, 13700.56it/s]61441it [00:08, 13631.13it/s]63489it [00:08, 13642.46it/s]65537it [00:08, 13524.03it/s]67585it [00:08, 13522.39it/s]69633it [00:08, 13515.81it/s]71681it [00:08, 13710.48it/s]73729it [00:08, 14092.42it/s]75777it [00:09, 14377.34it/s]77825it [00:09, 14309.72it/s]79873it [00:09, 14165.15it/s]81921it [00:09, 14199.69it/s]83969it [00:09, 14137.79it/s]86017it [00:09, 13910.61it/s]88065it [00:09, 13826.09it/s]90113it [00:10, 13848.95it/s]91192it [00:10, 9000.33it/s] 
I1123 13:40:02.291760 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134002c2c7dc0b0a36b8a8target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_16.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-19-1732648-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-19-1732648-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051da35d30> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:40:07.749963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:07.750246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:07.750358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:07.750511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:07.750704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:07.750790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:40:07.815968: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:07.816119: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:07.921790: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:40:07.921935: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.43s/it]2049it [00:03, 807.58it/s]4097it [00:03, 1817.64it/s]6145it [00:03, 3001.62it/s]8193it [00:03, 4392.70it/s]10241it [00:04, 5878.97it/s]12289it [00:04, 7353.09it/s]14337it [00:04, 8677.09it/s]16385it [00:04, 9951.32it/s]18433it [00:04, 11006.96it/s]20481it [00:04, 11962.59it/s]22529it [00:04, 12717.58it/s]24577it [00:05, 13237.18it/s]26625it [00:05, 13520.03it/s]28673it [00:05, 13701.85it/s]30721it [00:05, 13699.26it/s]32769it [00:05, 13907.84it/s]34817it [00:05, 15280.44it/s]36865it [00:05, 15973.90it/s]38913it [00:06, 16054.47it/s]40961it [00:06, 16203.26it/s]43009it [00:06, 15715.98it/s]45057it [00:06, 14956.38it/s]47105it [00:06, 14501.67it/s]49153it [00:06, 14275.24it/s]51201it [00:06, 14056.30it/s]53249it [00:07, 13917.03it/s]55297it [00:07, 13787.44it/s]57345it [00:07, 13701.56it/s]59393it [00:07, 13782.79it/s]61441it [00:07, 13793.91it/s]63489it [00:07, 13769.19it/s]65537it [00:07, 13666.52it/s]67585it [00:08, 13624.18it/s]69633it [00:08, 13590.68it/s]71681it [00:08, 13614.98it/s]73729it [00:08, 13679.56it/s]75777it [00:08, 13841.65it/s]77825it [00:08, 13680.87it/s]79873it [00:09, 13546.63it/s]81921it [00:09, 13447.59it/s]83969it [00:09, 13455.88it/s]86017it [00:09, 13402.93it/s]88065it [00:09, 13342.92it/s]90113it [00:09, 13367.39it/s]91192it [00:09, 9267.98it/s] 
I1123 13:40:17.778479 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134017b0973c0a09e46453target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_17.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-09-820728-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-09-820728-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dd6e3a0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:40:23.503449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:23.503718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:23.503843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:23.504012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:23.504133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:23.504228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:40:23.574358: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:23.574596: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:23.685197: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:40:23.685332: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.50s/it]2049it [00:03, 791.16it/s]4097it [00:03, 1778.19it/s]6145it [00:03, 2951.71it/s]8193it [00:04, 4252.35it/s]10241it [00:04, 5671.24it/s]12289it [00:04, 7132.35it/s]14337it [00:04, 8313.05it/s]16385it [00:04, 9416.36it/s]18433it [00:04, 10492.85it/s]20481it [00:04, 11558.04it/s]22529it [00:05, 12226.72it/s]24577it [00:05, 12606.57it/s]26625it [00:05, 12758.84it/s]28673it [00:05, 13124.82it/s]30721it [00:05, 13270.07it/s]32769it [00:05, 13474.54it/s]34817it [00:06, 13347.26it/s]36865it [00:06, 13690.61it/s]38913it [00:06, 14252.28it/s]40961it [00:06, 14169.44it/s]43009it [00:06, 14033.93it/s]45057it [00:06, 13812.27it/s]47105it [00:06, 13916.48it/s]49153it [00:07, 14253.96it/s]51201it [00:07, 14321.64it/s]53249it [00:07, 14007.34it/s]55297it [00:07, 13844.26it/s]57345it [00:07, 13816.82it/s]59393it [00:07, 14279.05it/s]61441it [00:07, 14345.46it/s]63489it [00:08, 15082.05it/s]65537it [00:08, 15190.23it/s]67585it [00:08, 14891.76it/s]69633it [00:08, 14535.32it/s]71681it [00:08, 14190.33it/s]73729it [00:08, 14166.86it/s]75777it [00:08, 13876.76it/s]77825it [00:09, 13710.40it/s]79873it [00:09, 13566.03it/s]81921it [00:09, 13368.34it/s]83969it [00:09, 13245.41it/s]86017it [00:09, 13248.17it/s]88065it [00:09, 13249.65it/s]90113it [00:09, 13244.83it/s]91192it [00:10, 9084.41it/s] 
I1123 13:40:33.591609 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313403354f5da0b0a364f90target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_18.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-24-2188608-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-24-2188608-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f04b6152040> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:40:38.953040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:38.953272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:38.953389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:38.953548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:38.953660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:38.953750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:40:39.017299: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:39.017433: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:39.114384: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:40:39.114540: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.42s/it]2049it [00:03, 811.91it/s]4097it [00:03, 1815.43it/s]6145it [00:03, 3013.36it/s]8193it [00:03, 4364.14it/s]10241it [00:04, 5822.71it/s]12289it [00:04, 7229.37it/s]14337it [00:04, 8526.13it/s]16385it [00:04, 9708.54it/s]18433it [00:04, 10481.42it/s]20481it [00:04, 11245.12it/s]22529it [00:05, 11528.28it/s]24577it [00:05, 12114.38it/s]26625it [00:05, 12487.51it/s]28673it [00:05, 12826.53it/s]30721it [00:05, 13269.63it/s]32769it [00:05, 13295.91it/s]34817it [00:05, 13420.88it/s]36865it [00:06, 13930.51it/s]38913it [00:06, 14070.66it/s]40961it [00:06, 14286.30it/s]43009it [00:06, 14140.01it/s]45057it [00:06, 14616.82it/s]47105it [00:06, 14354.41it/s]49153it [00:06, 14046.61it/s]51201it [00:07, 13940.71it/s]53249it [00:07, 13962.84it/s]55297it [00:07, 14036.90it/s]57345it [00:07, 13910.68it/s]59393it [00:07, 13871.61it/s]61441it [00:07, 13853.83it/s]63489it [00:07, 13842.92it/s]65537it [00:08, 13751.27it/s]67585it [00:08, 13686.87it/s]69633it [00:08, 13611.60it/s]71681it [00:08, 13669.62it/s]73729it [00:08, 13805.98it/s]75777it [00:08, 13861.43it/s]77825it [00:09, 14386.09it/s]79873it [00:09, 14728.84it/s]81921it [00:09, 14419.82it/s]83969it [00:09, 13925.45it/s]86017it [00:09, 13923.96it/s]88065it [00:09, 14011.25it/s]90113it [00:09, 13942.19it/s]91192it [00:09, 9163.68it/s] 
I1123 13:40:48.901435 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134048d2334a1a03fe2c68target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_19.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-31-2826952-11.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-31-2826952-11.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051db35f10> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:40:54.502426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:54.502658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:54.502772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:54.502935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:54.503050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:54.503142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:40:54.575029: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:54.575183: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:40:54.684461: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:40:54.684611: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.33s/it]11it [00:02,  4.68it/s]
I1123 13:40:56.240907 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134056a2eedc0b0a36ef55target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_20.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-06-547152-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-06-547152-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f04b62a13d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:40:59.980912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:59.981128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:59.981258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:59.981413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:59.981520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:40:59.981609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:41:00.048408: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:00.048570: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:00.159154: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:41:00.159304: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.42s/it]2049it [00:03, 805.79it/s]4097it [00:03, 1813.55it/s]6145it [00:03, 3024.78it/s]8193it [00:03, 4394.13it/s]10241it [00:04, 5768.68it/s]12289it [00:04, 7268.16it/s]14337it [00:04, 8633.07it/s]16385it [00:04, 9794.62it/s]18433it [00:04, 10707.08it/s]20481it [00:04, 11494.74it/s]22529it [00:05, 12003.29it/s]24577it [00:05, 12452.32it/s]26625it [00:05, 12875.58it/s]28673it [00:05, 13237.74it/s]30721it [00:05, 13257.43it/s]32769it [00:05, 14425.92it/s]34817it [00:05, 14906.10it/s]36865it [00:06, 14905.64it/s]38913it [00:06, 14961.04it/s]40961it [00:06, 15342.85it/s]43009it [00:06, 15530.17it/s]45057it [00:06, 15164.79it/s]47105it [00:06, 14687.71it/s]49153it [00:06, 14344.85it/s]51201it [00:06, 14406.24it/s]53249it [00:07, 14360.78it/s]55297it [00:07, 14455.54it/s]57345it [00:07, 14064.28it/s]59393it [00:07, 14019.81it/s]61441it [00:07, 13957.50it/s]63489it [00:07, 13901.80it/s]65537it [00:08, 13775.88it/s]67585it [00:08, 13916.86it/s]69633it [00:08, 13787.40it/s]71681it [00:08, 13722.76it/s]73729it [00:08, 13823.96it/s]75777it [00:08, 13945.28it/s]77825it [00:08, 14040.09it/s]79873it [00:09, 13991.53it/s]81921it [00:09, 13998.86it/s]83969it [00:09, 13772.34it/s]86017it [00:09, 13770.95it/s]88065it [00:09, 14008.01it/s]90113it [00:09, 13966.60it/s]91192it [00:12, 7268.10it/s] 
I1123 13:41:12.391275 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313411270c7dc0b0a36d04atarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_21.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-13-1185496-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-13-1185496-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dbd4610> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:41:18.223956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:18.224169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:18.224280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:18.224437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:18.224551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:18.224647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:41:18.291303: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:18.291474: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:18.395252: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:41:18.395411: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.32s/it]2049it [00:03, 828.11it/s]4097it [00:03, 1856.73it/s]6145it [00:03, 3092.50it/s]8193it [00:03, 4488.95it/s]10241it [00:04, 5949.37it/s]12289it [00:04, 7380.02it/s]14337it [00:04, 8813.57it/s]16385it [00:04, 9943.83it/s]18433it [00:04, 10905.79it/s]20481it [00:04, 11823.24it/s]22529it [00:04, 12609.06it/s]24577it [00:05, 13311.28it/s]26625it [00:05, 13853.71it/s]28673it [00:05, 14238.68it/s]30721it [00:05, 13929.26it/s]32769it [00:05, 14017.30it/s]34817it [00:05, 14134.46it/s]36865it [00:05, 13900.43it/s]38913it [00:06, 14039.00it/s]40961it [00:06, 14011.94it/s]43009it [00:06, 13798.70it/s]45057it [00:06, 13940.78it/s]47105it [00:06, 13989.60it/s]49153it [00:06, 14134.76it/s]51201it [00:06, 14131.62it/s]53249it [00:07, 13851.72it/s]55297it [00:07, 13621.74it/s]57345it [00:07, 13532.57it/s]59393it [00:07, 13338.63it/s]61441it [00:07, 13318.97it/s]63489it [00:07, 13720.16it/s]65537it [00:07, 13847.38it/s]67585it [00:08, 13732.96it/s]69633it [00:08, 13796.24it/s]71681it [00:08, 14074.30it/s]73729it [00:08, 14149.27it/s]75777it [00:08, 14358.79it/s]77825it [00:08, 14531.92it/s]79873it [00:08, 15247.97it/s]81921it [00:09, 15428.31it/s]83969it [00:09, 15055.87it/s]86017it [00:09, 14825.11it/s]88065it [00:09, 15011.11it/s]90113it [00:09, 14637.07it/s]91192it [00:09, 9403.81it/s] 
I1123 13:41:27.999844 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134127c557381a09e4a04atarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_22.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-04-364768-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-04-364768-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051ded0820> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:41:33.292537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:33.292756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:33.292869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:33.293028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:33.293153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:33.293244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:41:33.361477: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:33.361613: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:33.473846: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:41:33.474014: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.38s/it]2049it [00:03, 817.45it/s]4097it [00:03, 1834.73it/s]6145it [00:03, 3039.44it/s]8193it [00:03, 4394.80it/s]10241it [00:04, 5851.54it/s]12289it [00:04, 7369.35it/s]14337it [00:04, 8694.83it/s]16385it [00:04, 9808.27it/s]18433it [00:04, 10899.36it/s]20481it [00:04, 11912.99it/s]22529it [00:04, 12374.71it/s]24577it [00:05, 12476.61it/s]26625it [00:05, 12694.50it/s]28673it [00:05, 12775.07it/s]30721it [00:05, 12931.34it/s]32769it [00:05, 13036.90it/s]34817it [00:05, 13908.65it/s]36865it [00:06, 14098.24it/s]38913it [00:06, 14150.97it/s]40961it [00:06, 14009.28it/s]43009it [00:06, 14139.28it/s]45057it [00:06, 13957.62it/s]47105it [00:06, 13679.81it/s]49153it [00:06, 13939.53it/s]51201it [00:07, 13834.66it/s]53249it [00:07, 13945.00it/s]55297it [00:07, 14116.12it/s]57345it [00:07, 13870.02it/s]59393it [00:07, 13961.54it/s]61441it [00:07, 14127.44it/s]63489it [00:07, 13905.98it/s]65537it [00:08, 13914.30it/s]67585it [00:08, 13711.49it/s]69633it [00:08, 13569.48it/s]71681it [00:08, 13765.49it/s]73729it [00:08, 13906.82it/s]75777it [00:08, 14041.97it/s]77825it [00:08, 14388.95it/s]79873it [00:09, 14556.42it/s]81921it [00:09, 15215.91it/s]83969it [00:09, 14938.60it/s]86017it [00:09, 14541.35it/s]88065it [00:09, 14320.12it/s]90113it [00:09, 14367.93it/s]91192it [00:09, 9267.74it/s] 
I1123 13:41:43.153800 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134143d4334a1a09e46ba2target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_23.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-20-1823840-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-20-1823840-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f04b631e1f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:41:48.816464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:48.816700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:48.816811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:48.816975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:48.817084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:41:48.817171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:41:48.883213: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:48.883352: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:41:48.989758: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:41:48.989931: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.47s/it]2049it [00:03, 795.07it/s]4097it [00:03, 1790.76it/s]6145it [00:03, 2990.47it/s]8193it [00:04, 4344.50it/s]10241it [00:04, 5843.34it/s]12289it [00:04, 7367.01it/s]14337it [00:04, 8781.10it/s]16385it [00:04, 10042.86it/s]18433it [00:04, 11141.77it/s]20481it [00:04, 12151.45it/s]22529it [00:05, 12864.44it/s]24577it [00:05, 13517.36it/s]26625it [00:05, 13989.76it/s]28673it [00:05, 13801.19it/s]30721it [00:05, 13844.52it/s]32769it [00:05, 13985.68it/s]34817it [00:05, 13775.52it/s]36865it [00:06, 13598.69it/s]38913it [00:06, 13678.40it/s]40961it [00:06, 13718.76it/s]43009it [00:06, 13727.20it/s]45057it [00:06, 13751.85it/s]47105it [00:06, 13702.73it/s]49153it [00:06, 13575.60it/s]51201it [00:07, 13755.84it/s]53249it [00:07, 13820.82it/s]55297it [00:07, 14043.97it/s]57345it [00:07, 13856.13it/s]59393it [00:07, 13617.27it/s]61441it [00:07, 13410.69it/s]63489it [00:07, 13391.21it/s]65537it [00:08, 13538.34it/s]67585it [00:08, 13335.95it/s]69633it [00:08, 13556.74it/s]71681it [00:08, 13708.19it/s]73729it [00:08, 13780.27it/s]75777it [00:08, 13712.01it/s]77825it [00:09, 13731.84it/s]79873it [00:09, 14069.42it/s]81921it [00:09, 14290.37it/s]83969it [00:09, 14179.80it/s]86017it [00:09, 13719.02it/s]88065it [00:09, 13461.67it/s]90113it [00:09, 13420.16it/s]91192it [00:09, 9145.89it/s] 
I1123 13:41:58.736479 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313415891973c0a09e45bbatarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_24.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-11-1003112-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-11-1003112-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051d94e9d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:42:04.110407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:04.110573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:04.110652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:04.110770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:04.110846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:04.110909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:42:04.155059: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:04.155164: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:04.226519: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:42:04.226662: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.29s/it]2049it [00:03, 838.45it/s]4097it [00:03, 1876.74it/s]6145it [00:03, 3101.37it/s]8193it [00:03, 4462.92it/s]10241it [00:04, 5887.63it/s]12289it [00:04, 7363.49it/s]14337it [00:04, 8787.87it/s]16385it [00:04, 10083.28it/s]18433it [00:04, 10900.55it/s]20481it [00:04, 11833.78it/s]22529it [00:04, 12487.61it/s]24577it [00:05, 12935.41it/s]26625it [00:05, 13354.88it/s]28673it [00:05, 13577.03it/s]30721it [00:05, 13357.11it/s]32769it [00:05, 13818.49it/s]34817it [00:05, 13844.39it/s]36865it [00:05, 13250.02it/s]38913it [00:06, 13207.85it/s]40961it [00:06, 13312.40it/s]43009it [00:06, 13445.96it/s]45057it [00:06, 13077.41it/s]47105it [00:06, 13493.53it/s]49153it [00:06, 13766.61it/s]51201it [00:06, 14239.70it/s]53249it [00:07, 14449.33it/s]55297it [00:07, 14086.50it/s]57345it [00:07, 14100.56it/s]59393it [00:07, 14121.41it/s]61441it [00:07, 14296.64it/s]63489it [00:07, 14051.55it/s]65537it [00:07, 13703.60it/s]67585it [00:08, 13634.16it/s]69630it [00:08, 15146.57it/s]71200it [00:08, 13481.08it/s]72705it [00:08, 12960.71it/s]74753it [00:08, 13174.95it/s]76801it [00:08, 13411.16it/s]78849it [00:08, 13274.26it/s]80897it [00:09, 13958.46it/s]82945it [00:09, 13963.13it/s]84993it [00:09, 13884.31it/s]87041it [00:09, 13796.06it/s]89089it [00:09, 13761.65it/s]91192it [00:09, 9265.84it/s] 
I1123 13:42:13.830213 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134213b0973c0a09e4842dtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_25.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-27-2462184-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-27-2462184-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051db2d250> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:42:18.989771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:18.989950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:18.990037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:18.990170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:18.990249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:18.990316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:42:19.036507: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:19.036612: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:19.106785: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:42:19.106930: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.74s/it]2049it [00:02, 985.60it/s]4097it [00:03, 2172.13it/s]6145it [00:03, 3528.21it/s]8193it [00:03, 4974.89it/s]10241it [00:03, 6435.40it/s]12289it [00:03, 7861.20it/s]14337it [00:03, 9341.61it/s]16385it [00:03, 10464.18it/s]18433it [00:04, 11450.18it/s]20481it [00:04, 12147.54it/s]22529it [00:04, 12534.62it/s]24577it [00:04, 13062.79it/s]26625it [00:04, 13454.93it/s]28673it [00:04, 13711.51it/s]30721it [00:04, 13935.59it/s]32769it [00:05, 14270.03it/s]34817it [00:05, 15239.29it/s]36865it [00:05, 15362.65it/s]38913it [00:05, 15069.68it/s]40961it [00:05, 14949.04it/s]43009it [00:05, 14494.20it/s]45057it [00:05, 14407.42it/s]47105it [00:06, 14362.60it/s]49153it [00:06, 14344.84it/s]51201it [00:06, 14849.98it/s]53249it [00:06, 14154.69it/s]55297it [00:06, 14016.51it/s]57345it [00:06, 13801.50it/s]59393it [00:06, 14199.75it/s]61441it [00:07, 14385.94it/s]63489it [00:07, 14003.54it/s]65537it [00:07, 13804.04it/s]67585it [00:07, 13563.48it/s]69633it [00:07, 13332.63it/s]71681it [00:07, 13404.71it/s]73729it [00:07, 13436.93it/s]75777it [00:08, 13619.05it/s]77825it [00:08, 14128.31it/s]79873it [00:08, 13897.37it/s]81921it [00:08, 13770.29it/s]83969it [00:08, 13530.87it/s]86017it [00:08, 13232.08it/s]88065it [00:09, 13336.90it/s]90113it [00:09, 13704.96it/s]91192it [00:11, 7679.35it/s] 
I1123 13:42:31.337256 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134231e1cfdc0b0a36f54ftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_26.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-26-2370992-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-26-2370992-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051e0339d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:42:36.795603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:36.795770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:36.795849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:36.795978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:36.796055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:36.796119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:42:36.842877: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:36.842984: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:36.911995: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:42:36.912178: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.98s/it]2049it [00:03, 915.51it/s]4097it [00:03, 2029.07it/s]6145it [00:03, 3329.29it/s]8193it [00:03, 4765.48it/s]10241it [00:03, 6164.31it/s]12289it [00:03, 7688.66it/s]14337it [00:04, 9104.05it/s]16385it [00:04, 10138.52it/s]18433it [00:04, 11211.22it/s]20481it [00:04, 12013.26it/s]22529it [00:04, 12247.02it/s]24577it [00:04, 12413.04it/s]26625it [00:04, 12606.99it/s]28673it [00:05, 12706.68it/s]30721it [00:05, 13040.78it/s]32769it [00:05, 13197.38it/s]34817it [00:05, 13452.64it/s]36865it [00:05, 13286.02it/s]38913it [00:05, 13198.60it/s]40746it [00:05, 14309.69it/s]42227it [00:06, 12939.08it/s]44033it [00:06, 12307.03it/s]46081it [00:06, 12816.09it/s]48129it [00:06, 13149.75it/s]50177it [00:06, 13641.62it/s]52225it [00:06, 13687.65it/s]54273it [00:07, 13011.37it/s]56321it [00:07, 13170.52it/s]58369it [00:07, 13150.22it/s]60417it [00:07, 13285.36it/s]62465it [00:07, 13471.55it/s]64513it [00:07, 13613.37it/s]66561it [00:07, 13589.76it/s]68609it [00:08, 13694.17it/s]70657it [00:08, 13534.98it/s]72705it [00:08, 13729.83it/s]74753it [00:08, 14340.05it/s]76801it [00:08, 14795.97it/s]78849it [00:08, 15351.10it/s]80897it [00:08, 15322.49it/s]82945it [00:09, 14735.88it/s]84993it [00:09, 14202.68it/s]87041it [00:09, 13836.90it/s]89089it [00:09, 13821.57it/s]91192it [00:09, 9489.48it/s] 
I1123 13:42:46.506266 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134246a2eedc0b0a370f0atarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_27.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-14-1276688-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-14-1276688-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f04b6273c10> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:42:52.078672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:52.079116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:52.079244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:52.079540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:52.079670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:42:52.079866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:42:52.155654: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:52.155786: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:42:52.262422: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:42:52.262576: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.40s/it]2049it [00:03, 814.89it/s]4097it [00:03, 1838.28it/s]6145it [00:03, 3053.92it/s]8193it [00:03, 4434.44it/s]10241it [00:04, 5846.79it/s]12289it [00:04, 7296.85it/s]14337it [00:04, 8662.88it/s]16385it [00:04, 9889.51it/s]18433it [00:04, 10880.26it/s]20481it [00:04, 11727.55it/s]22529it [00:04, 12151.96it/s]24577it [00:05, 12666.69it/s]26625it [00:05, 12946.37it/s]28673it [00:05, 13124.73it/s]30721it [00:05, 13815.82it/s]32769it [00:05, 13950.41it/s]34817it [00:05, 13748.70it/s]36865it [00:06, 13788.77it/s]38913it [00:06, 13960.79it/s]40961it [00:06, 14105.31it/s]43009it [00:06, 14089.54it/s]45057it [00:06, 14001.47it/s]47105it [00:06, 14121.30it/s]49153it [00:06, 14109.02it/s]51201it [00:07, 13835.30it/s]53206it [00:07, 15230.39it/s]54778it [00:07, 13807.51it/s]56321it [00:07, 12918.87it/s]58369it [00:07, 13239.24it/s]60417it [00:07, 13778.08it/s]62465it [00:07, 14070.93it/s]64513it [00:07, 13980.74it/s]66561it [00:08, 14051.91it/s]68609it [00:08, 13983.60it/s]70657it [00:08, 13712.22it/s]72705it [00:08, 14136.70it/s]74753it [00:08, 14243.00it/s]76801it [00:08, 14218.27it/s]78849it [00:09, 14081.38it/s]80897it [00:09, 14658.50it/s]82945it [00:09, 14455.24it/s]84993it [00:09, 14007.39it/s]87041it [00:09, 13821.80it/s]89089it [00:09, 13761.54it/s]91192it [00:09, 9245.23it/s] 
I1123 13:43:01.923118 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313430191973c0a09e46e62target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_28.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-18-1641456-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-18-1641456-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051de62910> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:43:07.663575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:07.663776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:07.663908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:07.664064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:07.664173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:07.664264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:43:07.731109: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:07.731245: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:07.848585: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:43:07.848723: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.49s/it]2049it [00:03, 794.98it/s]4097it [00:03, 1787.59it/s]6145it [00:03, 2985.84it/s]8193it [00:04, 4352.22it/s]10241it [00:04, 5834.55it/s]12289it [00:04, 7391.69it/s]14337it [00:04, 8903.32it/s]16385it [00:04, 10220.29it/s]18433it [00:04, 11283.25it/s]20481it [00:04, 12089.43it/s]22529it [00:05, 12452.07it/s]24577it [00:05, 13075.50it/s]26625it [00:05, 13403.70it/s]28673it [00:05, 13538.51it/s]30721it [00:05, 13841.97it/s]32769it [00:05, 13778.17it/s]34817it [00:05, 13975.34it/s]36865it [00:06, 14042.66it/s]38913it [00:06, 14257.50it/s]40961it [00:06, 14564.82it/s]43009it [00:06, 14655.62it/s]45057it [00:06, 14729.11it/s]47105it [00:06, 13836.85it/s]49153it [00:06, 14191.69it/s]51201it [00:07, 14219.24it/s]53249it [00:07, 14346.20it/s]55297it [00:07, 14230.69it/s]57345it [00:07, 14168.47it/s]59393it [00:07, 14187.79it/s]61441it [00:07, 14288.97it/s]63489it [00:07, 14118.12it/s]65537it [00:08, 14079.07it/s]67585it [00:08, 14042.53it/s]69633it [00:08, 14097.76it/s]71681it [00:08, 14293.25it/s]73729it [00:08, 14379.07it/s]75777it [00:08, 14289.15it/s]77825it [00:08, 14103.53it/s]79873it [00:09, 14478.43it/s]81921it [00:09, 14479.85it/s]83969it [00:09, 14937.10it/s]86017it [00:09, 14669.82it/s]88065it [00:09, 14696.42it/s]90113it [00:09, 14437.32it/s]91192it [00:09, 9314.92it/s] 
I1123 13:43:17.251992 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134317e7c7dc0b0a36d224target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_29.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-21-1915032-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-21-1915032-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dec3d00> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:43:22.739006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:22.739168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:22.739247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:22.739380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:22.739478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:22.739545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:43:22.784558: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:22.784654: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:22.853286: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:43:22.853429: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.13s/it]2049it [00:03, 881.63it/s]4097it [00:03, 1968.63it/s]6145it [00:03, 3260.84it/s]8193it [00:03, 4676.57it/s]10241it [00:03, 6127.03it/s]12289it [00:03, 7570.87it/s]14337it [00:04, 9041.97it/s]16385it [00:04, 10246.71it/s]18433it [00:04, 11117.55it/s]20481it [00:04, 11817.11it/s]22529it [00:04, 12434.71it/s]24577it [00:04, 12852.10it/s]26625it [00:04, 13290.09it/s]28673it [00:05, 13543.25it/s]30721it [00:05, 13584.25it/s]32769it [00:05, 14109.88it/s]34817it [00:05, 14102.83it/s]36865it [00:05, 13942.64it/s]38913it [00:05, 13827.44it/s]40961it [00:06, 13743.01it/s]43009it [00:06, 13326.78it/s]45057it [00:06, 13328.34it/s]47105it [00:06, 13654.00it/s]49153it [00:06, 13939.46it/s]51201it [00:06, 13886.20it/s]53249it [00:06, 13817.74it/s]55297it [00:07, 13787.84it/s]57345it [00:07, 13839.59it/s]59393it [00:07, 13727.73it/s]61441it [00:07, 13759.85it/s]63489it [00:07, 13709.69it/s]65537it [00:07, 13701.39it/s]67585it [00:07, 13623.03it/s]69633it [00:08, 13466.15it/s]71681it [00:08, 13743.70it/s]73729it [00:08, 13604.83it/s]75777it [00:08, 13609.00it/s]77825it [00:08, 13650.49it/s]79873it [00:08, 13942.20it/s]81921it [00:09, 13892.83it/s]83969it [00:09, 13725.64it/s]86017it [00:09, 13613.45it/s]88065it [00:09, 13873.10it/s]90113it [00:09, 13833.38it/s]91192it [00:09, 9447.70it/s] 
I1123 13:43:32.198313 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313433297334a1a09e4add3target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_30.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-28-2553376-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-28-2553376-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051dcd34c0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:43:37.726433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:37.726789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:37.742918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:37.743698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:37.744645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:37.744759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:43:37.811086: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:37.811227: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:37.917367: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:43:37.917526: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.49s/it]2049it [00:03, 793.42it/s]4097it [00:03, 1788.32it/s]6145it [00:03, 2988.70it/s]8193it [00:04, 4331.53it/s]10241it [00:04, 5766.11it/s]12289it [00:04, 7227.01it/s]14337it [00:04, 8586.13it/s]16385it [00:04, 9830.84it/s]18433it [00:04, 10903.41it/s]20481it [00:04, 11791.36it/s]22529it [00:05, 12368.80it/s]24577it [00:05, 12900.14it/s]26625it [00:05, 13122.32it/s]28673it [00:05, 13238.13it/s]30721it [00:05, 13384.54it/s]32769it [00:05, 13426.22it/s]34817it [00:05, 14067.04it/s]36865it [00:06, 14407.42it/s]38913it [00:06, 14432.59it/s]40961it [00:06, 14604.17it/s]43009it [00:06, 14818.38it/s]45057it [00:06, 14743.91it/s]47105it [00:06, 14580.07it/s]49153it [00:06, 14585.59it/s]51201it [00:07, 14560.13it/s]53249it [00:07, 14133.18it/s]55297it [00:07, 13719.30it/s]57345it [00:07, 13684.24it/s]59393it [00:07, 13391.30it/s]61441it [00:07, 13300.54it/s]63489it [00:07, 13439.25it/s]65537it [00:08, 13370.07it/s]67585it [00:08, 13238.30it/s]69633it [00:08, 13526.69it/s]71506it [00:08, 14674.45it/s]73017it [00:08, 13182.80it/s]74753it [00:08, 13040.64it/s]76801it [00:08, 13532.72it/s]78849it [00:09, 13711.24it/s]80897it [00:09, 14037.75it/s]82945it [00:09, 13905.59it/s]84993it [00:09, 13652.16it/s]87041it [00:09, 13563.91it/s]89089it [00:09, 14059.64it/s]91192it [00:09, 9147.10it/s] 
I1123 13:43:47.626835 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134347f2cfdc0b0a36fb32target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511210000_31.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251121/part-r-30-2735760-91192.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251121/part-r-30-2735760-91192.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f051de01df0> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f051d8ee7c0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:43:53.249185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:53.249408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:53.249520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:53.249676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:53.249784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:43:53.249870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511200000/model.ckpt-159152
2025-11-23 13:43:53.313851: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:53.313980: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:43:53.417870: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:43:53.418041: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.17s/it]2049it [00:03, 863.21it/s]4097it [00:03, 1917.78it/s]6145it [00:03, 3162.83it/s]8193it [00:03, 4538.50it/s]10241it [00:03, 5999.07it/s]12289it [00:04, 7443.34it/s]14337it [00:04, 8680.74it/s]16385it [00:04, 9994.74it/s]18433it [00:04, 11073.43it/s]20481it [00:04, 11765.58it/s]22529it [00:04, 12176.45it/s]24577it [00:04, 12472.08it/s]26625it [00:05, 12669.69it/s]28673it [00:05, 12943.30it/s]30721it [00:05, 13202.21it/s]32769it [00:05, 13599.76it/s]34817it [00:05, 13997.69it/s]36865it [00:05, 14144.12it/s]38913it [00:05, 14520.92it/s]40961it [00:06, 14795.27it/s]43009it [00:06, 14981.54it/s]45057it [00:06, 14773.84it/s]47105it [00:06, 14736.75it/s]49153it [00:06, 14699.29it/s]51201it [00:06, 14574.58it/s]53249it [00:06, 14172.86it/s]55297it [00:07, 13961.00it/s]57345it [00:07, 13959.14it/s]59393it [00:07, 14159.14it/s]61441it [00:07, 14016.07it/s]63489it [00:07, 14217.34it/s]65537it [00:07, 14370.27it/s]67585it [00:07, 14393.71it/s]69633it [00:08, 14056.23it/s]71681it [00:08, 14068.40it/s]73729it [00:08, 14381.34it/s]75777it [00:08, 14357.12it/s]77825it [00:08, 14294.15it/s]79873it [00:08, 14119.44it/s]81921it [00:08, 14590.69it/s]83969it [00:09, 14482.81it/s]86017it [00:09, 15030.45it/s]88065it [00:09, 15127.68it/s]90113it [00:09, 15131.91it/s]91192it [00:09, 9558.35it/s] 
I1123 13:44:02.799890 139660730369856 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123134402e5cfdc0b0a36b261target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552'>
INFO:tensorflow:mode: infer device: GPU task_type: chief task_idx: 0 time_str: 202511210000 end_time_str: None waste: 8.25 mins
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511210000,feature_type=O35_mutil_cvr_v10,infer_time=20251123133552
/data/share/opt/model/O35_mutil_cvr_v10
----------------------------clear history data--------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
seq_idxs=[]
(Namespace(data_path='/data/share/opt/data', del_date='20251022'), [])
---------del_path=/data/share/opt/data/O35_mutil_cvr/20251022--------
 /data/share/opt/model/O35_mutil_cvr_v10/export_dir/1762765103 diff days 12 
 /data/share/opt/model/O35_mutil_cvr_v10/export_dir/1762841767 diff days 11 
 /data/share/opt/model/O35_mutil_cvr_v10/export_dir/1762925502 diff days 11 
/data/share/opt/model/O35_mutil_cvr_v10
nohup: ignoring input
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
--> time_str: 202511220000, end_date: 202511220000
---------------------------------main-train-------------------------------------
---------------------------------export.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-export-------------------------------------
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-23 13:56:24.171728: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-23 13:56:24.171754: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:56:24.171757: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:56:24.171851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-23 13:56:24.171865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-23 13:56:24.171868: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:Using CPU for training
INFO:tensorflow:time_str=20251122, end_time_str=20251122
INFO:tensorflow:train_date={'20251122': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-31-2233519-4.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-08-576392-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-09-648441-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-17-1224833-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-18-1296882-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-30-2161470-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-10-720490-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-22-1585078-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-26-1873274-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-20-1440980-72049.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511220000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 0
}
intra_op_parallelism_threads: 16
inter_op_parallelism_threads: 16
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: CPU
INFO:tensorflow:Batch sizes - Train: 2048, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 2048, 'train_epoch': 1, 'batch_size': 1024}
seq_idxs=[]
defalut feature:Tensor("StringJoin:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_1:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_2:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_3:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_4:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_5:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_6:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_7:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_8:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_9:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_10:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_11:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_12:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_13:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_14:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_15:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_16:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_17:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_18:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_19:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_20:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_21:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_22:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_23:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_24:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_25:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_26:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_27:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_28:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_29:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_30:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_31:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_32:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_33:0", shape=(None,), dtype=string)
feature:user__imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_34:0", shape=(None,), dtype=string)
feature:user__clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_35:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_36:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_37:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_38:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_39:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_40:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_41:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_42:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_43:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_44:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_45:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_46:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_47:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_48:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_49:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_50:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_51:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_52:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_53:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_54:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_55:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_56:0", shape=(None,), dtype=string)
feature:user__imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_57:0", shape=(None,), dtype=string)
feature:user__clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_58:0", shape=(None,), dtype=string)
feature:user__kv_day_h_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_59:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_60:0", shape=(None,), dtype=string)
feature:user__kv_template_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_61:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_62:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_63:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_64:0", shape=(None,), dtype=string)
feature:user__kv_package_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_65:0", shape=(None,), dtype=string)
feature:user__kv_template_type_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_66:0", shape=(None,), dtype=string)
feature:user__kv_product_name_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_67:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_68:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_69:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_70:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_71:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_72:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_73:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_74:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_75:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_76:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_77:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_78:0", shape=(None,), dtype=string)
feature:user__kv_day_h_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_79:0", shape=(None,), dtype=string)
feature:user__kv_ad_idea_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_80:0", shape=(None,), dtype=string)
feature:user__kv_template_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_81:0", shape=(None,), dtype=string)
feature:user__kv_adslot_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_82:0", shape=(None,), dtype=string)
feature:user__kv_app_first_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_83:0", shape=(None,), dtype=string)
feature:user__kv_ad_plan_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_84:0", shape=(None,), dtype=string)
feature:user__kv_package_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_85:0", shape=(None,), dtype=string)
feature:user__kv_template_type_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_86:0", shape=(None,), dtype=string)
feature:user__kv_product_name_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_87:0", shape=(None,), dtype=string)
feature:user__kv_first_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_88:0", shape=(None,), dtype=string)
feature:user__kv_industry_id_clk_div_imp_cnt_30d in boundaries_map, boundary idx:Tensor("StringJoin_89:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_90:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_91:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_92:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_93:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_94:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_95:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_96:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_97:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_98:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_99:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_100:0", shape=(None,), dtype=string)
defalut feature:Tensor("StringJoin_101:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_102:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_103:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_104:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_105:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_106:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_107:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_108:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_109:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_110:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_111:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_112:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_113:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_114:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_115:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_116:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_117:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_118:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_119:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_120:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_121:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_122:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_123:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_124:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_125:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_126:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_127:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_128:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_129:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_130:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_131:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_132:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_133:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_134:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_135:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_136:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_137:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_138:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_139:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_140:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_141:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_142:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_143:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_144:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_145:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_146:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_147:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_148:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_149:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_150:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_151:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_152:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_153:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_154:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_155:0", shape=(None,), dtype=string)
feature:doc__key_five__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_156:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_157:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_158:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_159:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_160:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_161:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_162:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_163:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_164:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_165:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_166:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_167:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_168:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_169:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_170:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_171:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_172:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_173:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_174:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_175:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_176:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_177:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_178:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_179:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_180:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_181:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_182:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_183:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_184:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_185:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_186:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_187:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_188:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_189:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_190:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_191:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_192:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_193:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_194:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_195:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_196:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_197:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_198:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_199:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_200:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_201:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_202:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_203:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_204:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_205:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_206:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_207:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_208:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_209:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_210:0", shape=(None,), dtype=string)
feature:doc__key_four__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_211:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_212:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_213:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_214:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_215:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_216:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_217:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_218:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_219:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_220:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_221:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_222:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_223:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_224:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_225:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_226:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_227:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_228:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_229:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_230:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_231:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_232:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_233:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_234:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_235:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_236:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_237:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_238:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_239:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_240:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_241:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_242:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_243:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_244:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_245:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_246:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_247:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_248:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_249:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_250:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_251:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_252:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_253:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_254:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_255:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_256:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_257:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_258:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_259:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_260:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_261:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_262:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_263:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_264:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_265:0", shape=(None,), dtype=string)
feature:doc__key_one__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_266:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_267:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_268:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_269:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_270:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_271:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_272:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_273:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_274:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_275:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_276:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_277:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_278:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_279:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_280:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_281:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_282:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_283:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_284:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_285:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_286:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_287:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_288:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_289:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_290:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_291:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_292:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_293:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_294:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_295:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_296:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_297:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_298:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_299:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_300:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_301:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_302:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_303:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_304:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_305:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_306:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_307:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_308:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_309:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_310:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_311:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_312:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_313:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_314:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_315:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_316:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_317:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_318:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_319:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_320:0", shape=(None,), dtype=string)
feature:doc__key_seven__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_321:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_322:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_323:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_324:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_325:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_326:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_327:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_328:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_329:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_330:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_331:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_332:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_333:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_334:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_335:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_336:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_337:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_338:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_339:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_340:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_341:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_342:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_343:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_344:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_345:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_346:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_347:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_348:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_349:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_350:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_351:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_352:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_353:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_354:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_355:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_356:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_357:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_358:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_359:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_360:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_361:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_362:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_363:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_364:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_365:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_366:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_367:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_368:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_369:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_370:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_371:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_372:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_373:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_374:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_375:0", shape=(None,), dtype=string)
feature:doc__key_six__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_376:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_377:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_378:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_379:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_380:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_381:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_382:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_383:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_384:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_385:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_386:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_387:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_388:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_389:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_390:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_391:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_392:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_393:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_394:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_395:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_396:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_397:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_398:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_399:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_400:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_401:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_402:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_403:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_404:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_405:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_406:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_407:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_408:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_409:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_410:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_411:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_412:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_413:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_414:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_415:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_416:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_417:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_418:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_419:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_420:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_421:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_422:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_423:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_424:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_425:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_426:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_427:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_428:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_429:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_430:0", shape=(None,), dtype=string)
feature:doc__key_three__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_431:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_432:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_433:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_434:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_435:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_436:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_437:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_438:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_439:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_440:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_441:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_442:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_443:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_444:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_445:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_446:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_447:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_448:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_449:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_450:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_451:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_dispatch_center_id_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_452:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_453:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_454:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_455:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_456:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_clk_div_imp_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_457:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_458:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_459:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_460:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_461:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_462:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_463:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_464:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_465:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_466:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_dci_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_467:0", shape=(None,), dtype=string)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f1624645370> -------
INFO:tensorflow:------ features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'export', 'ps_num': 0, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'CPU', 'gpu_ids': [], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is /job:localhost/replica:0/task:0/CPU:0 -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f16246455b0> emb_lookuped: Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("ctr_tower/zeros:0", shape=(None,), dtype=float32), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_1329:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("awake_tower/zeros:0", shape=(None,), dtype=float32), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("mmoe_tower/zeros:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("mmoe_tower/zeros_1:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("mmoe_tower/zeros_2:0", shape=(None,), dtype=float32), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
2025-11-23 13:56:27.576294: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511220000/model.ckpt-161624
2025-11-23 13:56:27.899737: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:56:27.900362: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: /data/share/opt/model/O35_mutil_cvr_v10/export_dir/temp-1763877384/saved_model.pb
INFO:tensorflow:mode: export device: CPU task_type: chief task_idx: 0 time_str: 202511220000 end_time_str: None waste: 0.08 mins
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_468:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_469:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_470:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_471:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_472:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_1d in boundaries_map, boundary idx:Tensor("StringJoin_473:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_network_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_474:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_region_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_475:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_ip_city_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_476:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_city_level_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_477:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_brand_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_478:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_479:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_model_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_480:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_size_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_481:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_carrier_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_482:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_device_os_version_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_483:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_day_h_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_484:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_7d in boundaries_map, boundary idx:Tensor("StringJoin_485:0", shape=(None,), dtype=string)
feature:doc__key_two__kv_keywords_conv_awake_div_clk_cnt_15d in boundaries_map, boundary idx:Tensor("StringJoin_486:0", shape=(None,), dtype=string)
features: {'features': <tf.Tensor 'concat:0' shape=(None, 487) dtype=string>} tensors: 487
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
-------------------------------generate_body---------------------------------------
seq_idxs=[]
(Namespace(day='20251122'), [])
[INFO/MainProcess] process shutting down
==================warmup.py:  export_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir ====================
2025-11-23 13:56:32.859295: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-11-23 13:56:32.859322: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:56:32.859327: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iZ2zegp68bfkz6q7nfj48eZ
2025-11-23 13:56:32.859413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.216.3
2025-11-23 13:56:32.859429: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.216.3
2025-11-23 13:56:32.859432: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.216.3
seq_idxs=[]
model_dir:/data/share/opt/model/O35_mutil_cvr_v10/export_dir
body_file:/opt/huangmian/yoyo_model/config/O35_mutil_cvr_v10/body.json
files: [1763006534, 1763089185, 1763175233, 1763346032, 1763432182, 1763518248, 1763604706, 1763691680, 1763875993, 1763877384]
/data/share/opt/model/O35_mutil_cvr_v10
eval data:202511220000
---------------------------------eval.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-eval-------------------------------------
---------------------------------save_eval_metric------------------------------------
/data/share/opt/model/O35_mutil_cvr_v10/logs/202511220000.eval not metrice date, please check code!
/data/share/opt/model/O35_mutil_cvr_v10
infer data:202511220000
---------------------------------infer.sh-------------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
---------------------------------main-infer-------------------------------------
ckpt_dir=/data/share/opt/model/O35_mutil_cvr_v10/202511210000, time_str=202511220000
WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/utils/resource_loader.py:34: UserWarning: Fail to get TFRA package information, if you are running on bazel test mode, please ignore this warning, 
or you should check TFRA installation.
  warnings.warn(
2025-11-23 13:58:57.575958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:57.576096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:57.581767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:57.581896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:57.581975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:57.582047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:>>>>>>>>>>>>>>>data_path=/data/share/opt/data/O35_mutil_cvr<<<<<<<<<<<<<<<<<<
INFO:tensorflow:time_str=20251122, end_time_str=20251122
INFO:tensorflow:train_date={'20251122': 32}
INFO:tensorflow:len(filenames)=32, filenames: ['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-31-2233519-4.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-01-72049-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-04-288196-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-23-1657127-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-21-1513029-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-10-720490-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-05-360245-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-29-2089421-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-30-2161470-72049.gz', '/data/share/opt/data/O35_mutil_cvr/20251122/part-r-09-648441-72049.gz']
INFO:tensorflow:Using config: {'_model_dir': '/data/share/opt/model/O35_mutil_cvr_v10/202511210000', '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': device_count {
  key: "GPU"
  value: 2
}
intra_op_parallelism_threads: 8
inter_op_parallelism_threads: 8
gpu_options {
  per_process_gpu_memory_fraction: 0.9
  allow_growth: true
  visible_device_list: "0"
}
allow_soft_placement: true
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
INFO:tensorflow:Device configuration: GPU
INFO:tensorflow:Using GPUs: 0
INFO:tensorflow:Batch sizes - Train: 2048, Eval: 1024
INFO:tensorflow:{'train_spec': {'max_steps': None}, 'eval_spec': {'start_delay_secs': 1e+20, 'steps': None}, 'train_batch_size': 2048, 'train_epoch': 1, 'batch_size': 1024}
seq_idxs=[]
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_0.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-31-2233519-4.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-31-2233519-4.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
WARNING:tensorflow:From /root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py:588: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc1669c40> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
WARNING:tensorflow:From /opt/huangmian/yoyo_model/common/metrics.py:51: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:58:59.089553: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-23 13:58:59.090140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:59.090343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:59.090454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:59.572272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:59.572455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:59.572576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:58:59.572691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 13:58:59.649426: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:58:59.649557: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:58:59.776884: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:58:59.777804: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2025-11-23 13:59:00.706167: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1it [00:03,  3.10s/it]4it [00:03,  1.27it/s]
I1123 13:59:03.407813 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511231359038657381a09e508ectarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_1.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-01-72049-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-01-72049-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5ce5c0a0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:59:07.309967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:07.310122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:07.310197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:07.310311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:07.310387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:07.310451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 13:59:07.355522: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:07.355621: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:07.427059: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:59:07.427378: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.35s/it]2049it [00:03, 818.26it/s]4097it [00:03, 1824.40it/s]6145it [00:03, 3009.78it/s]8193it [00:03, 4356.39it/s]10241it [00:04, 5768.21it/s]12289it [00:04, 7219.26it/s]14337it [00:04, 8477.14it/s]16385it [00:04, 9746.57it/s]18433it [00:04, 10621.37it/s]20481it [00:04, 11310.65it/s]22529it [00:05, 11843.59it/s]24577it [00:05, 12318.07it/s]26625it [00:05, 12577.10it/s]28673it [00:05, 12848.14it/s]30721it [00:05, 13153.25it/s]32769it [00:05, 13294.06it/s]34817it [00:05, 13411.29it/s]36865it [00:06, 13553.59it/s]38913it [00:06, 13678.42it/s]40961it [00:06, 14091.65it/s]43009it [00:06, 14002.33it/s]45057it [00:06, 13914.14it/s]47105it [00:06, 13822.94it/s]49153it [00:06, 13883.01it/s]51201it [00:07, 13915.78it/s]53249it [00:07, 14024.73it/s]55297it [00:07, 14224.77it/s]57345it [00:07, 14377.79it/s]59393it [00:07, 14384.16it/s]61441it [00:07, 14278.93it/s]63489it [00:07, 14605.19it/s]65537it [00:08, 14584.59it/s]67585it [00:08, 14442.14it/s]69633it [00:08, 14450.73it/s]71681it [00:08, 15618.13it/s]72049it [00:08, 8467.16it/s] 
I1123 13:59:15.555827 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123135915cbcfdc0b0a38210ftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_2.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-04-288196-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-04-288196-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc114e460> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:59:21.099811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:21.100026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:21.100135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:21.100288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:21.100407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:21.100498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 13:59:21.170724: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:21.170871: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:21.280014: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 13:59:21.288188: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.84s/it]2049it [00:03, 722.24it/s]4097it [00:04, 1635.09it/s]6145it [00:04, 2739.06it/s]8193it [00:04, 4000.65it/s]10241it [00:04, 5389.22it/s]12289it [00:04, 6890.56it/s]14337it [00:04, 8217.61it/s]16385it [00:05, 9364.41it/s]18433it [00:05, 10240.90it/s]20481it [00:05, 11171.81it/s]22529it [00:05, 11750.56it/s]24577it [00:05, 12190.37it/s]26625it [00:05, 12495.59it/s]28673it [00:05, 13189.11it/s]30721it [00:06, 13221.43it/s]32769it [00:06, 13307.62it/s]34817it [00:06, 13775.01it/s]36865it [00:06, 14519.04it/s]38913it [00:06, 14394.47it/s]40961it [00:06, 14051.23it/s]43009it [00:06, 13582.19it/s]45057it [00:07, 13511.65it/s]47105it [00:07, 13540.40it/s]49153it [00:07, 13829.47it/s]51201it [00:07, 13840.98it/s]53249it [00:07, 13936.71it/s]55297it [00:07, 13941.63it/s]57345it [00:07, 13883.82it/s]59393it [00:08, 13889.17it/s]61441it [00:08, 13802.77it/s]63489it [00:08, 13969.51it/s]65537it [00:08, 14067.19it/s]67585it [00:08, 14056.15it/s]69633it [00:08, 13993.58it/s]71681it [00:08, 15358.88it/s]72049it [00:08, 8011.13it/s] 
I1123 13:59:30.088015 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511231359308fc8dc0b0a37ff8btarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_3.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-23-1657127-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-23-1657127-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc112b7f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:59:35.710094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:35.710263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:35.710342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:35.710459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:35.710534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:35.710596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 13:59:35.756406: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:35.756506: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:35.825074: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:59:35.825231: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.18s/it]2049it [00:03, 865.19it/s]4097it [00:03, 1935.90it/s]6145it [00:03, 3199.16it/s]8193it [00:03, 4613.59it/s]10241it [00:03, 6025.09it/s]12289it [00:04, 7518.14it/s]14337it [00:04, 8772.55it/s]16385it [00:04, 9870.23it/s]18433it [00:04, 10762.51it/s]20481it [00:04, 11496.10it/s]22529it [00:04, 12045.03it/s]24577it [00:04, 12894.09it/s]26625it [00:05, 13866.04it/s]28673it [00:05, 14667.04it/s]30721it [00:05, 14262.84it/s]32769it [00:05, 13912.55it/s]34817it [00:05, 13770.09it/s]36511it [00:05, 14480.22it/s]38006it [00:05, 12893.57it/s]39937it [00:06, 12908.68it/s]41985it [00:06, 13469.79it/s]44033it [00:06, 13557.87it/s]46081it [00:06, 13505.88it/s]48129it [00:06, 13616.68it/s]50177it [00:06, 13441.82it/s]52225it [00:06, 13588.85it/s]54273it [00:07, 13888.30it/s]56321it [00:07, 13980.72it/s]58369it [00:07, 14047.36it/s]60417it [00:07, 14108.46it/s]62465it [00:07, 14306.83it/s]64513it [00:07, 14467.06it/s]66561it [00:07, 14456.40it/s]68609it [00:08, 14803.91it/s]70657it [00:08, 14794.35it/s]72049it [00:08, 8717.22it/s] 
I1123 13:59:43.666514 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511231359438657381a09e512d4target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_4.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-21-1513029-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-21-1513029-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc12fd880> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 13:59:49.198661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:49.198879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:49.198988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:49.199143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:49.199251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 13:59:49.199341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 13:59:49.266782: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:49.266923: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 13:59:49.375830: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 13:59:49.375985: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.52s/it]2049it [00:03, 783.05it/s]4097it [00:03, 1755.85it/s]6145it [00:03, 2909.50it/s]8193it [00:04, 4215.35it/s]10241it [00:04, 5572.60it/s]12289it [00:04, 6997.98it/s]14337it [00:04, 8355.06it/s]16385it [00:04, 9564.04it/s]18433it [00:04, 10816.40it/s]20481it [00:05, 11682.73it/s]22529it [00:05, 12339.61it/s]24577it [00:05, 12916.39it/s]26625it [00:05, 14143.68it/s]28673it [00:05, 14515.17it/s]30721it [00:05, 15048.80it/s]32769it [00:05, 14600.47it/s]34817it [00:05, 14181.34it/s]36865it [00:06, 13906.44it/s]38900it [00:06, 15360.19it/s]40504it [00:06, 13863.69it/s]41985it [00:06, 12724.90it/s]44033it [00:06, 13262.51it/s]46081it [00:06, 13529.67it/s]48129it [00:06, 13573.38it/s]50177it [00:07, 13596.62it/s]52225it [00:07, 13627.57it/s]54273it [00:07, 13529.10it/s]56321it [00:07, 13399.03it/s]58369it [00:07, 13536.37it/s]60417it [00:07, 13821.08it/s]62465it [00:08, 13646.29it/s]64513it [00:08, 13580.29it/s]66561it [00:08, 13520.61it/s]68609it [00:08, 13741.02it/s]70657it [00:08, 13796.03it/s]72049it [00:08, 8310.58it/s] 
I1123 13:59:57.731354 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112313595712344a1a09e50a6btarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_5.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-10-720490-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-10-720490-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5d2f2940> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:00:03.318732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:03.318961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:03.319070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:03.319223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:03.319330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:03.319433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:00:03.384973: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:03.385116: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:03.492340: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:00:03.492492: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.32s/it]2049it [00:03, 829.70it/s]4097it [00:03, 1866.86it/s]6145it [00:03, 3098.73it/s]8193it [00:03, 4470.95it/s]10241it [00:04, 5956.40it/s]12289it [00:04, 7386.38it/s]14337it [00:04, 8799.97it/s]16385it [00:04, 9931.83it/s]18433it [00:04, 10969.68it/s]20481it [00:04, 11739.69it/s]22529it [00:04, 12359.14it/s]24577it [00:05, 12747.56it/s]26625it [00:05, 13237.41it/s]28673it [00:05, 13344.72it/s]30721it [00:05, 13350.67it/s]32769it [00:05, 13477.99it/s]34817it [00:05, 13653.59it/s]36865it [00:05, 13806.55it/s]38913it [00:06, 14506.62it/s]40961it [00:06, 15028.36it/s]43009it [00:06, 14981.54it/s]45057it [00:06, 14646.16it/s]47105it [00:06, 14407.10it/s]49153it [00:06, 14408.35it/s]51201it [00:06, 14150.64it/s]53249it [00:07, 14111.26it/s]55297it [00:07, 14104.36it/s]57345it [00:07, 14001.82it/s]59393it [00:07, 13973.62it/s]61441it [00:07, 13695.18it/s]63489it [00:07, 13603.80it/s]65537it [00:07, 13793.71it/s]67585it [00:08, 13816.96it/s]69633it [00:08, 13970.11it/s]71681it [00:08, 15405.71it/s]72049it [00:12, 5774.44it/s] 
I1123 14:00:15.967813 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140015e1c7dc0b0a3836e6target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_6.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-05-360245-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-05-360245-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc149c280> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:00:21.506282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:21.506501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:21.506608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:21.506759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:21.506866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:21.506954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:00:21.574826: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:21.574961: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:21.681136: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:00:21.681306: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.98s/it]2049it [00:04, 695.35it/s]4097it [00:04, 1571.29it/s]6145it [00:04, 2634.24it/s]8193it [00:04, 3897.82it/s]10241it [00:04, 5239.54it/s]11831it [00:04, 6480.84it/s]13313it [00:04, 7184.78it/s]15361it [00:05, 8455.39it/s]17409it [00:05, 9635.94it/s]19457it [00:05, 10618.78it/s]21505it [00:05, 11562.61it/s]23553it [00:05, 11929.18it/s]25601it [00:05, 12297.47it/s]27649it [00:06, 12390.31it/s]29697it [00:06, 12837.37it/s]31745it [00:06, 12823.02it/s]33793it [00:06, 12750.45it/s]35782it [00:06, 14261.02it/s]37289it [00:06, 13223.00it/s]38913it [00:06, 12712.19it/s]40961it [00:07, 12792.57it/s]43009it [00:07, 13460.24it/s]45057it [00:07, 13273.67it/s]47105it [00:07, 13327.67it/s]49153it [00:07, 13299.24it/s]51201it [00:07, 13491.20it/s]53249it [00:07, 13858.00it/s]55297it [00:08, 13762.08it/s]57345it [00:08, 13627.69it/s]59393it [00:08, 13466.72it/s]61441it [00:08, 13415.49it/s]63489it [00:08, 13444.06it/s]65537it [00:08, 13434.44it/s]67585it [00:09, 13557.33it/s]69633it [00:09, 13607.85it/s]71692it [00:09, 15155.88it/s]72049it [00:09, 7729.42it/s] 
I1123 14:00:30.700515 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140030d2f2dc0b0a3816fetarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_7.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-29-2089421-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-29-2089421-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f44817040> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:00:36.018429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:36.018620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:36.018736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:36.018908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:36.019025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:36.019120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:00:36.087730: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:36.087883: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:36.196157: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:00:36.196289: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  4.00s/it]2049it [00:04, 691.82it/s]4097it [00:04, 1563.17it/s]5171it [00:04, 2116.21it/s]7169it [00:04, 3363.95it/s]9217it [00:04, 4783.39it/s]11265it [00:04, 6190.27it/s]13313it [00:05, 7673.24it/s]15361it [00:05, 8971.99it/s]17409it [00:05, 10115.18it/s]19457it [00:05, 11074.98it/s]21505it [00:05, 11431.76it/s]23553it [00:05, 12185.29it/s]25601it [00:05, 12711.52it/s]27649it [00:06, 13162.64it/s]29697it [00:06, 13483.27it/s]31745it [00:06, 13722.47it/s]33793it [00:06, 13866.05it/s]35841it [00:06, 13684.71it/s]37889it [00:06, 13613.48it/s]39937it [00:06, 13929.17it/s]41985it [00:07, 13828.38it/s]44033it [00:07, 13639.19it/s]46081it [00:07, 13634.07it/s]48129it [00:07, 13531.55it/s]50177it [00:07, 13390.64it/s]52225it [00:07, 13390.47it/s]54273it [00:08, 13823.61it/s]56321it [00:08, 13817.33it/s]58369it [00:08, 14089.26it/s]60417it [00:08, 14208.72it/s]62465it [00:08, 14205.65it/s]64513it [00:08, 13962.15it/s]66561it [00:08, 13963.87it/s]68609it [00:09, 14187.10it/s]70657it [00:09, 14212.94it/s]72049it [00:09, 7805.67it/s] 
I1123 14:00:44.937322 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112314004493973c0a09e5d091target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_8.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-30-2161470-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-30-2161470-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5d2f7c40> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:00:50.283541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:50.283752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:50.283859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:50.284014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:50.284122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:00:50.284211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:00:50.352361: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:50.352505: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:00:50.459190: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:00:50.459316: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.89s/it]2049it [00:04, 710.07it/s]4097it [00:04, 1599.34it/s]6145it [00:04, 2663.28it/s]8193it [00:04, 3893.02it/s]10241it [00:04, 5204.56it/s]12289it [00:04, 6467.53it/s]14337it [00:05, 7775.18it/s]16385it [00:05, 8863.93it/s]18433it [00:05, 9943.53it/s]20481it [00:05, 10832.80it/s]22529it [00:05, 11233.53it/s]24138it [00:05, 12172.70it/s]25601it [00:05, 11162.15it/s]27649it [00:06, 11719.88it/s]29697it [00:06, 12377.43it/s]31745it [00:06, 12461.05it/s]33793it [00:06, 12447.78it/s]35841it [00:06, 12882.25it/s]37889it [00:06, 13174.88it/s]39937it [00:06, 13723.04it/s]41985it [00:07, 14014.33it/s]44033it [00:07, 14764.23it/s]46081it [00:07, 14961.87it/s]48129it [00:07, 14649.87it/s]50177it [00:07, 14114.09it/s]52225it [00:07, 13848.13it/s]54273it [00:07, 13766.93it/s]56321it [00:08, 13732.06it/s]58369it [00:08, 13830.48it/s]60417it [00:08, 14083.48it/s]62465it [00:08, 14088.52it/s]64513it [00:08, 14355.46it/s]66561it [00:08, 14556.99it/s]68609it [00:08, 14160.22it/s]70657it [00:09, 14161.38it/s]72049it [00:09, 7848.70it/s] 
I1123 14:00:59.292368 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140059dcc7dc0b0a385898target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_9.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-09-648441-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-09-648441-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f44893190> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:01:04.620550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:04.620762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:04.620883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:04.621039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:04.621149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:04.621236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:01:04.690037: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:04.690182: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:04.800695: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:01:04.800824: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.93s/it]1025it [00:04, 358.31it/s]3073it [00:04, 1284.55it/s]5121it [00:04, 2405.96it/s]7169it [00:04, 3690.81it/s]9217it [00:04, 5058.89it/s]11265it [00:04, 6421.65it/s]13313it [00:04, 7776.89it/s]15361it [00:05, 8948.52it/s]17409it [00:05, 9732.75it/s]19457it [00:05, 10341.82it/s]21270it [00:05, 11767.31it/s]22687it [00:05, 10980.37it/s]24577it [00:05, 11257.88it/s]26625it [00:06, 12148.11it/s]28673it [00:06, 13014.23it/s]30721it [00:06, 13330.57it/s]32769it [00:06, 13494.36it/s]34817it [00:06, 13354.72it/s]36865it [00:06, 13283.91it/s]38913it [00:06, 13853.93it/s]40961it [00:07, 13761.17it/s]43009it [00:07, 13599.93it/s]45057it [00:07, 13517.87it/s]47105it [00:07, 13303.01it/s]49153it [00:07, 13485.96it/s]51201it [00:07, 13642.61it/s]53249it [00:07, 13671.57it/s]55297it [00:08, 13889.46it/s]57345it [00:08, 13669.37it/s]59393it [00:08, 13699.22it/s]61441it [00:08, 13638.77it/s]63489it [00:08, 14057.13it/s]65537it [00:08, 14065.30it/s]67585it [00:08, 14004.65it/s]69633it [00:09, 13921.26it/s]71681it [00:09, 15148.86it/s]72049it [00:09, 7776.43it/s] 
I1123 14:01:13.661938 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140113d2334a1a03ff7d44target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_10.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-18-1296882-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-18-1296882-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc1664dc0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:01:19.065683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:19.065896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:19.066002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:19.066154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:19.066260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:19.066358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:01:19.133568: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:19.133700: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:19.239158: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:01:19.239284: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.87s/it]2049it [00:04, 714.75it/s]4097it [00:04, 1603.35it/s]6145it [00:04, 2670.33it/s]8193it [00:04, 3854.29it/s]10241it [00:04, 5215.28it/s]12289it [00:04, 6493.65it/s]14337it [00:04, 7699.20it/s]16385it [00:05, 8674.53it/s]18433it [00:05, 9869.17it/s]20481it [00:05, 11054.78it/s]22529it [00:05, 11503.38it/s]24524it [00:05, 13168.39it/s]26053it [00:05, 12150.56it/s]27649it [00:06, 11872.19it/s]29697it [00:06, 12301.97it/s]31745it [00:06, 12463.21it/s]33793it [00:06, 12645.26it/s]35841it [00:06, 13131.27it/s]37889it [00:06, 13435.88it/s]39937it [00:06, 13584.63it/s]41985it [00:07, 13540.05it/s]44033it [00:07, 13478.03it/s]46081it [00:07, 13420.18it/s]48129it [00:07, 13300.90it/s]50177it [00:07, 13195.06it/s]52225it [00:07, 13291.01it/s]54273it [00:07, 13412.28it/s]56321it [00:08, 13476.26it/s]58369it [00:08, 13611.47it/s]60417it [00:08, 13941.13it/s]62465it [00:08, 14688.16it/s]64513it [00:08, 14423.31it/s]66561it [00:08, 14197.29it/s]68609it [00:08, 13992.47it/s]70657it [00:09, 13886.38it/s]72049it [00:09, 7819.67it/s] 
I1123 14:01:28.128159 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511231401288fc8dc0b0a382a8atarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_11.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-00-0-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-00-0-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc1675430> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:01:33.482700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:33.482925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:33.483034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:33.483186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:33.483293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:33.483381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:01:33.552155: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:33.552287: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:33.657335: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:01:33.657496: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.92s/it]2049it [00:04, 705.87it/s]4097it [00:04, 1588.90it/s]6145it [00:04, 2647.82it/s]8193it [00:04, 3867.44it/s]10241it [00:04, 5218.79it/s]12289it [00:04, 6443.97it/s]14269it [00:04, 8214.42it/s]15735it [00:05, 8564.61it/s]17409it [00:05, 9154.38it/s]19457it [00:05, 10070.90it/s]21505it [00:05, 10718.55it/s]23300it [00:05, 12133.61it/s]24712it [00:05, 11232.91it/s]26625it [00:06, 11747.50it/s]28673it [00:06, 11763.46it/s]30721it [00:06, 12532.83it/s]32769it [00:06, 12694.96it/s]34587it [00:06, 13887.83it/s]36048it [00:06, 12254.94it/s]37889it [00:06, 12813.30it/s]39937it [00:06, 13718.16it/s]41985it [00:07, 14391.66it/s]44033it [00:07, 14328.47it/s]46081it [00:07, 13903.57it/s]48129it [00:07, 13642.61it/s]50177it [00:07, 13441.05it/s]52225it [00:07, 13720.93it/s]54273it [00:08, 14150.36it/s]56321it [00:08, 13837.26it/s]58369it [00:08, 13655.37it/s]60417it [00:08, 13460.63it/s]62465it [00:08, 13587.70it/s]64513it [00:08, 13849.44it/s]66561it [00:08, 13665.61it/s]68609it [00:09, 13627.09it/s]70657it [00:09, 13620.36it/s]72049it [00:09, 7746.94it/s] 
I1123 14:01:42.648944 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112314014291973c0a09e5a6ectarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_12.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-19-1368931-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-19-1368931-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f44af53a0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:01:47.967885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:47.968096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:47.968204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:47.968373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:47.968482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:01:47.968569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:01:48.037859: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:48.038015: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:01:48.147625: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:01:48.147755: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.93s/it]2049it [00:04, 704.71it/s]4097it [00:04, 1593.76it/s]6145it [00:04, 2675.46it/s]8193it [00:04, 3934.41it/s]10241it [00:04, 5264.01it/s]12289it [00:04, 6564.33it/s]14337it [00:05, 7875.93it/s]16385it [00:05, 8924.11it/s]17666it [00:05, 9563.55it/s]19457it [00:05, 9723.04it/s]21505it [00:05, 10713.23it/s]23553it [00:05, 11447.23it/s]25601it [00:05, 12045.31it/s]27649it [00:06, 12236.73it/s]29697it [00:06, 12345.36it/s]31745it [00:06, 12235.03it/s]33793it [00:06, 12680.00it/s]35841it [00:06, 12645.01it/s]37889it [00:06, 12859.43it/s]39937it [00:06, 13324.70it/s]41985it [00:07, 13471.27it/s]44033it [00:07, 13351.43it/s]46081it [00:07, 13321.03it/s]48129it [00:07, 13253.11it/s]50177it [00:07, 13260.71it/s]52225it [00:07, 13264.80it/s]54273it [00:08, 13496.41it/s]56321it [00:08, 13785.98it/s]58369it [00:08, 13693.19it/s]60417it [00:08, 13604.60it/s]62465it [00:08, 13657.52it/s]64513it [00:08, 14026.34it/s]66561it [00:08, 14437.61it/s]68609it [00:09, 14814.47it/s]70657it [00:09, 14745.65it/s]72049it [00:09, 7773.35it/s] 
I1123 14:01:56.944456 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112314015654f5da0b0a37c33atarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_13.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-16-1152784-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-16-1152784-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc15cdb80> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:02:02.576000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:02.576210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:02.576318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:02.576472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:02.576580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:02.576670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:02:02.646048: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:02.646188: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:02.754177: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:02:02.754306: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.82s/it]2049it [00:03, 723.81it/s]4097it [00:04, 1634.68it/s]6145it [00:04, 2716.48it/s]8193it [00:04, 3946.71it/s]10241it [00:04, 5278.90it/s]12289it [00:04, 6709.04it/s]14337it [00:04, 7995.75it/s]16385it [00:05, 9208.01it/s]18433it [00:05, 10077.50it/s]20481it [00:05, 10826.62it/s]21794it [00:05, 11261.93it/s]23496it [00:05, 12486.03it/s]24923it [00:05, 11454.93it/s]26625it [00:05, 11503.88it/s]28673it [00:06, 12099.58it/s]30721it [00:06, 12677.00it/s]32769it [00:06, 12624.94it/s]34817it [00:06, 12593.41it/s]36865it [00:06, 12753.06it/s]38913it [00:06, 13018.19it/s]40961it [00:06, 13092.15it/s]43009it [00:07, 13180.92it/s]45057it [00:07, 13160.98it/s]47105it [00:07, 13119.44it/s]49153it [00:07, 13221.64it/s]51201it [00:07, 13351.13it/s]53249it [00:07, 13345.53it/s]55297it [00:08, 13445.53it/s]57345it [00:08, 13460.28it/s]59393it [00:08, 13510.03it/s]61441it [00:08, 13499.96it/s]63489it [00:08, 13352.67it/s]65537it [00:08, 13249.24it/s]67585it [00:08, 13234.50it/s]69633it [00:09, 13253.69it/s]71681it [00:09, 14665.49it/s]72049it [00:09, 7796.83it/s] 
I1123 14:02:11.631681 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140211b1973c0a09e5f0f0target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_14.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-17-1224833-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-17-1224833-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc11314c0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:02:16.816743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:16.816949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:16.817061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:16.817212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:16.817333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:16.817425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:02:16.884201: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:16.884349: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:16.995941: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:02:16.996101: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.77s/it]1967it [00:03, 718.71it/s]3124it [00:04, 1233.15it/s]5121it [00:04, 2382.65it/s]7169it [00:04, 3697.02it/s]9217it [00:04, 5105.47it/s]11265it [00:04, 6403.96it/s]13313it [00:04, 7761.92it/s]15361it [00:04, 9077.38it/s]17409it [00:05, 10016.83it/s]19457it [00:05, 10780.23it/s]21505it [00:05, 11413.82it/s]23553it [00:05, 12040.17it/s]25601it [00:05, 12645.27it/s]27649it [00:05, 12715.59it/s]29697it [00:06, 12743.21it/s]31745it [00:06, 13037.41it/s]33793it [00:06, 13189.54it/s]35841it [00:06, 13464.22it/s]37384it [00:06, 13896.86it/s]38913it [00:06, 12460.31it/s]40961it [00:06, 12961.76it/s]43009it [00:06, 14136.10it/s]45057it [00:07, 15179.60it/s]47105it [00:07, 15842.80it/s]49153it [00:07, 15543.71it/s]51201it [00:07, 15471.42it/s]53249it [00:07, 15976.70it/s]55297it [00:07, 15581.39it/s]57345it [00:07, 15220.02it/s]59393it [00:08, 14650.01it/s]61441it [00:08, 14306.28it/s]63489it [00:08, 13949.23it/s]65537it [00:08, 14536.29it/s]67585it [00:08, 14453.16it/s]69633it [00:08, 14002.28it/s]71681it [00:08, 15324.41it/s]72049it [00:08, 8080.89it/s] 
I1123 14:02:25.678751 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140225e1cfdc0b0a384ed2target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_15.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-12-864588-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-12-864588-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5d5918b0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:02:30.942107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:30.942300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:30.942408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:30.942560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:30.942668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:30.942756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:02:31.009821: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:31.009961: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:31.119902: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:02:31.120086: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.77s/it]2049it [00:03, 731.88it/s]4097it [00:04, 1650.30it/s]6145it [00:04, 2735.82it/s]8193it [00:04, 3961.78it/s]10241it [00:04, 5256.06it/s]12289it [00:04, 6429.70it/s]14337it [00:04, 7746.77it/s]16094it [00:05, 9221.53it/s]17489it [00:05, 9283.74it/s]19457it [00:05, 10160.50it/s]21505it [00:05, 11078.94it/s]23553it [00:05, 11526.90it/s]25586it [00:05, 13328.46it/s]27094it [00:05, 12183.78it/s]28673it [00:06, 11518.57it/s]30721it [00:06, 12133.19it/s]32769it [00:06, 12824.90it/s]34817it [00:06, 13137.51it/s]36865it [00:06, 13338.84it/s]38913it [00:06, 13630.70it/s]40961it [00:06, 14051.76it/s]43009it [00:07, 13978.77it/s]45057it [00:07, 14788.14it/s]47105it [00:07, 15203.09it/s]49153it [00:07, 14918.01it/s]51201it [00:07, 14664.01it/s]53249it [00:07, 14197.43it/s]55297it [00:07, 13896.36it/s]57345it [00:08, 13661.19it/s]59393it [00:08, 13597.98it/s]61441it [00:08, 13553.04it/s]63489it [00:08, 13415.39it/s]65537it [00:08, 13548.05it/s]67585it [00:08, 13877.60it/s]69633it [00:08, 13674.30it/s]71681it [00:09, 14961.26it/s]72049it [00:09, 7924.12it/s] 
I1123 14:02:40.100679 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140240a2eedc0b0a386ad9target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_16.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-15-1080735-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-15-1080735-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc12a56a0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:02:45.510125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:45.510338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:45.510448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:45.510599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:45.510705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:45.510793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:02:45.578015: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:45.578144: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:45.683222: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:02:45.683370: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.88s/it]2049it [00:04, 709.85it/s]4097it [00:04, 1603.08it/s]6145it [00:04, 2696.69it/s]8193it [00:04, 3962.09it/s]10241it [00:04, 5329.23it/s]12289it [00:04, 6721.63it/s]14337it [00:04, 8015.08it/s]16385it [00:05, 8841.50it/s]18433it [00:05, 9635.99it/s]20481it [00:05, 10606.86it/s]22529it [00:05, 11276.84it/s]24577it [00:05, 11628.30it/s]26625it [00:05, 12137.73it/s]28673it [00:06, 12522.35it/s]30721it [00:06, 12900.85it/s]32769it [00:06, 13261.77it/s]34817it [00:06, 13132.20it/s]36865it [00:06, 13029.95it/s]38913it [00:06, 12766.36it/s]40961it [00:07, 12765.21it/s]43009it [00:07, 13277.38it/s]45057it [00:07, 13394.07it/s]47105it [00:07, 13574.00it/s]49153it [00:07, 13687.71it/s]51201it [00:07, 14045.81it/s]53249it [00:07, 14518.29it/s]55297it [00:07, 14833.92it/s]57345it [00:08, 14678.44it/s]59393it [00:08, 14372.38it/s]61441it [00:08, 13994.59it/s]63489it [00:08, 13867.05it/s]65537it [00:08, 13946.46it/s]67585it [00:08, 13817.75it/s]69633it [00:09, 13705.18it/s]71681it [00:09, 15035.26it/s]72049it [00:09, 7853.07it/s] 
I1123 14:02:54.450417 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140254cbcfdc0b0a3872datarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_17.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-20-1440980-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-20-1440980-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3e172b55e0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:02:59.615651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:59.615876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:59.615988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:59.616140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:59.616247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:02:59.616333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:02:59.684184: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:59.684325: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:02:59.790763: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:02:59.790945: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.91s/it]2049it [00:04, 705.58it/s]4097it [00:04, 1586.54it/s]6145it [00:04, 2642.91it/s]8193it [00:04, 3854.08it/s]10241it [00:04, 5110.09it/s]12289it [00:04, 6474.87it/s]14337it [00:05, 7914.49it/s]16385it [00:05, 9126.38it/s]18433it [00:05, 10274.41it/s]20481it [00:05, 11249.70it/s]22529it [00:05, 11420.27it/s]24577it [00:05, 11902.49it/s]26625it [00:05, 12437.76it/s]28673it [00:06, 12565.12it/s]30721it [00:06, 12868.08it/s]32769it [00:06, 12875.09it/s]34817it [00:06, 13178.56it/s]36865it [00:06, 13126.95it/s]38913it [00:06, 12919.85it/s]40961it [00:07, 12515.18it/s]43009it [00:07, 12599.55it/s]45057it [00:07, 13443.07it/s]47105it [00:07, 13609.80it/s]49153it [00:07, 13807.23it/s]51201it [00:07, 13663.34it/s]53249it [00:07, 13675.29it/s]55297it [00:08, 13644.14it/s]57345it [00:08, 13877.75it/s]59393it [00:08, 13615.53it/s]61441it [00:08, 13873.53it/s]63489it [00:08, 13781.19it/s]65537it [00:08, 13675.08it/s]67585it [00:08, 13538.19it/s]69633it [00:09, 13481.29it/s]71681it [00:09, 14735.69it/s]72049it [00:09, 7766.42it/s] 
I1123 14:03:08.485610 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140308a2eedc0b0a38760btarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_18.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-28-2017372-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-28-2017372-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5d523fa0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:03:13.794957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:13.795168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:13.795276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:13.795456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:13.795566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:13.795656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:03:13.862576: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:13.862710: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:13.969787: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:03:13.969938: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.80s/it]2049it [00:03, 727.74it/s]3997it [00:04, 1633.38it/s]5309it [00:04, 2304.17it/s]7169it [00:04, 3461.16it/s]9217it [00:04, 4967.37it/s]11265it [00:04, 6513.98it/s]13313it [00:04, 8016.96it/s]15361it [00:04, 9379.92it/s]17409it [00:05, 10338.04it/s]19457it [00:05, 11229.83it/s]21436it [00:05, 12914.78it/s]22992it [00:05, 11807.90it/s]24577it [00:05, 11193.24it/s]26625it [00:05, 11860.88it/s]28673it [00:05, 12301.45it/s]30721it [00:06, 12632.69it/s]32769it [00:06, 12523.88it/s]34817it [00:06, 13034.36it/s]36148it [00:06, 12661.67it/s]37889it [00:06, 12041.39it/s]39937it [00:06, 12505.58it/s]41985it [00:07, 12753.95it/s]44033it [00:07, 13321.17it/s]46081it [00:07, 13256.07it/s]48129it [00:07, 13867.53it/s]50177it [00:07, 14001.88it/s]52225it [00:07, 14154.78it/s]54273it [00:07, 14161.86it/s]56321it [00:08, 13950.56it/s]58369it [00:08, 14025.99it/s]60417it [00:08, 14141.33it/s]62465it [00:08, 14076.44it/s]64513it [00:08, 13847.39it/s]66561it [00:08, 13626.35it/s]68609it [00:08, 13561.96it/s]70657it [00:09, 13451.73it/s]72049it [00:09, 7886.10it/s] 
I1123 14:03:22.719979 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140322d4334a1a09e5e030target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_19.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-24-1729176-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-24-1729176-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc11576d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:03:28.352285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:28.352451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:28.352527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:28.352641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:28.352717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:28.352780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:03:28.398076: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:28.398178: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:28.466711: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:03:28.466874: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.76s/it]2049it [00:03, 735.34it/s]4097it [00:04, 1661.77it/s]6145it [00:04, 2784.82it/s]8193it [00:04, 4080.17it/s]10241it [00:04, 5542.20it/s]12289it [00:04, 6858.05it/s]14337it [00:04, 8324.02it/s]16385it [00:04, 9638.74it/s]18433it [00:05, 10279.79it/s]20481it [00:05, 10847.53it/s]22529it [00:05, 11404.23it/s]24577it [00:05, 11742.90it/s]26625it [00:05, 12027.35it/s]28476it [00:05, 13340.81it/s]29933it [00:05, 12113.04it/s]31745it [00:06, 12226.86it/s]33793it [00:06, 12707.75it/s]35841it [00:06, 12859.17it/s]37889it [00:06, 13227.47it/s]39937it [00:06, 13054.78it/s]41985it [00:06, 13760.04it/s]44033it [00:07, 14178.02it/s]46081it [00:07, 14791.95it/s]48129it [00:07, 14564.73it/s]50177it [00:07, 14099.95it/s]52225it [00:07, 14655.89it/s]54273it [00:07, 14619.35it/s]56321it [00:07, 14794.08it/s]58369it [00:07, 14738.27it/s]60417it [00:08, 14470.21it/s]62465it [00:08, 14167.33it/s]64513it [00:08, 14015.40it/s]66561it [00:08, 13773.75it/s]68609it [00:08, 13692.84it/s]70657it [00:08, 13691.01it/s]72049it [00:08, 8048.05it/s] 
I1123 14:03:37.214258 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140337b2c8dc0b0a3882b1target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_20.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-02-144098-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-02-144098-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc1187460> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:03:42.305569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:42.305774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:42.305880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:42.306031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:42.306138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:42.306227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:03:42.373537: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:42.373663: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:42.479372: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:03:42.479540: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.84s/it]2049it [00:04, 719.31it/s]4097it [00:04, 1614.57it/s]6145it [00:04, 2672.07it/s]7579it [00:04, 3587.13it/s]9217it [00:04, 4595.23it/s]11265it [00:04, 6023.53it/s]13015it [00:04, 7591.88it/s]14372it [00:05, 7765.82it/s]16385it [00:05, 9030.02it/s]18433it [00:05, 9904.69it/s]20481it [00:05, 10727.75it/s]22529it [00:05, 11191.26it/s]24577it [00:05, 11561.99it/s]26625it [00:05, 12079.79it/s]28673it [00:06, 12257.37it/s]30721it [00:06, 12345.86it/s]32769it [00:06, 12404.15it/s]34817it [00:06, 12404.10it/s]36865it [00:06, 12820.34it/s]38913it [00:06, 12915.06it/s]40961it [00:07, 13343.10it/s]43009it [00:07, 13900.02it/s]45057it [00:07, 13883.52it/s]47105it [00:07, 13428.82it/s]49153it [00:07, 13517.97it/s]51201it [00:07, 13288.48it/s]53249it [00:07, 13410.64it/s]55297it [00:08, 13467.74it/s]57345it [00:08, 13474.72it/s]59393it [00:08, 13647.56it/s]61441it [00:08, 13530.38it/s]63489it [00:08, 13332.84it/s]65537it [00:08, 13306.24it/s]67585it [00:09, 13225.08it/s]69633it [00:09, 13254.92it/s]71681it [00:09, 14480.81it/s]72049it [00:09, 7692.90it/s] 
I1123 14:03:51.613353 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140351d2f2dc0b0a386898target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_21.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-13-936637-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-13-936637-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc1698670> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:03:56.987540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:56.987733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:56.987841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:56.988007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:56.988116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:03:56.988204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:03:57.057563: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:57.057746: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:03:57.168573: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:03:57.168699: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.85s/it]2049it [00:04, 718.63it/s]4097it [00:04, 1610.68it/s]6145it [00:04, 2674.19it/s]8193it [00:04, 3919.09it/s]10241it [00:04, 5337.17it/s]12289it [00:04, 6739.33it/s]14337it [00:04, 8051.23it/s]16385it [00:05, 9278.38it/s]18433it [00:05, 10231.23it/s]20481it [00:05, 10833.84it/s]22529it [00:05, 11440.65it/s]24577it [00:05, 11831.33it/s]26625it [00:05, 12111.33it/s]28673it [00:06, 12611.96it/s]30640it [00:06, 14093.34it/s]32159it [00:06, 13204.23it/s]33793it [00:06, 12529.07it/s]35841it [00:06, 13122.88it/s]37889it [00:06, 13577.85it/s]39937it [00:06, 14319.45it/s]41985it [00:06, 14919.73it/s]44033it [00:07, 15071.08it/s]46081it [00:07, 14688.89it/s]48129it [00:07, 14490.11it/s]50177it [00:07, 14377.43it/s]52225it [00:07, 14802.34it/s]54273it [00:07, 14414.33it/s]56321it [00:07, 13963.77it/s]58369it [00:08, 13796.92it/s]60417it [00:08, 13744.65it/s]62465it [00:08, 13683.98it/s]64513it [00:08, 13600.30it/s]66561it [00:08, 13669.06it/s]68609it [00:08, 13827.95it/s]70657it [00:08, 13913.31it/s]72049it [00:09, 7961.86it/s] 
I1123 14:04:05.840868 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140405da334a1a09e562a6target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_22.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-03-216147-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-03-216147-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3e173297f0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:04:10.763730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:10.763899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:10.763977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:10.764090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:10.764166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:10.764231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:04:10.810508: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:10.810612: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:10.879535: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:04:10.879666: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.42s/it]2049it [00:03, 798.59it/s]4097it [00:03, 1786.27it/s]6145it [00:03, 2983.53it/s]8193it [00:04, 4302.32it/s]10241it [00:04, 5807.69it/s]12289it [00:04, 7316.84it/s]14337it [00:04, 8571.25it/s]16385it [00:04, 9796.08it/s]18433it [00:04, 10817.49it/s]20481it [00:04, 11603.49it/s]22529it [00:05, 11836.40it/s]24577it [00:05, 12290.10it/s]26625it [00:05, 12819.70it/s]28673it [00:05, 13049.12it/s]30721it [00:05, 13098.67it/s]32769it [00:05, 13084.07it/s]34817it [00:05, 13317.27it/s]36865it [00:06, 13404.82it/s]38913it [00:06, 13459.62it/s]40961it [00:06, 13498.95it/s]43009it [00:06, 13924.65it/s]45057it [00:06, 14327.87it/s]47105it [00:06, 14764.34it/s]49153it [00:06, 14662.95it/s]51201it [00:07, 15018.98it/s]53249it [00:07, 15552.23it/s]55297it [00:07, 15384.31it/s]57345it [00:07, 14881.43it/s]59393it [00:07, 14421.00it/s]61441it [00:07, 14439.68it/s]63489it [00:07, 14171.77it/s]65537it [00:08, 14162.05it/s]67585it [00:08, 14355.65it/s]69633it [00:08, 14316.90it/s]71681it [00:08, 15549.42it/s]72049it [00:08, 8460.17it/s] 
I1123 14:04:19.181865 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140419a2eedc0b0a388f4dtarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_23.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-11-792539-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-11-792539-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc16dbee0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:04:24.481475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:24.481641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:24.481720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:24.481842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:24.481932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:24.481999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:04:24.528155: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:24.528257: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:24.598888: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:04:24.599052: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.62s/it]2049it [00:03, 764.52it/s]4097it [00:03, 1706.88it/s]6145it [00:04, 2808.56it/s]8193it [00:04, 4066.53it/s]10241it [00:04, 5410.55it/s]12289it [00:04, 6784.47it/s]14337it [00:04, 7986.68it/s]16385it [00:04, 9155.96it/s]18433it [00:05, 10073.50it/s]20481it [00:05, 10888.75it/s]22529it [00:05, 11543.87it/s]24577it [00:05, 11853.74it/s]26625it [00:05, 12083.36it/s]28673it [00:05, 12457.68it/s]30721it [00:05, 12776.37it/s]32769it [00:06, 13032.64it/s]34817it [00:06, 13340.78it/s]36865it [00:06, 13826.98it/s]38913it [00:06, 13415.87it/s]40961it [00:06, 13671.26it/s]43009it [00:06, 14008.12it/s]45057it [00:06, 14501.69it/s]47105it [00:07, 14272.77it/s]49153it [00:07, 13933.33it/s]51201it [00:07, 13719.70it/s]53249it [00:07, 13638.77it/s]55297it [00:07, 14485.48it/s]57345it [00:07, 14630.82it/s]59393it [00:07, 14372.65it/s]61441it [00:08, 14215.48it/s]63489it [00:08, 14129.48it/s]65537it [00:08, 13833.51it/s]67585it [00:08, 13786.35it/s]69633it [00:08, 13718.37it/s]71681it [00:08, 15096.56it/s]72049it [00:08, 8105.66it/s] 
I1123 14:04:33.103888 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140433a2eedc0b0a389424target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_24.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-27-1945323-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-27-1945323-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5d2cb9d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:04:38.088354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:38.088583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:38.088695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:38.088850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:38.088959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:38.089046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:04:38.156861: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:38.157020: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:38.261488: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:04:38.261655: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.95s/it]1647it [00:04, 574.49it/s]3073it [00:04, 1195.63it/s]5121it [00:04, 2325.31it/s]7169it [00:04, 3618.83it/s]9217it [00:04, 5024.77it/s]11265it [00:04, 6429.38it/s]13313it [00:04, 7828.80it/s]15361it [00:05, 8903.96it/s]17409it [00:05, 9779.05it/s]19457it [00:05, 10693.10it/s]21505it [00:05, 11380.06it/s]23553it [00:05, 11847.28it/s]25601it [00:05, 11837.26it/s]27649it [00:06, 12402.73it/s]29697it [00:06, 13000.99it/s]31745it [00:06, 13346.42it/s]33793it [00:06, 13364.02it/s]35841it [00:06, 12990.07it/s]37889it [00:06, 12874.50it/s]39937it [00:07, 12375.49it/s]41985it [00:07, 12644.90it/s]44033it [00:07, 12962.86it/s]46081it [00:07, 13799.52it/s]48129it [00:07, 14452.82it/s]50177it [00:07, 14516.49it/s]52225it [00:07, 14537.02it/s]54273it [00:07, 14542.12it/s]56321it [00:08, 14165.93it/s]58369it [00:08, 14183.62it/s]60417it [00:08, 14294.81it/s]62465it [00:08, 14069.51it/s]64513it [00:08, 14100.14it/s]66561it [00:08, 14340.24it/s]68609it [00:09, 14051.67it/s]70657it [00:09, 13908.34it/s]72049it [00:09, 7810.94it/s] 
I1123 14:04:47.245950 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=2025112314044797334a1a09e61a90target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_25.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-08-576392-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-08-576392-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc110eeb0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:04:52.484493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:52.484688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:52.484797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:52.484965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:52.485099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:04:52.485188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:04:52.553739: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:52.553866: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:04:52.660289: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:04:52.660419: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.77s/it]2049it [00:03, 736.23it/s]4097it [00:04, 1654.24it/s]6094it [00:04, 2818.26it/s]7523it [00:04, 3630.27it/s]9217it [00:04, 4811.56it/s]10470it [00:04, 5736.53it/s]12200it [00:04, 7465.75it/s]13594it [00:04, 7915.07it/s]15361it [00:04, 8859.01it/s]17409it [00:05, 9926.18it/s]19457it [00:05, 11004.82it/s]21505it [00:05, 11527.02it/s]23553it [00:05, 12210.73it/s]25601it [00:05, 12549.23it/s]27649it [00:05, 12792.74it/s]29697it [00:06, 12785.26it/s]31745it [00:06, 12687.14it/s]33793it [00:06, 12915.07it/s]35189it [00:06, 13138.87it/s]36865it [00:06, 11829.22it/s]38913it [00:06, 12086.51it/s]40961it [00:06, 12984.12it/s]43009it [00:07, 14278.38it/s]45057it [00:07, 14867.78it/s]47105it [00:07, 15430.47it/s]49153it [00:07, 15577.22it/s]51201it [00:07, 15265.00it/s]53249it [00:07, 15157.55it/s]55297it [00:07, 15002.23it/s]57345it [00:07, 14729.14it/s]59393it [00:08, 14381.78it/s]61441it [00:08, 14289.59it/s]63489it [00:08, 13840.02it/s]65537it [00:08, 13768.19it/s]67585it [00:08, 13605.60it/s]69633it [00:08, 13639.71it/s]71681it [00:08, 15055.69it/s]72049it [00:09, 7977.78it/s] 
I1123 14:05:01.254298 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511231405011c344a1a09e60236target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_26.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-07-504343-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-07-504343-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f449fc3d0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:05:06.011981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:06.012148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:06.012228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:06.012346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:06.012422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:06.012496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:05:06.058658: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:06.058756: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:06.130810: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:05:06.131068: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:02,  2.85s/it]2049it [00:03, 951.23it/s]4097it [00:03, 2094.47it/s]6145it [00:03, 3445.37it/s]8193it [00:03, 4909.05it/s]10241it [00:03, 6469.78it/s]12289it [00:03, 7986.48it/s]14337it [00:03, 9435.86it/s]16385it [00:04, 10548.49it/s]18433it [00:04, 11524.53it/s]20481it [00:04, 11944.82it/s]22529it [00:04, 12211.95it/s]24577it [00:04, 12214.67it/s]26625it [00:04, 12437.53it/s]28673it [00:04, 12633.33it/s]30721it [00:05, 12684.26it/s]32769it [00:05, 12746.49it/s]34817it [00:05, 12634.53it/s]36865it [00:05, 12593.62it/s]38913it [00:05, 12614.06it/s]40961it [00:05, 12531.95it/s]43009it [00:06, 12605.46it/s]45057it [00:06, 12924.72it/s]47105it [00:06, 13084.09it/s]49153it [00:06, 13298.60it/s]51201it [00:06, 13417.35it/s]53249it [00:06, 13726.81it/s]55297it [00:06, 13964.08it/s]57345it [00:07, 14314.17it/s]59393it [00:07, 14691.16it/s]61441it [00:07, 14779.70it/s]63489it [00:07, 14782.46it/s]65537it [00:07, 15163.89it/s]67585it [00:07, 14508.90it/s]69633it [00:07, 14181.00it/s]71681it [00:08, 15493.87it/s]72049it [00:08, 8917.46it/s] 
I1123 14:05:14.201996 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140514b0973c0a09e61345target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_27.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-26-1873274-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-26-1873274-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f44ad2b20> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:05:19.505196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:19.505409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:19.505517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:19.505672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:19.505808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:19.505911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:05:19.572129: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:19.572260: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:19.676791: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:05:19.676928: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.51s/it]2049it [00:03, 780.68it/s]4097it [00:03, 1762.65it/s]6145it [00:03, 2918.68it/s]8193it [00:04, 4241.66it/s]10241it [00:04, 5624.07it/s]12289it [00:04, 7056.42it/s]14337it [00:04, 8220.15it/s]16385it [00:04, 9469.34it/s]18433it [00:04, 10679.91it/s]20347it [00:04, 12277.67it/s]21889it [00:05, 11948.75it/s]23553it [00:05, 11690.81it/s]25601it [00:05, 12073.64it/s]27649it [00:05, 12720.48it/s]29697it [00:05, 12735.31it/s]31745it [00:05, 13081.15it/s]33793it [00:06, 12883.43it/s]35841it [00:06, 13127.38it/s]37889it [00:06, 13329.96it/s]39937it [00:06, 13190.16it/s]41985it [00:06, 13061.71it/s]44033it [00:06, 13007.76it/s]46081it [00:06, 13011.83it/s]48129it [00:07, 13120.13it/s]50177it [00:07, 13034.08it/s]52225it [00:07, 13234.06it/s]54273it [00:07, 13577.35it/s]56321it [00:07, 14199.37it/s]58369it [00:07, 14593.39it/s]60417it [00:07, 14808.15it/s]62465it [00:08, 14753.51it/s]64513it [00:08, 14617.13it/s]66561it [00:08, 14537.27it/s]68609it [00:08, 14519.95it/s]70657it [00:08, 14566.46it/s]72049it [00:08, 8253.80it/s] 
I1123 14:05:27.966947 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140527d8c7dc0b0a37f636target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_28.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-25-1801225-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-25-1801225-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3fc1319760> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:05:33.219513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:33.219747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:33.219862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:33.220018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:33.220127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:33.220221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:05:33.287224: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:33.287356: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:33.381999: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:05:33.382148: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.32s/it]2049it [00:03, 832.13it/s]4097it [00:03, 1868.56it/s]6145it [00:03, 3090.90it/s]8193it [00:03, 4448.91it/s]10241it [00:04, 5858.12it/s]12289it [00:04, 7287.60it/s]14337it [00:04, 8677.46it/s]16385it [00:04, 9864.60it/s]18327it [00:04, 11531.95it/s]19861it [00:04, 11331.37it/s]21505it [00:04, 11121.65it/s]23553it [00:05, 11847.14it/s]25601it [00:05, 12697.52it/s]27649it [00:05, 13016.13it/s]29697it [00:05, 13154.18it/s]31745it [00:05, 13638.91it/s]33793it [00:05, 13775.90it/s]35841it [00:05, 13836.56it/s]37889it [00:06, 13633.38it/s]39937it [00:06, 13417.78it/s]41985it [00:06, 13533.11it/s]44033it [00:06, 13349.81it/s]46081it [00:06, 13336.24it/s]48129it [00:06, 13565.11it/s]50177it [00:06, 13565.46it/s]52225it [00:07, 13426.01it/s]54273it [00:07, 13323.85it/s]56321it [00:07, 13501.20it/s]58369it [00:07, 13487.86it/s]60417it [00:07, 13758.50it/s]62465it [00:07, 13643.94it/s]64513it [00:08, 13514.05it/s]66561it [00:08, 13378.61it/s]68609it [00:08, 13372.31it/s]70657it [00:08, 13525.50it/s]72049it [00:08, 8417.73it/s] 
I1123 14:05:41.575217 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140541d7334a1a09e5481ftarget project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_29.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-06-432294-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-06-432294-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5d483b80> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:05:47.034287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:47.034506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:47.034619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:47.034775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:47.034885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:05:47.034982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:05:47.102980: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:47.103118: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:05:47.211291: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:05:47.211427: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.43s/it]2049it [00:03, 803.07it/s]4097it [00:03, 1793.53it/s]6145it [00:03, 2959.99it/s]8193it [00:04, 4281.40it/s]10241it [00:04, 5687.71it/s]12289it [00:04, 7079.73it/s]14337it [00:04, 8390.94it/s]16385it [00:04, 9522.46it/s]18433it [00:04, 10518.45it/s]20481it [00:04, 11376.17it/s]22320it [00:05, 12756.17it/s]23821it [00:05, 11799.30it/s]25601it [00:05, 11717.09it/s]27649it [00:05, 12065.39it/s]29697it [00:05, 12610.87it/s]31745it [00:05, 13324.98it/s]33793it [00:05, 13570.52it/s]35841it [00:06, 13773.70it/s]37889it [00:06, 13790.61it/s]39937it [00:06, 13580.00it/s]41985it [00:06, 13459.75it/s]44033it [00:06, 13377.62it/s]46081it [00:06, 13317.26it/s]48129it [00:07, 12983.79it/s]50177it [00:07, 12867.08it/s]52225it [00:07, 12923.34it/s]54273it [00:07, 12977.50it/s]56321it [00:07, 13110.26it/s]58369it [00:07, 13215.93it/s]60417it [00:07, 13460.84it/s]62465it [00:08, 13701.90it/s]64513it [00:08, 13928.31it/s]66561it [00:08, 13815.23it/s]68609it [00:08, 13519.54it/s]70657it [00:08, 13535.62it/s]72049it [00:08, 8221.84it/s] 
I1123 14:05:55.639154 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511231405559c334a1a09e5f515target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_30.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-14-1008686-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-14-1008686-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f44b01610> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:06:00.886618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:00.886836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:00.886944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:00.887099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:00.887206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:00.887299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:06:00.953771: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:06:00.953900: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:06:01.060291: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
2025-11-23 14:06:01.060457: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.39s/it]2049it [00:03, 811.33it/s]4097it [00:03, 1814.91it/s]6145it [00:03, 3024.39it/s]8193it [00:03, 4381.30it/s]10241it [00:04, 5873.32it/s]12289it [00:04, 7371.70it/s]14337it [00:04, 8793.01it/s]16385it [00:04, 9913.02it/s]18433it [00:04, 10806.70it/s]20481it [00:04, 11664.28it/s]22529it [00:04, 12253.33it/s]24577it [00:05, 12334.36it/s]26625it [00:05, 12729.07it/s]28673it [00:05, 13101.36it/s]30721it [00:05, 13565.89it/s]32769it [00:05, 13831.90it/s]34817it [00:05, 14050.08it/s]36865it [00:06, 14248.02it/s]38913it [00:06, 14253.87it/s]40961it [00:06, 14021.71it/s]43009it [00:06, 13896.42it/s]45057it [00:06, 13812.02it/s]47105it [00:06, 13707.48it/s]49153it [00:06, 13766.57it/s]51201it [00:07, 13805.42it/s]53249it [00:07, 13682.90it/s]55297it [00:07, 13683.47it/s]57345it [00:07, 13903.23it/s]59393it [00:07, 14225.33it/s]61441it [00:07, 13780.87it/s]63489it [00:07, 14420.58it/s]65537it [00:08, 15559.77it/s]67585it [00:08, 15306.55it/s]69633it [00:08, 14732.84it/s]71681it [00:08, 15769.06it/s]72049it [00:08, 8515.29it/s] 
I1123 14:06:09.337404 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=202511231406098fc8dc0b0a388f89target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
----predict file:/data/share/opt/model/O35_mutil_cvr_v10/logs/pred_202511220000_31.csv,data_file:/data/share/opt/data/O35_mutil_cvr/20251122/part-r-22-1585078-72049.gz------
0it [00:00, ?it/s]INFO:tensorflow:filenames=['/data/share/opt/data/O35_mutil_cvr/20251122/part-r-22-1585078-72049.gz']
INFO:tensorflow:('>>>', '/data/share/opt/model/O35_mutil_cvr_v10', 1, 0, True, 1, 1024)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:------ mode: infer strategy is <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3fc163dd30> -------
INFO:tensorflow:------ features: {'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'requestid': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'combination_un_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'ctr_label': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'awake_label': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'sd_label': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'sd_weight': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'lhb_label': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'lhb_weight': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ymfw_label': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ymfw_weight': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'features': <tf.Tensor 'IteratorGetNext:11' shape=(None, 487) dtype=string>} -------
INFO:tensorflow:------ params: {'mode': 'infer', 'ps_num': 1, 'task_number': 1, 'task_type': 'chief', 'task_idx': 0, 'slot': '', 'restrict': False, 'device': 'GPU', 'gpu_ids': ['0'], 'optimize_config': {'learning_rate': 0.005, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08}, 'use_senet': False, 'mlp_config': {'hidden_units': [256, 128, 64, 32], 'hidden_activations': 'relu', 'output_dim': 1, 'output_activation': None, 'dropout_rates': 0, 'batch_norm': False, 'bn_only_once': False, 'kernel_initializer': 'glorot_uniform', 'output_kernel_initializer': 'glorot_uniform', 'bias_initializer': 'glorot_uniform', 'use_bias': True}, 'awake_fusion_type': 'mlp', 'awake_fusion_hidden_units': [32], 'mmoe_fusion_type': 'mlp', 'mmoe_fusion_hidden_units': [32], 'mmoe_config': {'num_domains': 3, 'num_experts': 6, 'exprt_units': [128, 64, 128], 'hidden_units': [128, 64, 32], 'hidden_activations': 'relu', 'dropout_rates': 0, 'batch_norm': False}} -------
INFO:tensorflow:------ dynamic_embedding devices_info is ['/job:localhost/replica:0/task:0/GPU:0'] -------
INFO:tensorflow:------embeddings: <tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_variable.Variable object at 0x7f3f5d583be0> emb_lookuped: Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32) -------
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("ctr_tower/dense/activation/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("ctr_tower/dense_1/activation_1/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("ctr_tower/dense_2/activation_2/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---click_label=Tensor("IteratorGetNext:3", shape=(None,), dtype=float32, device=/device:CPU:0), ctr_logits=Tensor("ctr_tower/Sigmoid:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("Reshape_6:0", shape=(None, 4383), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("awake_tower/dense_5/activation_4/Relu:0", shape=(None, 256), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("awake_tower/dense_6/activation_5/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-3-inputs=Tensor("awake_tower/dense_7/activation_6/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------awake-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("awake_tower/concat:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:---awake_label=Tensor("IteratorGetNext:4", shape=(None,), dtype=float32, device=/device:CPU:0), awake_logits=Tensor("awake_tower/Sigmoid:0", shape=(None,), dtype=float32), awake_ctcvr=Tensor("awake_tower/Reshape_1:0", shape=(None,), dtype=float32)---
/opt/huangmian/yoyo_model/layers/mmoe.py:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  fea = tf.compat.v1.layers.dense(inputs=deep_feas, units=unit, name=name)
/root/anaconda3/envs/env_gpu/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs)
INFO:tensorflow:multi_task_outlist=[<tf.Tensor 'mmoe_tower/Sum:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'mmoe_tower/Sum_2:0' shape=(None, 128) dtype=float32>]
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_12/activation_28/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_13/activation_29/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------sd-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---sd_label-label:Tensor("IteratorGetNext:5", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_1:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_16/activation_31/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_17/activation_32/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------lhb-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_1:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---lhb_label-label:Tensor("IteratorGetNext:7", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_1:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_3:0", shape=(None,), dtype=float32)---
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-1-inputs=Tensor("mmoe_tower/dense_20/activation_34/Relu:0", shape=(None, 128), dtype=float32)
INFO:tensorflow:mlp-2-inputs=Tensor("mmoe_tower/dense_21/activation_35/Relu:0", shape=(None, 64), dtype=float32)
INFO:tensorflow:------ymfw-ctcvr_fusion.type=mlp-----------
INFO:tensorflow:mlp-0-inputs=Tensor("mmoe_tower/concat_2:0", shape=(None, 96), dtype=float32)
INFO:tensorflow:---ymfw_label-label:Tensor("IteratorGetNext:9", shape=(None,), dtype=float32, device=/device:CPU:0), task_out:Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32), task_logits:Tensor("mmoe_tower/Sigmoid_2:0", shape=(None,), dtype=float32), task_ctcvr:Tensor("mmoe_tower/Reshape_5:0", shape=(None,), dtype=float32)---
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2025-11-23 14:06:14.381284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:14.381485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:14.381583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:14.381720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:14.381809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2025-11-23 14:06:14.381899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43784 MB memory:  -> device: 0, name: NVIDIA L20, pci bus id: 0000:00:03.0, compute capability: 8.9
INFO:tensorflow:Restoring parameters from /data/share/opt/model/O35_mutil_cvr_v10/202511210000/model.ckpt-160533
2025-11-23 14:06:14.431435: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
Identity: GPU CPU 
TFRA>CuckooHashTableOfTensors: CPU 
TFRA>CuckooHashTableSize: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableFind: CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  embeddings/embeddings_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings/embeddings_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  embeddings_mht_1of1_Size/TFRA>CuckooHashTableSize (TFRA>CuckooHashTableSize) /job:localhost/replica:0/task:0/device:GPU:0
  lookup/lookup/Read/embeddings_mht_1of1_lookup_table_find/TFRA>CuckooHashTableFind (TFRA>CuckooHashTableFind) /job:localhost/replica:0/task:0/device:GPU:0
  save/embeddings_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/embeddings/embeddings_mht_1of1/_6 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_112 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/embeddings_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_118 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:06:14.431535: W tensorflow/core/common_runtime/colocation_graph.cc:1203] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
TFRA>CuckooHashTableRemove: CPU 
TFRA>CuckooHashTableExport: CPU 
TFRA>CuckooHashTableImport: CPU 
TFRA>CuckooHashTableInsert: CPU 
TFRA>CuckooHashTableOfTensors: CPU 
Identity: GPU CPU 
Switch: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  status/timestamp/status_embeddings_timestamp_mht_1of1 (TFRA>CuckooHashTableOfTensors) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status/timestamp/status_embeddings_timestamp_mht_1of1_lookup_table_export_values_1/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  status_embeddings_timestamp_mht_1of1_lookup_table_insert/TFRA>CuckooHashTableInsert (TFRA>CuckooHashTableInsert) /job:localhost/replica:0/task:0/device:GPU:0
  save/status_embeddings_timestamp_mht_1of1_table_restore/TFRA>CuckooHashTableImport (TFRA>CuckooHashTableImport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/status/timestamp/status_embeddings_timestamp_mht_1of1/_5 (Switch) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/then/_0/input/_111 (Identity) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport (TFRA>CuckooHashTableExport) /job:localhost/replica:0/task:0/device:GPU:0
  cond/then/_0/status_embeddings_timestamp_mht_1of1_lookup_table_remove/TFRA>CuckooHashTableRemove (TFRA>CuckooHashTableRemove) /job:localhost/replica:0/task:0/device:GPU:0
  Func/cond/else/_1/input/_117 (Identity) /job:localhost/replica:0/task:0/device:GPU:0

2025-11-23 14:06:14.500419: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=8192
2025-11-23 14:06:14.500551: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=f, DIM=9, init_size=8192
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
1it [00:03,  3.14s/it]2049it [00:03, 871.45it/s]4097it [00:03, 1939.19it/s]6145it [00:03, 3208.18it/s]8193it [00:03, 4623.97it/s]10241it [00:03, 6087.08it/s]12289it [00:04, 7581.92it/s]14337it [00:04, 9025.72it/s]16385it [00:04, 10110.11it/s]18433it [00:04, 10887.92it/s]20481it [00:04, 11729.85it/s]22529it [00:04, 12205.06it/s]24577it [00:04, 12650.76it/s]26625it [00:05, 13216.57it/s]28673it [00:05, 13641.27it/s]30721it [00:05, 13598.67it/s]32769it [00:05, 13515.35it/s]34817it [00:05, 13566.56it/s]36865it [00:05, 13846.30it/s]38913it [00:05, 13960.21it/s]40961it [00:06, 13792.65it/s]43009it [00:06, 13601.13it/s]45057it [00:06, 13475.07it/s]47105it [00:06, 13304.92it/s]49153it [00:06, 13269.41it/s]51201it [00:06, 13163.42it/s]53249it [00:07, 13334.81it/s]55297it [00:07, 13521.82it/s]57345it [00:07, 13522.18it/s]59393it [00:07, 13472.03it/s]61441it [00:07, 13478.64it/s]63489it [00:07, 13895.05it/s]65537it [00:07, 13842.40it/s]67585it [00:08, 13757.28it/s]69633it [00:08, 13890.89it/s]72049it [00:08, 8657.76it/s] 
I1123 14:06:22.636399 139912616068928 tabletunnel.py:541] Tunnel session created: <TableUploadSession id=20251123140622d4334a1a09e61b28target project=adx_dmp table=ads_algorithm_yoyo_model_offline_shallow_predict partition_spec='ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857'>
INFO:tensorflow:mode: infer device: GPU task_type: chief task_idx: 0 time_str: 202511220000 end_time_str: None waste: 7.48 mins
expert_outlist---- Tensor("mmoe_tower/stack:0", shape=(None, 6, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_1:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_1:0", shape=(None, 128), dtype=float32)
gate_i-- Tensor("mmoe_tower/ExpandDims_2:0", shape=(None, 6, 1), dtype=float32)
--domain_input Tensor("mmoe_tower/Sum_2:0", shape=(None, 128), dtype=float32)
write_df2odps:adx_dmp.ads_algorithm_yoyo_model_offline_shallow_predict,partitions:ds_date=202511220000,feature_type=O35_mutil_cvr_v10,infer_time=20251123135857
/data/share/opt/model/O35_mutil_cvr_v10
----------------------------clear history data--------------------------------
code_dir=/opt/huangmian/yoyo_model
TRAIN_CONFIG=config/O35_mutil_cvr_v10/train_config.py
seq_idxs=[]
(Namespace(data_path='/data/share/opt/data', del_date='20251023'), [])
---------del_path=/data/share/opt/data/O35_mutil_cvr/20251023--------
/data/share/opt/model/O35_mutil_cvr_v10
